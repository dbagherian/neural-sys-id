{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#path to save trained model\n",
    "sd=95000\n",
    "\n",
    "\n",
    "wheretosave='/home/ubuntu/Notebooks/kdd_sona43_sd' + str(sd) + '.mat'\n",
    "no_data_ex=4224 \n",
    "no_data_validation=185 \n",
    "no_data_test=160\n",
    "train_loss_size = 32 \n",
    "total_data_ex=4569 \n",
    "\n",
    "#number of pixels in training images\n",
    "numpix=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import hdf5storage\n",
    "from __future__ import division\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Handle training data: Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#load preconvolved stimuli\n",
    "\n",
    "\n",
    "datapath='/home/ubuntu/Notebooks/kdd_sona_preconv_data.mat'\n",
    "\n",
    "data = hdf5storage.loadmat(datapath)\n",
    "\n",
    "## Handle training data: Stimuli convolved with bipolar cell kernels\n",
    "\n",
    "input_bip1_0 = data['b1_input']\n",
    "input_bip2_0 = data['b2_input']\n",
    "input_bip3_0 = data['b3_input']\n",
    "input_bip4_0 = data['b4_input']\n",
    "input_bip5_0 = data['b5_input']\n",
    "input_bip6_0 = data['b6_input']\n",
    "input_bip7_0 = data['b7_input']\n",
    "input_bip8_0 = data['b8_input']\n",
    "input_bip9_0 = data['b9_input']\n",
    "input_bip10_0 = data['b10_input']\n",
    "input_bip11_0 = data['b11_input']\n",
    "input_bip12_0 = data['b12_input']\n",
    "input_bip13_0 = data['b13_input']\n",
    "input_bip14_0 = data['b14_input']\n",
    "input_bip15_0 = data['b15_input']\n",
    "input_bip16_0 = data['b16_input']\n",
    "\n",
    "\n",
    "\n",
    "data_duration1=input_bip1_0.shape[1]\n",
    "print(data_duration1)\n",
    "\n",
    "data_duration = 990\n",
    "\n",
    "def rearrange_bip_input(input_bip_0, startind, endind):\n",
    "    input_bip_1 = reshape(input_bip_0, [1, total_data_ex, data_duration1, numpix])\n",
    "    input_bip_11 = input_bip_1[:, startind:endind, 7:997, :]\n",
    "    input_bip_2 = np.swapaxes(input_bip_11, 0, 3)\n",
    "    input_bip_3 = reshape(input_bip_2, [numpix, total_data_ex, data_duration])\n",
    "    return input_bip_3\n",
    "\n",
    "startind = 0\n",
    "endind = total_data_ex\n",
    "\n",
    "input_bip1_3 = rearrange_bip_input(input_bip1_0, startind, endind)\n",
    "input_bip2_3 = rearrange_bip_input(input_bip2_0, startind, endind)\n",
    "input_bip3_3 = rearrange_bip_input(input_bip3_0, startind, endind)\n",
    "input_bip4_3 = rearrange_bip_input(input_bip4_0, startind, endind)\n",
    "input_bip5_3 = rearrange_bip_input(input_bip5_0, startind, endind)\n",
    "input_bip6_3 = rearrange_bip_input(input_bip6_0, startind, endind)\n",
    "input_bip7_3 = rearrange_bip_input(input_bip7_0, startind, endind)\n",
    "input_bip8_3 = rearrange_bip_input(input_bip8_0, startind, endind)\n",
    "input_bip9_3 = rearrange_bip_input(input_bip9_0, startind, endind)\n",
    "input_bip10_3 = rearrange_bip_input(input_bip10_0, startind, endind)\n",
    "input_bip11_3 = rearrange_bip_input(input_bip11_0, startind, endind)\n",
    "input_bip12_3 = rearrange_bip_input(input_bip12_0, startind, endind)\n",
    "input_bip13_3 = rearrange_bip_input(input_bip13_0, startind, endind)\n",
    "input_bip14_3 = rearrange_bip_input(input_bip14_0, startind, endind)\n",
    "input_bip15_3 = rearrange_bip_input(input_bip15_0, startind, endind)\n",
    "input_bip16_3 = rearrange_bip_input(input_bip16_0, startind, endind)\n",
    "\n",
    "\n",
    "input_bip1_valid = input_bip1_3[:, 0:no_data_validation, :]\n",
    "input_bip1_train = input_bip1_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip1_test = input_bip1_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip2_valid = input_bip2_3[:, 0:no_data_validation, :]\n",
    "input_bip2_train = input_bip2_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip2_test = input_bip2_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip3_valid = input_bip3_3[:, 0:no_data_validation, :]\n",
    "input_bip3_train = input_bip3_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip3_test = input_bip3_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip4_valid = input_bip4_3[:, 0:no_data_validation, :]\n",
    "input_bip4_train = input_bip4_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip4_test = input_bip4_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip5_valid = input_bip5_3[:, 0:no_data_validation, :]\n",
    "input_bip5_train = input_bip5_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip5_test = input_bip5_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip6_valid = input_bip6_3[:, 0:no_data_validation, :]\n",
    "input_bip6_train = input_bip6_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip6_test = input_bip6_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip7_valid = input_bip7_3[:, 0:no_data_validation, :]\n",
    "input_bip7_train = input_bip7_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip7_test = input_bip7_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip8_valid = input_bip8_3[:, 0:no_data_validation, :]\n",
    "input_bip8_train = input_bip8_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip8_test = input_bip8_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip9_valid = input_bip9_3[:, 0:no_data_validation, :]\n",
    "input_bip9_train = input_bip9_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip9_test = input_bip9_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip10_valid = input_bip10_3[:, 0:no_data_validation, :]\n",
    "input_bip10_train = input_bip10_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip10_test = input_bip10_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "\n",
    "input_bip11_valid = input_bip11_3[:, 0:no_data_validation, :]\n",
    "input_bip11_train = input_bip11_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip11_test = input_bip11_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "\n",
    "input_bip12_valid = input_bip12_3[:, 0:no_data_validation, :]\n",
    "input_bip12_train = input_bip12_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip12_test = input_bip12_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip13_valid = input_bip13_3[:, 0:no_data_validation, :]\n",
    "input_bip13_train = input_bip13_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip13_test = input_bip13_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip14_valid = input_bip14_3[:, 0:no_data_validation, :]\n",
    "input_bip14_train = input_bip14_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip14_test = input_bip14_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip15_valid = input_bip15_3[:, 0:no_data_validation, :]\n",
    "input_bip15_train = input_bip15_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip15_test = input_bip15_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip16_valid = input_bip16_3[:, 0:no_data_validation, :]\n",
    "input_bip16_train = input_bip16_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip16_test = input_bip16_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load and handle ganglion cell responses\n",
    "\n",
    "\n",
    "datapath='/home/ubuntu/Notebooks/cell43_y_train.mat'\n",
    "data = hdf5storage.loadmat(datapath)\n",
    "\n",
    "y_train0 = 0.5*reshape(data['y_train'], [total_data_ex, 1, data_duration1])\n",
    "y_train0 = y_train0[0:total_data_ex, :, 0:990]\n",
    "\n",
    "y_valid = y_train0[ 0:no_data_validation, :, :]\n",
    "y_train = y_train0[no_data_validation:no_data_validation+no_data_ex, :, :]\n",
    "y_test = y_train0[no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :, :]\n",
    "\n",
    "gen_gc_w=[0.0, -0.5, 0.0, 1.0, 0.0]\n",
    "gen_gc_w=np.reshape(gen_gc_w, [5, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SET NUMBER OF NEURONS IN EACH LAYER\n",
    "no_filters=16 #14\n",
    "no_filters_per_bc_type=1\n",
    "\n",
    "no_bipolar_rows = 1\n",
    "no_bipolars= numpix*no_bipolar_rows\n",
    "no_bipolar_types=2 \n",
    "no_relu=0\n",
    "no_am_types = 5\n",
    "no_am1=8 \n",
    "no_am2=21\n",
    "no_am3=21\n",
    "no_gc=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## load and handle filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "\n",
    "def bias_var(shape, initial_val):\n",
    "    initial = tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "#     initial = tf.random_uniform(shape, minval=-1.0, maxval=0.0, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bg_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.1, maxval=0.8, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def ba_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.05, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def zero_synapse_var(shape, initial_val):\n",
    "#     initial_val=tf.zeros(shape=shape)\n",
    "    initial=tf.constant(0.0*initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "#     initial = tf.random_uniform(shape, minval=0.05, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.15, maxval=0.18, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def linear_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.05, maxval=0.08, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def fb_synapse_var(shape, initial_val):\n",
    "    initial_val = initial_val.astype(float32)\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "    \n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "#     initial = tf.random_uniform(shape, minval=0.1, maxval=0.8, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def ab_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.1, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def ag_synapse_var(shape, true_initial_val, train_initial_val):\n",
    "    initial=tf.constant(true_initial_val, shape=shape)\n",
    "#     initial=tf.constant(train_initial_val, shape=shape)\n",
    "    \n",
    "#     initial=tf.constant(true_initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.1, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def pbconv2d(x, W):\n",
    "    padsize=175 #200 #W.shape[0]\n",
    "    paddedx=tf.pad(x, [[0, 0], [padsize, 0], [0, 0], [0, 0]], 'CONSTANT')\n",
    "    outconv=tf.nn.conv2d(paddedx, W, strides=[1, 1, 1, 1], padding='SAME') #250 for movingdot and noise\n",
    "    #return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+250, 0, 0], [-1, 250, 1, 1])\n",
    "    return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+x_train.shape[1], 0, 0], [-1, x_train.shape[1], 1, 1])\n",
    "\n",
    "\n",
    "def gcconv2d(x, W):\n",
    "    padsize=5 #200 #W.shape[0]\n",
    "    paddedx=tf.pad(x, [[0, 0], [padsize, 0], [0, 0], [0, 0]], 'CONSTANT')\n",
    "    outconv=tf.nn.conv2d(paddedx, W, strides=[1, 1, 1, 1], padding='SAME') #250 for movingdot and noise\n",
    "    #return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+250, 0, 0], [-1, 250, 1, 1])\n",
    "    return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+data_duration, 0, 0], [-1, data_duration, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create input placeholder variables\n",
    "\n",
    "input_filt1_ = tf.placeholder(\"float32\", name=\"input_filt1\")\n",
    "input_filt2_ = tf.placeholder(\"float32\", name=\"input_filt2\")\n",
    "input_filt3_ = tf.placeholder(\"float32\", name=\"input_filt3\")\n",
    "input_filt4_ = tf.placeholder(\"float32\", name=\"input_filt4\")\n",
    "input_filt5_ = tf.placeholder(\"float32\", name=\"input_filt5\")\n",
    "input_filt6_ = tf.placeholder(\"float32\", name=\"input_filt6\")\n",
    "input_filt7_ = tf.placeholder(\"float32\", name=\"input_filt7\")\n",
    "input_filt8_ = tf.placeholder(\"float32\", name=\"input_filt8\")\n",
    "input_filt9_ = tf.placeholder(\"float32\", name=\"input_filt9\")\n",
    "input_filt10_ = tf.placeholder(\"float32\", name=\"input_filt10\")\n",
    "input_filt11_ = tf.placeholder(\"float32\", name=\"input_filt11\")\n",
    "input_filt12_ = tf.placeholder(\"float32\", name=\"input_filt12\")\n",
    "input_filt13_ = tf.placeholder(\"float32\", name=\"input_filt13\")\n",
    "input_filt14_ = tf.placeholder(\"float32\", name=\"input_filt14\")\n",
    "input_filt15_ = tf.placeholder(\"float32\", name=\"input_filt15\")\n",
    "input_filt16_ = tf.placeholder(\"float32\", name=\"input_filt16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO HAND ADJUST INITIALIZATIONS, USE PARAMS BELOW\n",
    "# NB: THIS IS FOR PLAYING AROUND/INSPECTION ONLY. \n",
    "# DURING ACTUAL TRAINING, VARIABLES ARE RANDOMLY INITIALIZED (see helper functions)\n",
    "\n",
    "b1g = [0.0]\n",
    "b2g = [0.0]\n",
    "b11g = [0.0]\n",
    "\n",
    "b1copyg = [0.0]\n",
    "b2copyg = [0.0]\n",
    "b11copyg = [0.0]\n",
    "\n",
    "b1b = 0.0\n",
    "b2b = -10.0\n",
    "b11b = -0.0 \n",
    "\n",
    "b1a1 = 0.0\n",
    "b2a1 = 0.0\n",
    "b11a1 = 1.0\n",
    "\n",
    "a1g = [0.0]\n",
    "\n",
    "a1b1copy = 5.0\n",
    "a1b2copy = 0.0\n",
    "\n",
    "\n",
    "bip1_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip1_gc_initial[bip_i, gc_i]=b1g[gc_i]\n",
    "bip1_gc_initial=bip1_gc_initial.astype(float32)\n",
    "\n",
    "bip2_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip2_gc_initial[bip_i, gc_i]=b2g[gc_i]\n",
    "bip2_gc_initial=bip2_gc_initial.astype(float32)\n",
    "\n",
    "\n",
    "bip11_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip11_gc_initial[bip_i, gc_i]=b11g[gc_i]\n",
    "bip11_gc_initial=bip11_gc_initial.astype(float32)\n",
    "\n",
    "\n",
    "\n",
    "bip1_copy_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip1_copy_gc_initial[bip_i, gc_i]=b1copyg[gc_i]\n",
    "bip1_copy_gc_initial=bip1_copy_gc_initial.astype(float32)\n",
    "\n",
    "bip2_copy_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(8):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip2_copy_gc_initial[bip_i, gc_i]=b2copyg[gc_i]\n",
    "bip2_copy_gc_initial=bip2_copy_gc_initial.astype(float32)\n",
    "\n",
    "\n",
    "bip11_copy_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(8):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip11_gc_initial[bip_i, gc_i]=b11copyg[gc_i]\n",
    "bip11_copy_gc_initial=bip11_copy_gc_initial.astype(float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "am1_b1copy_initial=np.zeros([no_am1, no_bipolars])\n",
    "for am_i in range(1):\n",
    "    for bip_i in range(4, 12):\n",
    "        am1_b1copy_initial[bip_i-4, bip_i]=a1b1copy\n",
    "am1_b1copy_initial=am1_b1copy_initial.astype(float32)\n",
    "\n",
    "am1_b2copy_initial=np.zeros([no_am1, no_bipolars])\n",
    "for am_i in range(3):\n",
    "    for bip_i in range(8):\n",
    "        am1_b2copy_initial[am_i, bip_i]=a1b2copy\n",
    "am1_b2copy_initial=am1_b2copy_initial.astype(float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "am1_gc_initial=np.zeros([no_am1, no_gc])\n",
    "for am_i in range(3):\n",
    "    for gc_i in range(no_gc):\n",
    "        am1_gc_initial[am_i, gc_i]=a1g[gc_i]\n",
    "am1_gc_initial=am1_gc_initial.astype(float32)\n",
    "\n",
    "am1_gc_train_initial=np.zeros([no_am1, no_gc])\n",
    "for am_i in range(no_am1):\n",
    "    am1_gc_train_initial[am_i, 0]=0.0*np.random.uniform()\n",
    "am1_gc_train_initial=am1_gc_train_initial.astype(float32)\n",
    "\n",
    "\n",
    "bip1_am1_initial=np.zeros([no_bipolars, no_am1])\n",
    "for am_i in range(1):\n",
    "    for bip_i in range(8, 16):\n",
    "        bip1_am1_initial[bip_i, am_i]=b1a1\n",
    "bip1_am1_initial=bip1_am1_initial.astype(float32)\n",
    "\n",
    "bip2_am1_initial=np.zeros([no_bipolars, no_am1])\n",
    "for am_i in range(1):\n",
    "    for bip_i in range(8, 16):\n",
    "        bip2_am1_initial[bip_i, am_i]=b2a1\n",
    "bip2_am1_initial=bip2_am1_initial.astype(float32)\n",
    "\n",
    "bip11_am1_initial=np.zeros([no_bipolars, no_am1])\n",
    "for bip_i in range(4, 12):\n",
    "#     for bip_i in range(4, 12):\n",
    "    bip11_am1_initial[bip_i-1, bip_i-4]=b11a1\n",
    "    bip11_am1_initial[bip_i, bip_i-4]=b11a1\n",
    "    bip11_am1_initial[bip_i+1, bip_i-4]=b11a1\n",
    "bip11_am1_initial=bip11_am1_initial.astype(float32)\n",
    "\n",
    "\n",
    "gc_stretch_initial=1.0*np.ones([no_gc, 1])\n",
    "gc_stretch_initial=gc_stretch_initial.astype(float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# load synaptic weight masks (derived from IPL address book)\n",
    "\n",
    "maskpath='/home/ubuntu/Notebooks/alpha_realdata_syn_weight_masks_2D_30pix.mat'\n",
    "mask=sio.loadmat(maskpath)\n",
    "\n",
    "bip1_gc_mask = mask['bip1_gc_mask']\n",
    "bip2_gc_mask = mask['bip2_gc_mask']\n",
    "bip11_gc_mask = mask['bip11_gc_mask']\n",
    "\n",
    "bip1_am1_mask = mask['bip1_am1_mask']\n",
    "bip2_am1_mask = mask['bip2_am1_mask']\n",
    "bip11_am1_mask = mask['bip11_am1_mask']\n",
    "\n",
    "am1_gc_mask = mask['am1_gc_mask']+1.0\n",
    "\n",
    "print(am1_gc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# INITIALIZE SYNAPTIC WEIGHT AND BIAS VARIABLES\n",
    "\n",
    "# bip1_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip1_gc_initial), bip1_gc_mask) #20201215\n",
    "bip1_gc_syn=tf.math.multiply(synapse_var([no_bipolars, no_gc], bip1_gc_initial), bip1_gc_mask)\n",
    "\n",
    "bip2_gc_syn=tf.math.multiply(linear_synapse_var([no_bipolars, no_gc], bip2_gc_initial), bip2_gc_mask)\n",
    "# bip2_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip2_gc_initial), bip2_gc_mask)\n",
    "\n",
    "bip11_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip11_gc_initial), bip11_gc_mask)\n",
    "\n",
    "bip1_copy_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip1_copy_gc_initial), bip1_gc_mask)#20201215\n",
    "\n",
    "bip2_copy_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip2_copy_gc_initial), bip2_gc_mask)\n",
    "\n",
    "bip11_copy_gc_syn=tf.math.multiply(bg_synapse_var([no_bipolars, no_gc], bip11_copy_gc_initial), bip11_gc_mask)\n",
    "\n",
    "bip1_am1_syn = tf.math.multiply(ba_synapse_var([no_bipolars, no_am1], bip1_am1_initial), bip1_am1_mask)\n",
    "bip2_am1_syn = tf.math.multiply(ba_synapse_var([no_bipolars, no_am1], bip2_am1_initial), bip2_am1_mask)\n",
    "bip11_am1_syn = tf.math.multiply(ba_synapse_var([no_bipolars, no_am1], bip11_am1_initial), bip11_am1_mask)\n",
    "\n",
    "\n",
    "\n",
    "am1_gc_syn = tf.math.multiply(ag_synapse_var([no_am1, no_gc], am1_gc_initial, am1_gc_train_initial), am1_gc_mask)\n",
    "\n",
    "am1_b1copy_syn = ab_synapse_var([no_am1, no_bipolars], am1_b1copy_initial)\n",
    "\n",
    "am1_b2copy_syn = zero_synapse_var([no_am1, no_bipolars], am1_b2copy_initial)\n",
    "\n",
    "\n",
    "b1_bias_initial=b1b*np.ones([no_bipolars, 1])\n",
    "b1_bias_initial=b1_bias_initial.astype(float32)\n",
    "\n",
    "b2_bias_initial=b2b*np.ones([no_bipolars, 1])\n",
    "b2_bias_initial=b2_bias_initial.astype(float32)\n",
    "\n",
    "\n",
    "b11_bias_initial=b11b*np.ones([no_bipolars, 1])\n",
    "b11_bias_initial=b11_bias_initial.astype(float32)\n",
    "\n",
    "\n",
    "\n",
    "b1_bias=bias_var([no_bipolars, 1], b1_bias_initial)\n",
    "b2_bias=bias_var([no_bipolars, 1], b2_bias_initial)\n",
    "\n",
    "b11_bias=bias_var([no_bipolars, 1], b11_bias_initial)\n",
    "\n",
    "\n",
    "am1_bias_initial=-50.0*np.ones([no_am1, 1])\n",
    "am1_bias_initial=am1_bias_initial.astype(float32)\n",
    "am1_bias=bias_var([no_am1, 1], am1_bias_initial)\n",
    "\n",
    "gc_bias_initial = np.array([[0.0]])\n",
    "gc_bias_initial=gc_bias_initial.astype(float32)\n",
    "gc_bias=bias_var([no_gc, 1], gc_bias_initial)\n",
    "\n",
    "gc_stretch=synapse_var([no_gc, 1], gc_stretch_initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#INITIALIZE BIPOLAR CELL TEMPORAL KERNELS. three parameter sets modeled after biological bipolar cells.\n",
    "\n",
    "# ## normal filt\n",
    "# f1b1=32.4739\n",
    "# f2b1=-36.2776\n",
    "# f3b1=9.2522\n",
    "# f4b1=-24.8925\n",
    "# f5b1=-3.3185\n",
    "# f6b1=3.4590\n",
    "# f7b1=1.8170\n",
    "# f8b1=-2.8191\n",
    "# f9b1=0.2779\n",
    "# f10b1=-0.0095\n",
    "# f11b1=0.0742\n",
    "# f12b1=0.5002\n",
    "# f13b1=-0.8313\n",
    "# f14b1=1.0948\n",
    "# f15b1=-0.7449\n",
    "# f16b1=0.6164\n",
    "\n",
    "# f1b2=32.4739\n",
    "# f2b2=-36.2776\n",
    "# f3b2=9.2522\n",
    "# f4b2=-24.8925\n",
    "# f5b2=-3.3185\n",
    "# f6b2=3.4590\n",
    "# f7b2=1.8170\n",
    "# f8b2=-2.8191\n",
    "# f9b2=0.2779\n",
    "# f10b2=-0.0095\n",
    "# f11b2=0.0742\n",
    "# f12b2=0.5002\n",
    "# f13b2=-0.8313\n",
    "# f14b2=1.0948\n",
    "# f15b2=-0.7449\n",
    "# f16b2=0.6164\n",
    "\n",
    "# f1b11=-32.4739\n",
    "# f2b11=36.2776\n",
    "# f3b11=-9.2522\n",
    "# f4b11=24.8925\n",
    "# f5b11=3.3185\n",
    "# f6b11=-3.4590\n",
    "# f7b11=-1.8170\n",
    "# f8b11=2.8191\n",
    "# f9b11=-0.2779\n",
    "# f10b11=0.0095\n",
    "# f11b11=-0.0742\n",
    "# f12b11=-0.5002\n",
    "# f13b11=0.8313\n",
    "# f14b11=-1.0948\n",
    "# f15b11=0.7449\n",
    "# f16b11=-0.6164\n",
    "\n",
    "## slow filt\n",
    "f1b1=8.9629\n",
    "f2b1=-14.8934\n",
    "f3b1=-3.7342\n",
    "f4b1=-2.4524\n",
    "f5b1=-2.2385\n",
    "f6b1=4.8663\n",
    "f7b1=1.0306\n",
    "f8b1=-0.1179\n",
    "f9b1=-0.1026\n",
    "f10b1=0.1568\n",
    "f11b1=0.1731\n",
    "f12b1=0.1854\n",
    "f13b1=0.0526\n",
    "f14b1=-0.0769\n",
    "f15b1=-0.0104\n",
    "f16b1=-0.0069\n",
    "\n",
    "f1b2=8.9629\n",
    "f2b2=-14.8934\n",
    "f3b2=-3.7342\n",
    "f4b2=-2.4524\n",
    "f5b2=-2.2385\n",
    "f6b2=4.8663\n",
    "f7b2=1.0306\n",
    "f8b2=-0.1179\n",
    "f9b2=-0.1026\n",
    "f10b2=0.1568\n",
    "f11b2=0.1731\n",
    "f12b2=0.1854\n",
    "f13b2=0.0526\n",
    "f14b2=-0.0769\n",
    "f15b2=-0.0104\n",
    "f16b2=-0.0069\n",
    "\n",
    "f1b11=-8.9629\n",
    "f2b11=14.8934\n",
    "f3b11=3.7342\n",
    "f4b11=2.4524\n",
    "f5b11=2.2385\n",
    "f6b11=-4.8663\n",
    "f7b11=-1.0306\n",
    "f8b11=0.1179\n",
    "f9b11=0.1026\n",
    "f10b11=-0.1568\n",
    "f11b11=-0.1731\n",
    "f12b11=-0.1854\n",
    "f13b11=-0.0526\n",
    "f14b11=0.0769\n",
    "f15b11=0.0104\n",
    "f16b11=0.0069\n",
    "\n",
    "\n",
    "# ## fast filt\n",
    "# f1b1=3.3739\n",
    "# f2b1=-3.0542\n",
    "# f3b1=4.9315\n",
    "# f4b1=-7.0294\n",
    "# f5b1=1.8001\n",
    "# f6b1=-5.5280\n",
    "# f7b1=-1.2573\n",
    "# f8b1=0.5046\n",
    "# f9b1=0.2822\n",
    "# f10b1=-0.1797\n",
    "# f11b1=-0.0894\n",
    "# f12b1=-0.6905\n",
    "# f13b1=0.0932\n",
    "# f14b1=-0.6807\n",
    "# f15b1=0.4166\n",
    "# f16b1=-0.8054\n",
    "\n",
    "\n",
    "# f1b2=3.3739\n",
    "# f2b2=-3.0542\n",
    "# f3b2=4.9315\n",
    "# f4b2=-7.0294\n",
    "# f5b2=1.8001\n",
    "# f6b2=-5.5280\n",
    "# f7b2=-1.2573\n",
    "# f8b2=0.5046\n",
    "# f9b2=0.2822\n",
    "# f10b2=-0.1797\n",
    "# f11b2=-0.0894\n",
    "# f12b2=-0.6905\n",
    "# f13b2=0.0932\n",
    "# f14b2=-0.6807\n",
    "# f15b2=0.4166\n",
    "# f16b2=-0.8054\n",
    "\n",
    "# f1b11=-3.3739\n",
    "# f2b11=3.0542\n",
    "# f3b11=-4.9315\n",
    "# f4b11=7.0294\n",
    "# f5b11=-1.8001\n",
    "# f6b11=5.5280\n",
    "# f7b11=1.2573\n",
    "# f8b11=-0.5046\n",
    "# f9b11=-0.2822\n",
    "# f10b11=0.1797\n",
    "# f11b11=0.0894\n",
    "# f12b11=0.6905\n",
    "# f13b11=-0.0932\n",
    "# f14b11=0.6807\n",
    "# f15b11=-0.4166\n",
    "# f16b11=0.8054\n",
    "\n",
    "f1b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f1b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f2b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f2b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f3b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f3b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f4b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f4b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f5b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f5b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f6b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f6b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f7b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f7b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f8b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f8b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f9b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f9b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f10b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f10b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f11b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f11b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f12b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f12b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f13b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f13b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f14b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f14b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f15b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f15b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f16b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f16b1*np.ones([1, no_filters_per_bc_type]))\n",
    "\n",
    "f1b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f1b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f2b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f2b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f3b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f3b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f4b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f4b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f5b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f5b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f6b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f6b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f7b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f7b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f8b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f8b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f9b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f9b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f10b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f10b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f11b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f11b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f12b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f12b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f13b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f13b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f14b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f14b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f15b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f15b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f16b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f16b2*np.ones([1, no_filters_per_bc_type]))\n",
    "\n",
    "f1b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f1b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f2b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f2b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f3b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f3b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f4b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f4b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f5b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f5b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f6b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f6b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f7b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f7b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f8b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f8b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f9b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f9b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f10b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f10b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f11b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f11b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f12b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f12b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f13b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f13b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f14b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f14b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f15b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f15b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f16b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f16b11*np.ones([1, no_filters_per_bc_type]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dur=data_duration\n",
    "batchsize=32\n",
    "no_bip=no_bipolars\n",
    "\n",
    "batchsize_ = tf.placeholder(\"int32\", name=\"batch_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DEFINE ANN GRAPH\n",
    "\n",
    "@tf.function\n",
    "def biplayer(f1_input, f2_input, f3_input, f4_input, f5_input, f6_input, f7_input, f8_input, \n",
    "                f9_input, f10_input, f11_input, f12_input, f13_input, f14_input, f15_input, f16_input, \n",
    "                f1b_syn, f2b_syn, f3b_syn, f4b_syn, f5b_syn, f6b_syn, f7b_syn, f8b_syn, f9b_syn, f10b_syn, \n",
    "                f11b_syn, f12b_syn, f13b_syn, f14b_syn, f15b_syn, f16b_syn, b_bias, bip_gc_syn, no_bip, no_gc, batchsize, dur): #, no_bip, no_filt, batchsize, dur):\n",
    "    \n",
    "    f1b_syn=tf.broadcast_to(tf.reshape(f1b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f2b_syn=tf.broadcast_to(tf.reshape(f2b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f3b_syn=tf.broadcast_to(tf.reshape(f3b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f4b_syn=tf.broadcast_to(tf.reshape(f4b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f5b_syn=tf.broadcast_to(tf.reshape(f5b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f6b_syn=tf.broadcast_to(tf.reshape(f6b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f7b_syn=tf.broadcast_to(tf.reshape(f7b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f8b_syn=tf.broadcast_to(tf.reshape(f8b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f9b_syn=tf.broadcast_to(tf.reshape(f9b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f10b_syn=tf.broadcast_to(tf.reshape(f10b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f11b_syn=tf.broadcast_to(tf.reshape(f11b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f12b_syn=tf.broadcast_to(tf.reshape(f12b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f13b_syn=tf.broadcast_to(tf.reshape(f13b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f14b_syn=tf.broadcast_to(tf.reshape(f14b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f15b_syn=tf.broadcast_to(tf.reshape(f15b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f16b_syn=tf.broadcast_to(tf.reshape(f16b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    \n",
    "    f1_input=tf.tile(f1_input, [no_bipolar_rows, 1, 1])\n",
    "    f2_input=tf.tile(f2_input, [no_bipolar_rows, 1, 1])\n",
    "    f3_input=tf.tile(f3_input, [no_bipolar_rows, 1, 1])\n",
    "    f4_input=tf.tile(f4_input, [no_bipolar_rows, 1, 1])\n",
    "    f5_input=tf.tile(f5_input, [no_bipolar_rows, 1, 1])\n",
    "    f6_input=tf.tile(f6_input, [no_bipolar_rows, 1, 1])\n",
    "    f7_input=tf.tile(f7_input, [no_bipolar_rows, 1, 1])\n",
    "    f8_input=tf.tile(f8_input, [no_bipolar_rows, 1, 1])\n",
    "    f9_input=tf.tile(f9_input, [no_bipolar_rows, 1, 1])\n",
    "    f10_input=tf.tile(f10_input, [no_bipolar_rows, 1, 1])\n",
    "    f11_input=tf.tile(f11_input, [no_bipolar_rows, 1, 1])\n",
    "    f12_input=tf.tile(f12_input, [no_bipolar_rows, 1, 1])\n",
    "    f13_input=tf.tile(f13_input, [no_bipolar_rows, 1, 1])\n",
    "    f14_input=tf.tile(f14_input, [no_bipolar_rows, 1, 1])\n",
    "    f15_input=tf.tile(f15_input, [no_bipolar_rows, 1, 1])\n",
    "    f16_input=tf.tile(f16_input, [no_bipolar_rows, 1, 1])\n",
    "\n",
    "    \n",
    "    b_input = tf.add_n([tf.math.multiply(f1b_syn, f1_input), tf.math.multiply(f2b_syn, f2_input), tf.math.multiply(f3b_syn, f3_input),\\\n",
    "                        tf.math.multiply(f4b_syn, f4_input), tf.math.multiply(f5b_syn, f5_input), tf.math.multiply(f6b_syn, f6_input),\\\n",
    "                        tf.math.multiply(f7b_syn, f7_input), tf.math.multiply(f8b_syn, f8_input), tf.math.multiply(f9b_syn, f9_input),\\\n",
    "                        tf.math.multiply(f10b_syn, f10_input), tf.math.multiply(f11b_syn, f11_input), tf.math.multiply(f12b_syn, f12_input), \\\n",
    "                        tf.math.multiply(f13b_syn, f13_input), tf.math.multiply(f14b_syn, f14_input), tf.math.multiply(f15b_syn, f15_input), tf.math.multiply(f16b_syn, f16_input)])\n",
    "    b_bias_expand=tf.broadcast_to(tf.reshape(b_bias, [no_bipolars, 1, 1]), [no_bipolars, batchsize_, dur], name=\"bro1\")\n",
    "    b_bias_add=tf.add(-1.0*b_input, b_bias_expand)\n",
    "    del b_input\n",
    "    del b_bias_expand\n",
    "    b_relu=tf.nn.relu(b_bias_add)\n",
    "    del b_bias_add\n",
    "    bip_layer_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize_, 1, dur]), [no_bip, batchsize_, no_gc, dur], name=\"bro2\")\n",
    "    \n",
    "    bg_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(bip_gc_syn), [no_bip, 1, no_gc, 1]), [no_bip, batchsize_, no_gc, dur], name=\"bro3\")\n",
    "    bg_mult=tf.math.multiply(bip_layer_expand, bg_syn_expand)\n",
    "    del bip_layer_expand \n",
    "    del bg_syn_expand\n",
    "    bg_sum=tf.reduce_sum(bg_mult, 0)\n",
    "    del bg_mult\n",
    "    return b_relu, bg_sum\n",
    "    \n",
    "@tf.function\n",
    "def linear_biplayer(f1_input, f2_input, f3_input, f4_input, f5_input, f6_input, f7_input, f8_input, \n",
    "                f9_input, f10_input, f11_input, f12_input, f13_input, f14_input, f15_input, f16_input, \n",
    "                f1b_syn, f2b_syn, f3b_syn, f4b_syn, f5b_syn, f6b_syn, f7b_syn, f8b_syn, f9b_syn, f10b_syn, \n",
    "                f11b_syn, f12b_syn, f13b_syn, f14b_syn, f15b_syn, f16b_syn, b_bias, bip_gc_syn, no_bip, no_gc, batchsize, dur): #, no_bip, no_filt, batchsize, dur):\n",
    "    \n",
    "    f1b_syn=tf.broadcast_to(tf.reshape(f1b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur], name='brosyn1')\n",
    "    f2b_syn=tf.broadcast_to(tf.reshape(f2b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f3b_syn=tf.broadcast_to(tf.reshape(f3b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f4b_syn=tf.broadcast_to(tf.reshape(f4b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f5b_syn=tf.broadcast_to(tf.reshape(f5b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f6b_syn=tf.broadcast_to(tf.reshape(f6b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f7b_syn=tf.broadcast_to(tf.reshape(f7b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f8b_syn=tf.broadcast_to(tf.reshape(f8b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f9b_syn=tf.broadcast_to(tf.reshape(f9b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f10b_syn=tf.broadcast_to(tf.reshape(f10b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f11b_syn=tf.broadcast_to(tf.reshape(f11b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f12b_syn=tf.broadcast_to(tf.reshape(f12b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f13b_syn=tf.broadcast_to(tf.reshape(f13b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f14b_syn=tf.broadcast_to(tf.reshape(f14b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f15b_syn=tf.broadcast_to(tf.reshape(f15b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f16b_syn=tf.broadcast_to(tf.reshape(f16b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    \n",
    "    f1_input=tf.tile(f1_input, [no_bipolar_rows, 1, 1])\n",
    "    f2_input=tf.tile(f2_input, [no_bipolar_rows, 1, 1])\n",
    "    f3_input=tf.tile(f3_input, [no_bipolar_rows, 1, 1])\n",
    "    f4_input=tf.tile(f4_input, [no_bipolar_rows, 1, 1])\n",
    "    f5_input=tf.tile(f5_input, [no_bipolar_rows, 1, 1])\n",
    "    f6_input=tf.tile(f6_input, [no_bipolar_rows, 1, 1])\n",
    "    f7_input=tf.tile(f7_input, [no_bipolar_rows, 1, 1])\n",
    "    f8_input=tf.tile(f8_input, [no_bipolar_rows, 1, 1])\n",
    "    f9_input=tf.tile(f9_input, [no_bipolar_rows, 1, 1])\n",
    "    f10_input=tf.tile(f10_input, [no_bipolar_rows, 1, 1])\n",
    "    f11_input=tf.tile(f11_input, [no_bipolar_rows, 1, 1])\n",
    "    f12_input=tf.tile(f12_input, [no_bipolar_rows, 1, 1])\n",
    "    f13_input=tf.tile(f13_input, [no_bipolar_rows, 1, 1])\n",
    "    f14_input=tf.tile(f14_input, [no_bipolar_rows, 1, 1])\n",
    "    f15_input=tf.tile(f15_input, [no_bipolar_rows, 1, 1])\n",
    "    f16_input=tf.tile(f16_input, [no_bipolar_rows, 1, 1])\n",
    "\n",
    "    \n",
    "\n",
    "    b_input = tf.add_n([tf.math.multiply(f1b_syn, f1_input), tf.math.multiply(f2b_syn, f2_input), tf.math.multiply(f3b_syn, f3_input),\\\n",
    "                        tf.math.multiply(f4b_syn, f4_input), tf.math.multiply(f5b_syn, f5_input), tf.math.multiply(f6b_syn, f6_input),\\\n",
    "                        tf.math.multiply(f7b_syn, f7_input), tf.math.multiply(f8b_syn, f8_input), tf.math.multiply(f9b_syn, f9_input),\\\n",
    "                        tf.math.multiply(f10b_syn, f10_input), tf.math.multiply(f11b_syn, f11_input), tf.math.multiply(f12b_syn, f12_input), \\\n",
    "                        tf.math.multiply(f13b_syn, f13_input), tf.math.multiply(f14b_syn, f14_input), tf.math.multiply(f15b_syn, f15_input), tf.math.multiply(f16b_syn, f16_input)])\n",
    "    b_bias_expand=tf.broadcast_to(tf.reshape(b_bias, [no_bipolars, 1, 1]), [no_bipolars, batchsize_, dur], name=\"bro1\")\n",
    "    b_bias_add=tf.add(-1.0*b_input, b_bias_expand)\n",
    "    del b_input\n",
    "    del b_bias_expand\n",
    "    b_relu=b_bias_add\n",
    "    del b_bias_add\n",
    "    bip_layer_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize_, 1, dur]), [no_bip, batchsize_, no_gc, dur], name=\"bro2\")\n",
    "\n",
    "    bg_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(bip_gc_syn), [no_bip, 1, no_gc, 1]), [no_bip, batchsize_, no_gc, dur], name=\"bro3\")\n",
    "    bg_mult=tf.math.multiply(bip_layer_expand, bg_syn_expand)\n",
    "    del bip_layer_expand\n",
    "    del bg_syn_expand\n",
    "    bg_sum=tf.reduce_sum(bg_mult, 0)\n",
    "    del bg_mult\n",
    "    return b_relu, bg_sum\n",
    "    \n",
    "\n",
    "b1_relu, b1g_sum = biplayer(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                            input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                            input_filt14_, input_filt15_, input_filt16_, f1b1_syn, f2b1_syn, f3b1_syn, f4b1_syn, f5b1_syn,\n",
    "                            f6b1_syn, f7b1_syn, f8b1_syn, f9b1_syn, f10b1_syn, f11b1_syn, f12b1_syn, f13b1_syn, f14b1_syn, \n",
    "                            f15b1_syn, f16b1_syn, b1_bias, bip1_gc_syn, no_bip, no_gc, batchsize_, dur)\n",
    "\n",
    "b2_relu, b2g_sum = linear_biplayer(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                                   input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                                   input_filt14_, input_filt15_, input_filt16_, f1b2_syn, f2b2_syn, f3b2_syn, f4b2_syn, f5b2_syn,\n",
    "                                   f6b2_syn, f7b2_syn, f8b2_syn, f9b2_syn, f10b2_syn, f11b2_syn, f12b2_syn, f13b2_syn, f14b2_syn, \n",
    "                                   f15b2_syn, f16b2_syn, b2_bias, bip2_gc_syn, no_bip, no_gc, batchsize_, dur)\n",
    "\n",
    "\n",
    "b11_relu, b11g_sum = biplayer(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                              input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                              input_filt14_, input_filt15_, input_filt16_, f1b11_syn, f2b11_syn, f3b11_syn, f4b11_syn, f5b11_syn,\n",
    "                              f6b11_syn, f7b11_syn, f8b11_syn, f9b11_syn, f10b11_syn, f11b11_syn, f12b11_syn, f13b11_syn, f14b11_syn, \n",
    "                              f15b11_syn, f16b11_syn, b11_bias, bip11_gc_syn, no_bip, no_gc, batchsize_, dur)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def bip_to_am_input(b_relu, bip_am_syn, no_bip, no_am, batchsize, dur):\n",
    "    bip_layer_am_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize, 1, dur]), [no_bip, batchsize, no_am, dur], name=\"bro10\")\n",
    "    ba_syn_expand = tf.broadcast_to(tf.reshape(tf.abs(bip_am_syn), [no_bip, 1, no_am, 1]), [no_bip, batchsize, no_am, dur], name=\"bro11\")\n",
    "    del b_relu\n",
    "    ba_mult = tf.math.multiply(bip_layer_am_expand, ba_syn_expand)\n",
    "    del bip_layer_am_expand\n",
    "    del ba_syn_expand\n",
    "    ba_sum = tf.reduce_sum(ba_mult, 0)\n",
    "    return ba_mult, ba_sum\n",
    "\n",
    "b11a1_mult, b11a1_sum = bip_to_am_input(b11_relu, bip11_am1_syn, no_bip, no_am1, batchsize_, dur)\n",
    "\n",
    "am1_activation = tf.add_n([b11a1_sum])\n",
    "\n",
    "am1_bias_expand = tf.broadcast_to(am1_bias, [batchsize_, no_am1, dur], name=\"bro20\")\n",
    "\n",
    "am1_bias_add = tf.add(am1_activation, am1_bias_expand)\n",
    "del am1_bias_expand\n",
    "\n",
    "\n",
    "am1_output = tf.nn.relu(am1_bias_add)\n",
    "del am1_bias_add\n",
    "\n",
    "am1_reshape = tf.reshape(am1_output, [batchsize_, no_am1, 1, dur])\n",
    "am1_expand=tf.broadcast_to(am1_reshape, [batchsize_, no_am1, no_gc, dur], name=\"bro22\")\n",
    "am1g_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(am1_gc_syn), [1, no_am1, no_gc, 1]), [batchsize_, no_am1, no_gc, dur], name=\"bro23\")\n",
    "am1g_mult=tf.math.multiply(am1_expand, am1g_syn_expand)\n",
    "del am1_expand\n",
    "del am1g_syn_expand\n",
    "am1g_sum=tf.reduce_sum(am1g_mult, 1)\n",
    "del am1g_mult\n",
    "\n",
    "\n",
    "\n",
    "am1_bcopy_expand=tf.broadcast_to(am1_reshape, [batchsize_, no_am1, no_bip, dur], name=\"bro26\")\n",
    "del am1_reshape\n",
    "\n",
    "@tf.function\n",
    "def biplayer_copy_input(f1_input, f2_input, f3_input, f4_input, f5_input, f6_input, f7_input, f8_input, \n",
    "                        f9_input, f10_input, f11_input, f12_input, f13_input, f14_input, f15_input, f16_input, \n",
    "                        f1b_syn, f2b_syn, f3b_syn, f4b_syn, f5b_syn, f6b_syn, f7b_syn, f8b_syn, f9b_syn, f10b_syn, \n",
    "                        f11b_syn, f12b_syn, f13b_syn, f14b_syn, f15b_syn, f16b_syn,am_bcopy_expand, am_bcopy_syn, b_bias, bip_copy_gc_syn, no_bip, no_am, no_gc, batchsize, dur):\n",
    "    \n",
    "    f1b_syn=tf.broadcast_to(tf.reshape(f1b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f2b_syn=tf.broadcast_to(tf.reshape(f2b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f3b_syn=tf.broadcast_to(tf.reshape(f3b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f4b_syn=tf.broadcast_to(tf.reshape(f4b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f5b_syn=tf.broadcast_to(tf.reshape(f5b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f6b_syn=tf.broadcast_to(tf.reshape(f6b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f7b_syn=tf.broadcast_to(tf.reshape(f7b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f8b_syn=tf.broadcast_to(tf.reshape(f8b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f9b_syn=tf.broadcast_to(tf.reshape(f9b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f10b_syn=tf.broadcast_to(tf.reshape(f10b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f11b_syn=tf.broadcast_to(tf.reshape(f11b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f12b_syn=tf.broadcast_to(tf.reshape(f12b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f13b_syn=tf.broadcast_to(tf.reshape(f13b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f14b_syn=tf.broadcast_to(tf.reshape(f14b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f15b_syn=tf.broadcast_to(tf.reshape(f15b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f16b_syn=tf.broadcast_to(tf.reshape(f16b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    \n",
    "    f1_input=tf.tile(f1_input, [no_bipolar_rows, 1, 1])\n",
    "    f2_input=tf.tile(f2_input, [no_bipolar_rows, 1, 1])\n",
    "    f3_input=tf.tile(f3_input, [no_bipolar_rows, 1, 1])\n",
    "    f4_input=tf.tile(f4_input, [no_bipolar_rows, 1, 1])\n",
    "    f5_input=tf.tile(f5_input, [no_bipolar_rows, 1, 1])\n",
    "    f6_input=tf.tile(f6_input, [no_bipolar_rows, 1, 1])\n",
    "    f7_input=tf.tile(f7_input, [no_bipolar_rows, 1, 1])\n",
    "    f8_input=tf.tile(f8_input, [no_bipolar_rows, 1, 1])\n",
    "    f9_input=tf.tile(f9_input, [no_bipolar_rows, 1, 1])\n",
    "    f10_input=tf.tile(f10_input, [no_bipolar_rows, 1, 1])\n",
    "    f11_input=tf.tile(f11_input, [no_bipolar_rows, 1, 1])\n",
    "    f12_input=tf.tile(f12_input, [no_bipolar_rows, 1, 1])\n",
    "    f13_input=tf.tile(f13_input, [no_bipolar_rows, 1, 1])\n",
    "    f14_input=tf.tile(f14_input, [no_bipolar_rows, 1, 1])\n",
    "    f15_input=tf.tile(f15_input, [no_bipolar_rows, 1, 1])\n",
    "    f16_input=tf.tile(f16_input, [no_bipolar_rows, 1, 1])\n",
    "\n",
    "    \n",
    "    b_input = tf.add_n([tf.math.multiply(f1b_syn, f1_input), tf.math.multiply(f2b_syn, f2_input), tf.math.multiply(f3b_syn, f3_input),\\\n",
    "                        tf.math.multiply(f4b_syn, f4_input), tf.math.multiply(f5b_syn, f5_input), tf.math.multiply(f6b_syn, f6_input),\\\n",
    "                        tf.math.multiply(f7b_syn, f7_input), tf.math.multiply(f8b_syn, f8_input), tf.math.multiply(f9b_syn, f9_input),\\\n",
    "                        tf.math.multiply(f10b_syn, f10_input), tf.math.multiply(f11b_syn, f11_input), tf.math.multiply(f12b_syn, f12_input), \\\n",
    "                        tf.math.multiply(f13b_syn, f13_input), tf.math.multiply(f14b_syn, f14_input), tf.math.multiply(f15b_syn, f15_input), tf.math.multiply(f16b_syn, f16_input)])\n",
    "    ambcopy_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(am_bcopy_syn), [1, no_am, no_bip, 1]), [batchsize, no_am, no_bip, dur], name=\"bro33\")\n",
    "    ambcopy_mult=tf.math.multiply(am_bcopy_expand, ambcopy_syn_expand)\n",
    "    del am_bcopy_expand\n",
    "    del ambcopy_syn_expand\n",
    "    ambcopy_sum1=tf.squeeze(tf.reduce_sum(ambcopy_mult, 1))\n",
    "    ambcopy_sum=tf.transpose(ambcopy_sum1, [1, 0, 2])\n",
    "    \n",
    "    del ambcopy_mult\n",
    "    del ambcopy_sum1\n",
    "    \n",
    "    b_bias_expand=tf.broadcast_to(tf.reshape(b_bias, [no_bipolars, 1, 1]), [no_bipolars, batchsize, dur], name=\"bro1\")\n",
    "    b_bias_add=tf.add_n([b_input,-1.0*ambcopy_sum, b_bias_expand])\n",
    "    del b_input\n",
    "    del b_bias_expand\n",
    "    b_relu=tf.nn.relu(b_bias_add)\n",
    "    del b_bias_add\n",
    "    bip_layer_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize_, 1, dur]), [no_bip, batchsize, no_gc, dur], name=\"bro2\")\n",
    "\n",
    "    bg_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(10.0*bip_copy_gc_syn), [no_bip, 1, no_gc, 1]), [no_bip, batchsize, no_gc, dur], name=\"bro3\")\n",
    "    bg_mult=tf.math.multiply(bip_layer_expand, bg_syn_expand)\n",
    "    del bip_layer_expand\n",
    "    del bg_syn_expand\n",
    "    bg_sum=tf.reduce_sum(bg_mult, 0)\n",
    "    del bg_mult\n",
    "    return b_relu, bg_sum\n",
    "\n",
    "b1copy_relu, b1copyg_sum = biplayer_copy_input(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                                  input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                                  input_filt14_, input_filt15_, input_filt16_, f1b1_syn, f2b1_syn, f3b1_syn, f4b1_syn, f5b1_syn,\n",
    "                                  f6b1_syn, f7b1_syn, f8b1_syn, f9b1_syn, f10b1_syn, f11b1_syn, f12b1_syn, f13b1_syn, f14b1_syn, \n",
    "                                  f15b1_syn, f16b1_syn, am1_bcopy_expand, am1_b1copy_syn, b1_bias, bip1_copy_gc_syn, no_bip, \n",
    "                                  no_am1, no_gc, batchsize_, dur)\n",
    "b2copy_relu, b2copyg_sum = biplayer_copy_input(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                                  input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                                  input_filt14_, input_filt15_, input_filt16_, f1b2_syn, f2b2_syn, f3b2_syn, f4b2_syn, f5b2_syn,\n",
    "                                  f6b2_syn, f7b2_syn, f8b2_syn, f9b2_syn, f10b2_syn, f11b2_syn, f12b2_syn, f13b2_syn, f14b2_syn, \n",
    "                                  f15b2_syn, f16b2_syn,am1_bcopy_expand, am1_b2copy_syn, b2_bias, bip2_copy_gc_syn, \n",
    "                                  no_bip, no_am1, no_gc, batchsize_, dur)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gc_activation=tf.add_n([b1copyg_sum, b2copyg_sum, b1g_sum, b2g_sum, -1.0*am1g_sum])\n",
    "\n",
    "\n",
    "pre_gc=tf.reshape(tf.squeeze(gcconv2d(tf.reshape(gc_activation, [batchsize_, dur, 1, 1]) , gen_gc_w)), [batchsize_, no_gc, dur])\n",
    "# pre_gc=gc_activation\n",
    "\n",
    "del b1copyg_sum\n",
    "del b2copyg_sum\n",
    "del b1g_sum\n",
    "del b2g_sum\n",
    "del am1g_sum\n",
    "\n",
    "\n",
    "gc_bias_expand=tf.broadcast_to(gc_bias, [batchsize_, no_gc, dur])\n",
    "\n",
    "gc_bias_add=tf.add(pre_gc, gc_bias_expand)\n",
    "\n",
    "output=4.0*gc_stretch*tf.nn.relu(gc_bias_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(\"float\", name=\"output_spikes\")\n",
    "learn_rate=1e-3\n",
    "\n",
    "trainsampfd={batchsize_: train_loss_size, input_filt1_: input_bip1_train[:, 0:train_loss_size, :], \\\n",
    "             input_filt2_: input_bip2_train[:, 0:train_loss_size, :], input_filt3_: input_bip3_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt4_: input_bip4_train[:, 0:train_loss_size, :], input_filt5_: input_bip5_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt6_: input_bip6_train[:, 0:train_loss_size, :], input_filt7_: input_bip7_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt8_: input_bip8_train[:, 0:train_loss_size, :], input_filt9_: input_bip9_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt10_: input_bip10_train[:, 0:train_loss_size, :], input_filt11_: input_bip11_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt12_: input_bip12_train[:, 0:train_loss_size, :], input_filt13_: input_bip13_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt14_: input_bip14_train[:, 0:train_loss_size, :], input_filt15_: input_bip15_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt16_: input_bip16_train[:, 0:train_loss_size, :], y_:y_train[0:train_loss_size, :, :]}\n",
    "\n",
    "singlefd={batchsize_: 32, input_filt1_: input_bip1_train[:, 0:32, :], \\\n",
    "          input_filt2_: input_bip2_train[:, 0:32, :], input_filt3_: input_bip3_train[:, 0:32, :],\\\n",
    "          input_filt4_: input_bip4_train[:, 0:32, :], input_filt5_: input_bip5_train[:, 0:32, :],\\\n",
    "          input_filt6_: input_bip6_train[:, 0:32, :], input_filt7_: input_bip7_train[:, 0:32, :],\\\n",
    "          input_filt8_: input_bip8_train[:, 0:32, :], input_filt9_: input_bip9_train[:, 0:32, :],\\\n",
    "          input_filt10_: input_bip10_train[:, 0:32, :], input_filt11_: input_bip11_train[:, 0:32, :],\\\n",
    "          input_filt12_: input_bip12_train[:, 0:32, :], input_filt13_: input_bip13_train[:, 0:32, :],\\\n",
    "          input_filt14_: input_bip14_train[:, 0:32, :], input_filt15_: input_bip15_train[:, 0:32, :],\\\n",
    "          input_filt16_: input_bip16_train[:, 0:32, :], y_:y_train[0:32, :, :]}\n",
    "\n",
    "\n",
    "batchsize= 32\n",
    "\n",
    "# L2 loss (normalized)\n",
    "loss = (tf.nn.l2_loss((output - y_), name='loss'))/(batchsize*data_duration) \n",
    "single_loss = tf.reduce_sum((abs(output - y_))/(batchsize*data_duration), 1)\n",
    "\n",
    "# L1 regularization on weights and output\n",
    "reg1 = tf.add_n([tf.reduce_sum(tf.abs(bip1_gc_syn)), tf.reduce_sum(tf.abs(bip2_gc_syn)),  tf.reduce_sum(tf.abs(bip11_gc_syn))])\n",
    "reg2 = tf.add_n([tf.reduce_sum(tf.abs(bip1_copy_gc_syn)), tf.reduce_sum(tf.abs(bip2_copy_gc_syn)), tf.reduce_sum(tf.abs(bip11_copy_gc_syn))])\n",
    "reg3 = tf.add_n([tf.reduce_sum(tf.abs(bip1_am1_syn)), tf.reduce_sum(tf.abs(bip2_am1_syn)), tf.reduce_sum(tf.abs(bip11_am1_syn))])\n",
    "reg5 = tf.add_n([tf.reduce_sum(tf.abs(am1_gc_syn))])\n",
    "reg6 = tf.add_n([tf.reduce_sum(tf.abs(am1_b1copy_syn)), tf.reduce_sum(tf.abs(am1_b2copy_syn))])\n",
    "reg7 = 1e-4*tf.reduce_sum(tf.abs(output))\n",
    "# regularizer=tf.add_n([reg1, reg2, reg3, reg5, reg6, reg7])\n",
    "regularizer=tf.add_n([reg1, reg3, reg5])\n",
    "\n",
    "\n",
    "\n",
    "# lambda1=1e-1 \n",
    "lambda1=1e1 \n",
    "\n",
    "objective=tf.add(loss, lambda1*regularizer)\n",
    "\n",
    "algorithm_choice=2  #1\n",
    "\n",
    "if algorithm_choice==1:\n",
    "    train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(objective)\n",
    "elif algorithm_choice==2:\n",
    "    my_epsilon=1e-4 #1e-8\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=learn_rate, epsilon=my_epsilon).minimize(objective)\n",
    "elif algorithm_choice==3:\n",
    "    momentum_par=0.9\n",
    "    train_step = tf.train.MomentumOptimizer(learn_rate, momentum_par).minimize(objective)\n",
    "elif algorithm_choice==4:\n",
    "    train_step = tf.train.AdagradOptimizer(learn_rate).minimize(objective)\n",
    "elif algorithm_choice==5:\n",
    "    train_step = tf.train.RMSPropOptimizer(learn_rate).minimize(objective)\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialize arrays to store weight histories\n",
    "\n",
    "f1b1_syn_hist=tf.reshape(f1b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f2b1_syn_hist=tf.reshape(f2b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f3b1_syn_hist=tf.reshape(f3b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f4b1_syn_hist=tf.reshape(f4b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f5b1_syn_hist=tf.reshape(f5b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f6b1_syn_hist=tf.reshape(f6b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f7b1_syn_hist=tf.reshape(f7b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f8b1_syn_hist=tf.reshape(f8b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f9b1_syn_hist=tf.reshape(f9b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f10b1_syn_hist=tf.reshape(f10b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f11b1_syn_hist=tf.reshape(f11b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f12b1_syn_hist=tf.reshape(f12b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f13b1_syn_hist=tf.reshape(f13b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f14b1_syn_hist=tf.reshape(f14b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f15b1_syn_hist=tf.reshape(f15b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f16b1_syn_hist=tf.reshape(f16b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "\n",
    "f1b2_syn_hist=tf.reshape(f1b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f2b2_syn_hist=tf.reshape(f2b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f3b2_syn_hist=tf.reshape(f3b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f4b2_syn_hist=tf.reshape(f4b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f5b2_syn_hist=tf.reshape(f5b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f6b2_syn_hist=tf.reshape(f6b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f7b2_syn_hist=tf.reshape(f7b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f8b2_syn_hist=tf.reshape(f8b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f9b2_syn_hist=tf.reshape(f9b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f10b2_syn_hist=tf.reshape(f10b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f11b2_syn_hist=tf.reshape(f11b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f12b2_syn_hist=tf.reshape(f12b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f13b2_syn_hist=tf.reshape(f13b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f14b2_syn_hist=tf.reshape(f14b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f15b2_syn_hist=tf.reshape(f15b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f16b2_syn_hist=tf.reshape(f16b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "\n",
    "f1b11_syn_hist=tf.reshape(f1b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f2b11_syn_hist=tf.reshape(f2b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f3b11_syn_hist=tf.reshape(f3b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f4b11_syn_hist=tf.reshape(f4b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f5b11_syn_hist=tf.reshape(f5b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f6b11_syn_hist=tf.reshape(f6b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f7b11_syn_hist=tf.reshape(f7b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f8b11_syn_hist=tf.reshape(f8b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f9b11_syn_hist=tf.reshape(f9b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f10b11_syn_hist=tf.reshape(f10b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f11b11_syn_hist=tf.reshape(f11b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f12b11_syn_hist=tf.reshape(f12b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f13b11_syn_hist=tf.reshape(f13b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f14b11_syn_hist=tf.reshape(f14b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f15b11_syn_hist=tf.reshape(f15b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f16b11_syn_hist=tf.reshape(f16b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "\n",
    "bip1_gc_syn_hist=tf.reshape(bip1_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip2_gc_syn_hist=tf.reshape(bip2_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip11_gc_syn_hist=tf.reshape(bip11_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "\n",
    "\n",
    "bip1_copy_gc_syn_hist=tf.reshape(bip1_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip2_copy_gc_syn_hist=tf.reshape(bip2_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip11_copy_gc_syn_hist=tf.reshape(bip11_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "\n",
    "\n",
    "b1_bias_hist=tf.reshape(b1_bias.eval(session=sess), [1, no_bipolars])\n",
    "b2_bias_hist=tf.reshape(b2_bias.eval(session=sess), [1, no_bipolars])\n",
    "b11_bias_hist=tf.reshape(b11_bias.eval(session=sess), [1, no_bipolars])\n",
    "\n",
    "\n",
    "am1_bias_hist=tf.reshape(am1_bias.eval(session=sess), [1, no_am1])\n",
    "gc_bias_hist=tf.reshape(gc_bias.eval(session=sess), [1, no_gc])\n",
    "\n",
    "gc_stretch_hist=tf.reshape(gc_stretch.eval(session=sess), [1, no_gc])\n",
    "\n",
    "bip1_am1_syn_hist=tf.reshape(bip1_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])\n",
    "bip2_am1_syn_hist=tf.reshape(bip2_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])\n",
    "bip11_am1_syn_hist=tf.reshape(bip11_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])\n",
    "\n",
    "am1_b1copy_syn_hist=tf.reshape(am1_b1copy_syn.eval(session=sess), [1, no_am1, no_bipolars])\n",
    "am1_b2copy_syn_hist=tf.reshape(am1_b2copy_syn.eval(session=sess), [1, no_am1, no_bipolars])\n",
    "\n",
    "am1_gc_syn_hist=tf.reshape(am1_gc_syn.eval(session=sess), [1, no_am1, no_gc])\n",
    "\n",
    "output_hist=tf.reshape(output.eval(session=sess, feed_dict=singlefd), [1, 32, data_duration])\n",
    "\n",
    "#loss\n",
    "loss_hist = ones([1])\n",
    "valid_hist = ones([1])\n",
    "test_hist = ones([1])\n",
    "\n",
    "\n",
    "check=1.0\n",
    "step=0\n",
    "end_flag=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137.3980994591346\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE LOSS AT ANN INITIALIZATION\n",
    "\n",
    "loss_val = (batchsize/78.0)*sess.run(loss, feed_dict= trainsampfd)\n",
    "print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# INITIALIZE LOSS HISTORIES\n",
    "\n",
    "fddd={batchsize_: no_data_test, input_filt1_: input_bip1_test, \\\n",
    "          input_filt2_: input_bip2_test, input_filt3_: input_bip3_test,\\\n",
    "          input_filt4_: input_bip4_test, input_filt5_: input_bip5_test,\\\n",
    "          input_filt6_: input_bip6_test, input_filt7_: input_bip7_test,\\\n",
    "          input_filt8_: input_bip8_test, input_filt9_: input_bip9_test,\\\n",
    "          input_filt10_: input_bip10_test, input_filt11_: input_bip11_test,\\\n",
    "          input_filt12_: input_bip12_test, input_filt13_: input_bip13_test,\\\n",
    "          input_filt14_: input_bip14_test, input_filt15_: input_bip15_test,\\\n",
    "          input_filt16_: input_bip16_test, y_:y_test}\n",
    "\n",
    "test_loss = (batchsize/input_bip1_test.shape[1])*sess.run(loss, feed_dict=fddd)\n",
    "\n",
    "loss_hist=loss_val*loss_hist\n",
    "test_hist=test_loss*test_hist\n",
    "\n",
    "batch_loss_hist=np.zeros([1])\n",
    "batch_loss_hist=batch_loss_hist.astype(float32)\n",
    "L1_hist=np.zeros([1])\n",
    "L1_hist=L1_hist.astype(float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  loss: = 187.272568 \n",
      "\n",
      "step: 1  loss: = 177.636826 \n",
      "\n",
      "step: 2  loss: = 175.643753 \n",
      "\n",
      "step: 3  loss: = 173.181244 \n",
      "\n",
      "step: 4  loss: = 172.133118 \n",
      "\n",
      "step: 5  loss: = 170.310486 \n",
      "\n",
      "step: 6  loss: = 167.509125 \n",
      "\n",
      "step: 7  loss: = 164.698776 \n",
      "\n",
      "step: 8  loss: = 164.228592 \n",
      "\n",
      "step: 9  loss: = 163.302841 \n",
      "\n",
      "step: 10  loss: = 160.975723 \n",
      "\n",
      "step: 11  loss: = 160.738922 \n",
      "\n",
      "step: 12  loss: = 159.968552 \n",
      "\n",
      "step: 13  loss: = 159.190323 \n",
      "\n",
      "step: 14  loss: = 158.973953 \n",
      "\n",
      "step: 15  loss: = 157.980423 \n",
      "\n",
      "step: 16  loss: = 157.551514 \n",
      "\n",
      "step: 17  loss: = 157.129959 \n",
      "\n",
      "step: 18  loss: = 155.852036 \n",
      "\n",
      "step: 19  loss: = 155.783615 \n",
      "\n",
      "step: 20  loss: = 156.134460 \n",
      "\n",
      "step: 21  loss: = 155.293411 \n",
      "\n",
      "step: 22  loss: = 155.718216 \n",
      "\n",
      "step: 23  loss: = 154.957581 \n",
      "\n",
      "step: 24  loss: = 155.054703 \n",
      "\n",
      "step: 25  loss: = 154.385147 \n",
      "\n",
      "step: 26  loss: = 154.837311 \n",
      "\n",
      "step: 27  loss: = 153.896286 \n",
      "\n",
      "step: 28  loss: = 155.392258 \n",
      "\n",
      "step: 29  loss: = 154.026901 \n",
      "\n",
      "step: 30  loss: = 153.712814 \n",
      "\n",
      "step: 31  loss: = 153.015778 \n",
      "\n",
      "step: 32  loss: = 152.902405 \n",
      "\n",
      "step: 33  loss: = 153.061539 \n",
      "\n",
      "step: 34  loss: = 152.938202 \n",
      "\n",
      "step: 35  loss: = 152.192490 \n",
      "\n",
      "step: 36  loss: = 152.743759 \n",
      "\n",
      "step: 37  loss: = 151.995453 \n",
      "\n",
      "step: 38  loss: = 151.352280 \n",
      "\n",
      "step: 39  loss: = 151.487579 \n",
      "\n",
      "step: 40  loss: = 154.353943 \n",
      "\n",
      "step: 41  loss: = 151.192703 \n",
      "\n",
      "step: 42  loss: = 151.709473 \n",
      "\n",
      "step: 43  loss: = 150.841232 \n",
      "\n",
      "step: 44  loss: = 151.220490 \n",
      "\n",
      "step: 45  loss: = 152.148483 \n",
      "\n",
      "step: 46  loss: = 152.055878 \n",
      "\n",
      "step: 47  loss: = 149.924713 \n",
      "\n",
      "step: 48  loss: = 150.169266 \n",
      "\n",
      "step: 49  loss: = 150.845535 \n",
      "\n",
      "step: 50  loss: = 151.262863 \n",
      "\n",
      "step: 51  loss: = 150.206924 \n",
      "\n",
      "step: 52  loss: = 149.902740 \n",
      "\n",
      "step: 53  loss: = 149.058075 \n",
      "\n",
      "step: 54  loss: = 149.651703 \n",
      "\n",
      "step: 55  loss: = 150.680939 \n",
      "\n",
      "step: 56  loss: = 149.946182 \n",
      "\n",
      "step: 57  loss: = 148.778290 \n",
      "\n",
      "step: 58  loss: = 149.167328 \n",
      "\n",
      "step: 59  loss: = 149.235443 \n",
      "\n",
      "step: 60  loss: = 149.129120 \n",
      "\n",
      "step: 61  loss: = 149.906631 \n",
      "\n",
      "step: 62  loss: = 149.076111 \n",
      "\n",
      "step: 63  loss: = 150.048355 \n",
      "\n",
      "step: 64  loss: = 149.955780 \n",
      "\n",
      "step: 65  loss: = 148.814087 \n",
      "\n",
      "step: 66  loss: = 148.348740 \n",
      "\n",
      "step: 67  loss: = 148.411270 \n",
      "\n",
      "step: 68  loss: = 149.067642 \n",
      "\n",
      "step: 69  loss: = 148.479980 \n",
      "\n",
      "step: 70  loss: = 148.686844 \n",
      "\n",
      "step: 71  loss: = 148.057388 \n",
      "\n",
      "step: 72  loss: = 148.199722 \n",
      "\n",
      "step: 73  loss: = 148.285324 \n",
      "\n",
      "step: 74  loss: = 148.532898 \n",
      "\n",
      "step: 75  loss: = 147.392502 \n",
      "\n",
      "step: 76  loss: = 147.661652 \n",
      "\n",
      "step: 77  loss: = 148.639328 \n",
      "\n",
      "step: 78  loss: = 148.395203 \n",
      "\n",
      "step: 79  loss: = 148.881882 \n",
      "\n",
      "step: 80  loss: = 148.125122 \n",
      "\n",
      "step: 81  loss: = 147.104797 \n",
      "\n",
      "step: 82  loss: = 148.183395 \n",
      "\n",
      "step: 83  loss: = 146.902267 \n",
      "\n",
      "step: 84  loss: = 147.337387 \n",
      "\n",
      "step: 85  loss: = 147.606796 \n",
      "\n",
      "step: 86  loss: = 148.284653 \n",
      "\n",
      "step: 87  loss: = 148.804443 \n",
      "\n",
      "step: 88  loss: = 148.325974 \n",
      "\n",
      "step: 89  loss: = 147.662277 \n",
      "\n",
      "step: 90  loss: = 146.838837 \n",
      "\n",
      "step: 91  loss: = 147.068909 \n",
      "\n",
      "step: 92  loss: = 147.915176 \n",
      "\n",
      "step: 93  loss: = 147.071533 \n",
      "\n",
      "step: 94  loss: = 146.495087 \n",
      "\n",
      "step: 95  loss: = 149.347168 \n",
      "\n",
      "step: 96  loss: = 146.645386 \n",
      "\n",
      "step: 97  loss: = 147.175949 \n",
      "\n",
      "step: 98  loss: = 147.337677 \n",
      "\n",
      "step: 99  loss: = 146.475372 \n",
      "\n",
      "step: 100  loss: = 146.612000 \n",
      "\n",
      "step: 101  loss: = 147.821472 \n",
      "\n",
      "step: 102  loss: = 146.247894 \n",
      "\n",
      "step: 103  loss: = 146.349304 \n",
      "\n",
      "step: 104  loss: = 146.800262 \n",
      "\n",
      "step: 105  loss: = 146.799759 \n",
      "\n",
      "step: 106  loss: = 147.847244 \n",
      "\n",
      "step: 107  loss: = 146.869324 \n",
      "\n",
      "step: 108  loss: = 146.764404 \n",
      "\n",
      "step: 109  loss: = 147.588821 \n",
      "\n",
      "step: 110  loss: = 146.366180 \n",
      "\n",
      "step: 111  loss: = 146.550247 \n",
      "\n",
      "step: 112  loss: = 146.102844 \n",
      "\n",
      "step: 113  loss: = 148.171783 \n",
      "\n",
      "step: 114  loss: = 146.864410 \n",
      "\n",
      "step: 115  loss: = 146.466324 \n",
      "\n",
      "step: 116  loss: = 147.225479 \n",
      "\n",
      "step: 117  loss: = 146.231720 \n",
      "\n",
      "step: 118  loss: = 145.783218 \n",
      "\n",
      "step: 119  loss: = 146.669312 \n",
      "\n",
      "step: 120  loss: = 147.534958 \n",
      "\n",
      "step: 121  loss: = 146.875824 \n",
      "\n",
      "step: 122  loss: = 148.325470 \n",
      "\n",
      "step: 123  loss: = 146.386551 \n",
      "\n",
      "step: 124  loss: = 146.905472 \n",
      "\n",
      "step: 125  loss: = 145.653061 \n",
      "\n",
      "step: 126  loss: = 145.832245 \n",
      "\n",
      "step: 127  loss: = 147.373749 \n",
      "\n",
      "step: 128  loss: = 145.469971 \n",
      "\n",
      "step: 129  loss: = 147.168167 \n",
      "\n",
      "step: 130  loss: = 146.173981 \n",
      "\n",
      "step: 131  loss: = 146.687561 \n",
      "\n",
      "step: 132  loss: = 146.195755 \n",
      "\n",
      "step: 133  loss: = 146.530533 \n",
      "\n",
      "step: 134  loss: = 146.413956 \n",
      "\n",
      "step: 135  loss: = 146.301086 \n",
      "\n",
      "step: 136  loss: = 147.573837 \n",
      "\n",
      "step: 137  loss: = 145.497192 \n",
      "\n",
      "step: 138  loss: = 145.705551 \n",
      "\n",
      "step: 139  loss: = 146.331909 \n",
      "\n",
      "step: 140  loss: = 145.552597 \n",
      "\n",
      "step: 141  loss: = 145.747955 \n",
      "\n",
      "step: 142  loss: = 145.741440 \n",
      "\n",
      "step: 143  loss: = 145.796661 \n",
      "\n",
      "step: 144  loss: = 145.304428 \n",
      "\n",
      "step: 145  loss: = 146.408966 \n",
      "\n",
      "step: 146  loss: = 145.262192 \n",
      "\n",
      "step: 147  loss: = 145.422165 \n",
      "\n",
      "step: 148  loss: = 146.580780 \n",
      "\n",
      "step: 149  loss: = 145.794388 \n",
      "\n",
      "step: 150  loss: = 146.820831 \n",
      "\n",
      "step: 151  loss: = 145.274521 \n",
      "\n",
      "step: 152  loss: = 145.615326 \n",
      "\n",
      "step: 153  loss: = 145.513107 \n",
      "\n",
      "step: 154  loss: = 145.956345 \n",
      "\n",
      "step: 155  loss: = 144.536057 \n",
      "\n",
      "step: 156  loss: = 145.134628 \n",
      "\n",
      "step: 157  loss: = 146.401535 \n",
      "\n",
      "step: 158  loss: = 148.423859 \n",
      "\n",
      "step: 159  loss: = 145.039673 \n",
      "\n",
      "step: 160  loss: = 145.704041 \n",
      "\n",
      "step: 161  loss: = 146.100922 \n",
      "\n",
      "step: 162  loss: = 144.733902 \n",
      "\n",
      "step: 163  loss: = 145.683151 \n",
      "\n",
      "step: 164  loss: = 146.776474 \n",
      "\n",
      "step: 165  loss: = 145.701782 \n",
      "\n",
      "step: 166  loss: = 145.415482 \n",
      "\n",
      "step: 167  loss: = 144.614365 \n",
      "\n",
      "step: 168  loss: = 145.208557 \n",
      "\n",
      "step: 169  loss: = 145.327850 \n",
      "\n",
      "step: 170  loss: = 145.276260 \n",
      "\n",
      "step: 171  loss: = 145.116714 \n",
      "\n",
      "step: 172  loss: = 144.952042 \n",
      "\n",
      "step: 173  loss: = 145.856476 \n",
      "\n",
      "step: 174  loss: = 146.138687 \n",
      "\n",
      "step: 175  loss: = 145.495728 \n",
      "\n",
      "step: 176  loss: = 145.725906 \n",
      "\n",
      "step: 177  loss: = 145.414093 \n",
      "\n",
      "step: 178  loss: = 145.910736 \n",
      "\n",
      "step: 179  loss: = 144.768723 \n",
      "\n",
      "step: 180  loss: = 147.186203 \n",
      "\n",
      "step: 181  loss: = 145.641129 \n",
      "\n",
      "step: 182  loss: = 145.865662 \n",
      "\n",
      "step: 183  loss: = 144.649994 \n",
      "\n",
      "step: 184  loss: = 144.301422 \n",
      "\n",
      "step: 185  loss: = 144.991852 \n",
      "\n",
      "step: 186  loss: = 145.074661 \n",
      "\n",
      "step: 187  loss: = 144.366547 \n",
      "\n",
      "step: 188  loss: = 144.655533 \n",
      "\n",
      "step: 189  loss: = 145.728119 \n",
      "\n",
      "step: 190  loss: = 145.975250 \n",
      "\n",
      "step: 191  loss: = 145.204865 \n",
      "\n",
      "step: 192  loss: = 145.339462 \n",
      "\n",
      "step: 193  loss: = 145.102921 \n",
      "\n",
      "step: 194  loss: = 145.275864 \n",
      "\n",
      "step: 195  loss: = 144.467789 \n",
      "\n",
      "step: 196  loss: = 144.951477 \n",
      "\n",
      "step: 197  loss: = 145.821945 \n",
      "\n",
      "step: 198  loss: = 146.038330 \n",
      "\n",
      "step: 199  loss: = 145.332535 \n",
      "\n",
      "step: 200  loss: = 146.297379 \n",
      "\n",
      "step: 201  loss: = 146.607788 \n",
      "\n",
      "step: 202  loss: = 145.566574 \n",
      "\n",
      "step: 203  loss: = 147.200348 \n",
      "\n",
      "step: 204  loss: = 145.643036 \n",
      "\n",
      "step: 205  loss: = 145.613724 \n",
      "\n",
      "step: 206  loss: = 144.983719 \n",
      "\n",
      "step: 207  loss: = 144.749588 \n",
      "\n",
      "step: 208  loss: = 145.438766 \n",
      "\n",
      "step: 209  loss: = 144.546616 \n",
      "\n",
      "step: 210  loss: = 144.645157 \n",
      "\n",
      "step: 211  loss: = 145.272614 \n",
      "\n",
      "step: 212  loss: = 145.055923 \n",
      "\n",
      "step: 213  loss: = 145.048325 \n",
      "\n",
      "step: 214  loss: = 146.198669 \n",
      "\n",
      "step: 215  loss: = 144.346664 \n",
      "\n",
      "step: 216  loss: = 145.370438 \n",
      "\n",
      "step: 217  loss: = 146.140503 \n",
      "\n",
      "step: 218  loss: = 144.669785 \n",
      "\n",
      "step: 219  loss: = 146.353882 \n",
      "\n",
      "step: 220  loss: = 144.265625 \n",
      "\n",
      "step: 221  loss: = 144.406464 \n",
      "\n",
      "step: 222  loss: = 145.068817 \n",
      "\n",
      "step: 223  loss: = 145.169159 \n",
      "\n",
      "step: 224  loss: = 144.519226 \n",
      "\n",
      "step: 225  loss: = 144.799103 \n",
      "\n",
      "step: 226  loss: = 144.307953 \n",
      "\n",
      "step: 227  loss: = 145.141922 \n",
      "\n",
      "step: 228  loss: = 145.624710 \n",
      "\n",
      "step: 229  loss: = 144.670303 \n",
      "\n",
      "step: 230  loss: = 144.941574 \n",
      "\n",
      "step: 231  loss: = 144.442047 \n",
      "\n",
      "step: 232  loss: = 144.298264 \n",
      "\n",
      "step: 233  loss: = 144.697632 \n",
      "\n",
      "step: 234  loss: = 144.768082 \n",
      "\n",
      "step: 235  loss: = 144.540176 \n",
      "\n",
      "step: 236  loss: = 144.603836 \n",
      "\n",
      "step: 237  loss: = 144.511276 \n",
      "\n",
      "step: 238  loss: = 144.876099 \n",
      "\n",
      "step: 239  loss: = 144.953873 \n",
      "\n",
      "step: 240  loss: = 145.315598 \n",
      "\n",
      "step: 241  loss: = 147.905884 \n",
      "\n",
      "step: 242  loss: = 144.557709 \n",
      "\n",
      "step: 243  loss: = 144.261230 \n",
      "\n",
      "step: 244  loss: = 145.527557 \n",
      "\n",
      "step: 245  loss: = 144.460861 \n",
      "\n",
      "step: 246  loss: = 144.963837 \n",
      "\n",
      "step: 247  loss: = 144.917618 \n",
      "\n",
      "step: 248  loss: = 144.781784 \n",
      "\n",
      "step: 249  loss: = 144.707382 \n",
      "\n",
      "step: 250  loss: = 144.815903 \n",
      "\n",
      "step: 251  loss: = 146.255554 \n",
      "\n",
      "step: 252  loss: = 145.792267 \n",
      "\n",
      "step: 253  loss: = 144.488480 \n",
      "\n",
      "step: 254  loss: = 144.370529 \n",
      "\n",
      "step: 255  loss: = 144.465744 \n",
      "\n",
      "step: 256  loss: = 144.705109 \n",
      "\n",
      "step: 257  loss: = 145.564011 \n",
      "\n",
      "step: 258  loss: = 146.372543 \n",
      "\n",
      "step: 259  loss: = 145.138824 \n",
      "\n",
      "step: 260  loss: = 144.506943 \n",
      "\n",
      "step: 261  loss: = 144.263641 \n",
      "\n",
      "step: 262  loss: = 145.802582 \n",
      "\n",
      "step: 263  loss: = 144.523331 \n",
      "\n",
      "step: 264  loss: = 145.959564 \n",
      "\n",
      "step: 265  loss: = 144.785675 \n",
      "\n",
      "step: 266  loss: = 144.666412 \n",
      "\n",
      "step: 267  loss: = 145.160126 \n",
      "\n",
      "step: 268  loss: = 144.888214 \n",
      "\n",
      "step: 269  loss: = 144.978256 \n",
      "\n",
      "step: 270  loss: = 143.955399 \n",
      "\n",
      "step: 271  loss: = 144.202957 \n",
      "\n",
      "step: 272  loss: = 146.476593 \n",
      "\n",
      "step: 273  loss: = 143.704529 \n",
      "\n",
      "step: 274  loss: = 144.627243 \n",
      "\n",
      "step: 275  loss: = 144.579407 \n",
      "\n",
      "step: 276  loss: = 144.535751 \n",
      "\n",
      "step: 277  loss: = 145.152969 \n",
      "\n",
      "step: 278  loss: = 145.060959 \n",
      "\n",
      "step: 279  loss: = 144.551147 \n",
      "\n",
      "step: 280  loss: = 145.652634 \n",
      "\n",
      "step: 281  loss: = 144.733215 \n",
      "\n",
      "step: 282  loss: = 144.634811 \n",
      "\n",
      "step: 283  loss: = 144.974792 \n",
      "\n",
      "step: 284  loss: = 143.924973 \n",
      "\n",
      "step: 285  loss: = 144.765457 \n",
      "\n",
      "step: 286  loss: = 144.789429 \n",
      "\n",
      "step: 287  loss: = 144.578690 \n",
      "\n",
      "step: 288  loss: = 144.101990 \n",
      "\n",
      "step: 289  loss: = 145.973007 \n",
      "\n",
      "step: 290  loss: = 144.753433 \n",
      "\n",
      "step: 291  loss: = 145.239014 \n",
      "\n",
      "step: 292  loss: = 144.352615 \n",
      "\n",
      "step: 293  loss: = 144.895920 \n",
      "\n",
      "step: 294  loss: = 147.228439 \n",
      "\n",
      "step: 295  loss: = 143.966324 \n",
      "\n",
      "step: 296  loss: = 144.441635 \n",
      "\n",
      "step: 297  loss: = 145.170090 \n",
      "\n",
      "step: 298  loss: = 144.036682 \n",
      "\n",
      "step: 299  loss: = 144.086243 \n",
      "\n",
      "step: 300  loss: = 144.330429 \n",
      "\n",
      "step: 301  loss: = 144.881470 \n",
      "\n",
      "step: 302  loss: = 144.579620 \n",
      "\n",
      "step: 303  loss: = 144.395599 \n",
      "\n",
      "step: 304  loss: = 144.622437 \n",
      "\n",
      "step: 305  loss: = 144.251801 \n",
      "\n",
      "step: 306  loss: = 144.245300 \n",
      "\n",
      "step: 307  loss: = 144.792160 \n",
      "\n",
      "step: 308  loss: = 146.945892 \n",
      "\n",
      "step: 309  loss: = 143.643753 \n",
      "\n",
      "step: 310  loss: = 144.985886 \n",
      "\n",
      "step: 311  loss: = 144.256256 \n",
      "\n",
      "step: 312  loss: = 144.469879 \n",
      "\n",
      "step: 313  loss: = 144.832047 \n",
      "\n",
      "step: 314  loss: = 145.049377 \n",
      "\n",
      "step: 315  loss: = 144.428253 \n",
      "\n",
      "step: 316  loss: = 144.574493 \n",
      "\n",
      "step: 317  loss: = 146.166519 \n",
      "\n",
      "step: 318  loss: = 144.660690 \n",
      "\n",
      "step: 319  loss: = 145.368622 \n",
      "\n",
      "step: 320  loss: = 145.674530 \n",
      "\n",
      "step: 321  loss: = 144.335388 \n",
      "\n",
      "step: 322  loss: = 144.628494 \n",
      "\n",
      "step: 323  loss: = 145.071686 \n",
      "\n",
      "step: 324  loss: = 144.283173 \n",
      "\n",
      "step: 325  loss: = 143.956024 \n",
      "\n",
      "step: 326  loss: = 144.477936 \n",
      "\n",
      "step: 327  loss: = 144.375320 \n",
      "\n",
      "step: 328  loss: = 144.722031 \n",
      "\n",
      "step: 329  loss: = 144.391464 \n",
      "\n",
      "step: 330  loss: = 143.869659 \n",
      "\n",
      "step: 331  loss: = 144.579636 \n",
      "\n",
      "step: 332  loss: = 144.946747 \n",
      "\n",
      "step: 333  loss: = 144.061966 \n",
      "\n",
      "step: 334  loss: = 144.818527 \n",
      "\n",
      "step: 335  loss: = 144.744904 \n",
      "\n",
      "step: 336  loss: = 144.214935 \n",
      "\n",
      "step: 337  loss: = 146.384338 \n",
      "\n",
      "step: 338  loss: = 144.929413 \n",
      "\n",
      "step: 339  loss: = 144.450653 \n",
      "\n",
      "step: 340  loss: = 145.074203 \n",
      "\n",
      "step: 341  loss: = 144.510452 \n",
      "\n",
      "step: 342  loss: = 143.606354 \n",
      "\n",
      "step: 343  loss: = 144.241852 \n",
      "\n",
      "step: 344  loss: = 144.374710 \n",
      "\n",
      "step: 345  loss: = 145.059494 \n",
      "\n",
      "step: 346  loss: = 145.228912 \n",
      "\n",
      "step: 347  loss: = 144.761963 \n",
      "\n",
      "step: 348  loss: = 145.748734 \n",
      "\n",
      "step: 349  loss: = 146.498062 \n",
      "\n",
      "step: 350  loss: = 144.613983 \n",
      "\n",
      "step: 351  loss: = 144.718445 \n",
      "\n",
      "step: 352  loss: = 144.098099 \n",
      "\n",
      "step: 353  loss: = 143.756851 \n",
      "\n",
      "step: 354  loss: = 144.139587 \n",
      "\n",
      "step: 355  loss: = 144.404831 \n",
      "\n",
      "step: 356  loss: = 145.210022 \n",
      "\n",
      "step: 357  loss: = 144.619888 \n",
      "\n",
      "step: 358  loss: = 144.312057 \n",
      "\n",
      "step: 359  loss: = 144.471573 \n",
      "\n",
      "step: 360  loss: = 146.063324 \n",
      "\n",
      "step: 361  loss: = 143.798203 \n",
      "\n",
      "step: 362  loss: = 146.210388 \n",
      "\n",
      "step: 363  loss: = 144.428879 \n",
      "\n",
      "step: 364  loss: = 143.617081 \n",
      "\n",
      "step: 365  loss: = 144.398773 \n",
      "\n",
      "step: 366  loss: = 143.957367 \n",
      "\n",
      "step: 367  loss: = 144.177917 \n",
      "\n",
      "step: 368  loss: = 144.664078 \n",
      "\n",
      "step: 369  loss: = 144.850815 \n",
      "\n",
      "step: 370  loss: = 143.874847 \n",
      "\n",
      "step: 371  loss: = 144.796356 \n",
      "\n",
      "step: 372  loss: = 145.129471 \n",
      "\n",
      "step: 373  loss: = 144.737442 \n",
      "\n",
      "step: 374  loss: = 145.029572 \n",
      "\n",
      "step: 375  loss: = 145.271957 \n",
      "\n",
      "step: 376  loss: = 143.912979 \n",
      "\n",
      "step: 377  loss: = 146.935196 \n",
      "\n",
      "step: 378  loss: = 144.085587 \n",
      "\n",
      "step: 379  loss: = 143.524277 \n",
      "\n",
      "step: 380  loss: = 144.205017 \n",
      "\n",
      "step: 381  loss: = 143.843674 \n",
      "\n",
      "step: 382  loss: = 144.165588 \n",
      "\n",
      "step: 383  loss: = 144.438446 \n",
      "\n",
      "step: 384  loss: = 144.156860 \n",
      "\n",
      "step: 385  loss: = 143.595505 \n",
      "\n",
      "step: 386  loss: = 146.196167 \n",
      "\n",
      "step: 387  loss: = 143.347961 \n",
      "\n",
      "step: 388  loss: = 143.321182 \n",
      "\n",
      "step: 389  loss: = 144.188263 \n",
      "\n",
      "step: 390  loss: = 144.189819 \n",
      "\n",
      "step: 391  loss: = 144.410309 \n",
      "\n",
      "step: 392  loss: = 145.165253 \n",
      "\n",
      "step: 393  loss: = 144.602493 \n",
      "\n",
      "step: 394  loss: = 145.968079 \n",
      "\n",
      "step: 395  loss: = 143.661652 \n",
      "\n",
      "step: 396  loss: = 145.130936 \n",
      "\n",
      "step: 397  loss: = 144.550812 \n",
      "\n",
      "step: 398  loss: = 144.504929 \n",
      "\n",
      "step: 399  loss: = 144.339584 \n",
      "\n",
      "step: 400  loss: = 145.940811 \n",
      "\n",
      "step: 401  loss: = 143.452499 \n",
      "\n",
      "step: 402  loss: = 145.087799 \n",
      "\n",
      "step: 403  loss: = 144.016983 \n",
      "\n",
      "step: 404  loss: = 143.655502 \n",
      "\n",
      "step: 405  loss: = 145.534821 \n",
      "\n",
      "step: 406  loss: = 143.985229 \n",
      "\n",
      "step: 407  loss: = 144.342621 \n",
      "\n",
      "step: 408  loss: = 144.244186 \n",
      "\n",
      "step: 409  loss: = 143.816589 \n",
      "\n",
      "step: 410  loss: = 145.208984 \n",
      "\n",
      "step: 411  loss: = 143.730560 \n",
      "\n",
      "step: 412  loss: = 143.847565 \n",
      "\n",
      "step: 413  loss: = 145.337936 \n",
      "\n",
      "step: 414  loss: = 145.673874 \n",
      "\n",
      "step: 415  loss: = 143.536850 \n",
      "\n",
      "step: 416  loss: = 144.192169 \n",
      "\n",
      "step: 417  loss: = 144.225830 \n",
      "\n",
      "step: 418  loss: = 143.920074 \n",
      "\n",
      "step: 419  loss: = 144.228149 \n",
      "\n",
      "step: 420  loss: = 143.676117 \n",
      "\n",
      "step: 421  loss: = 143.777237 \n",
      "\n",
      "step: 422  loss: = 144.790558 \n",
      "\n",
      "step: 423  loss: = 145.942261 \n",
      "\n",
      "step: 424  loss: = 144.331512 \n",
      "\n",
      "step: 425  loss: = 144.742325 \n",
      "\n",
      "step: 426  loss: = 143.452118 \n",
      "\n",
      "step: 427  loss: = 144.674759 \n",
      "\n",
      "step: 428  loss: = 143.474548 \n",
      "\n",
      "step: 429  loss: = 144.247635 \n",
      "\n",
      "step: 430  loss: = 145.266083 \n",
      "\n",
      "step: 431  loss: = 143.180725 \n",
      "\n",
      "step: 432  loss: = 145.294922 \n",
      "\n",
      "step: 433  loss: = 144.113937 \n",
      "\n",
      "step: 434  loss: = 143.901718 \n",
      "\n",
      "step: 435  loss: = 144.110611 \n",
      "\n",
      "step: 436  loss: = 143.484024 \n",
      "\n",
      "step: 437  loss: = 144.198257 \n",
      "\n",
      "step: 438  loss: = 144.509033 \n",
      "\n",
      "step: 439  loss: = 144.703445 \n",
      "\n",
      "step: 440  loss: = 144.629898 \n",
      "\n",
      "step: 441  loss: = 144.499695 \n",
      "\n",
      "step: 442  loss: = 144.346848 \n",
      "\n",
      "step: 443  loss: = 144.840439 \n",
      "\n",
      "step: 444  loss: = 144.005127 \n",
      "\n",
      "step: 445  loss: = 144.018188 \n",
      "\n",
      "step: 446  loss: = 143.833359 \n",
      "\n",
      "step: 447  loss: = 145.611923 \n",
      "\n",
      "step: 448  loss: = 143.195587 \n",
      "\n",
      "step: 449  loss: = 143.066223 \n",
      "\n",
      "step: 450  loss: = 145.200653 \n",
      "\n",
      "step: 451  loss: = 144.357132 \n",
      "\n",
      "step: 452  loss: = 144.191040 \n",
      "\n",
      "step: 453  loss: = 145.218994 \n",
      "\n",
      "step: 454  loss: = 143.506302 \n",
      "\n",
      "step: 455  loss: = 146.548004 \n",
      "\n",
      "step: 456  loss: = 143.980728 \n",
      "\n",
      "step: 457  loss: = 144.124084 \n",
      "\n",
      "step: 458  loss: = 143.882919 \n",
      "\n",
      "step: 459  loss: = 145.313705 \n",
      "\n",
      "step: 460  loss: = 144.088135 \n",
      "\n",
      "step: 461  loss: = 144.364075 \n",
      "\n",
      "step: 462  loss: = 144.369354 \n",
      "\n",
      "step: 463  loss: = 145.270660 \n",
      "\n",
      "step: 464  loss: = 144.763962 \n",
      "\n",
      "step: 465  loss: = 144.224243 \n",
      "\n",
      "step: 466  loss: = 144.164261 \n",
      "\n",
      "step: 467  loss: = 144.697479 \n",
      "\n",
      "step: 468  loss: = 143.386368 \n",
      "\n",
      "step: 469  loss: = 144.157013 \n",
      "\n",
      "step: 470  loss: = 144.744751 \n",
      "\n",
      "step: 471  loss: = 144.017624 \n",
      "\n",
      "step: 472  loss: = 144.196121 \n",
      "\n",
      "step: 473  loss: = 143.776382 \n",
      "\n",
      "step: 474  loss: = 144.137680 \n",
      "\n",
      "step: 475  loss: = 144.978348 \n",
      "\n",
      "step: 476  loss: = 145.249100 \n",
      "\n",
      "step: 477  loss: = 143.936707 \n",
      "\n",
      "step: 478  loss: = 144.425003 \n",
      "\n",
      "step: 479  loss: = 144.408981 \n",
      "\n",
      "step: 480  loss: = 144.533768 \n",
      "\n",
      "step: 481  loss: = 143.579010 \n",
      "\n",
      "step: 482  loss: = 144.807495 \n",
      "\n",
      "step: 483  loss: = 143.468582 \n",
      "\n",
      "step: 484  loss: = 143.106674 \n",
      "\n",
      "step: 485  loss: = 145.304794 \n",
      "\n",
      "step: 486  loss: = 143.940628 \n",
      "\n",
      "step: 487  loss: = 143.389389 \n",
      "\n",
      "step: 488  loss: = 143.714447 \n",
      "\n",
      "step: 489  loss: = 144.859375 \n",
      "\n",
      "step: 490  loss: = 144.180618 \n",
      "\n",
      "step: 491  loss: = 143.985992 \n",
      "\n",
      "step: 492  loss: = 144.532104 \n",
      "\n",
      "step: 493  loss: = 143.243088 \n",
      "\n",
      "step: 494  loss: = 144.005722 \n",
      "\n",
      "step: 495  loss: = 144.655746 \n",
      "\n",
      "step: 496  loss: = 145.052856 \n",
      "\n",
      "step: 497  loss: = 144.477432 \n",
      "\n",
      "step: 498  loss: = 143.234573 \n",
      "\n",
      "step: 499  loss: = 143.685226 \n",
      "\n",
      "step: 500  loss: = 144.954041 \n",
      "\n",
      "step: 501  loss: = 143.844162 \n",
      "\n",
      "step: 502  loss: = 143.261765 \n",
      "\n",
      "step: 503  loss: = 143.978668 \n",
      "\n",
      "step: 504  loss: = 143.658401 \n",
      "\n",
      "step: 505  loss: = 145.601837 \n",
      "\n",
      "step: 506  loss: = 144.017105 \n",
      "\n",
      "step: 507  loss: = 143.493439 \n",
      "\n",
      "step: 508  loss: = 143.776321 \n",
      "\n",
      "step: 509  loss: = 143.500702 \n",
      "\n",
      "step: 510  loss: = 143.569580 \n",
      "\n",
      "step: 511  loss: = 143.925446 \n",
      "\n",
      "step: 512  loss: = 144.736557 \n",
      "\n",
      "step: 513  loss: = 144.668869 \n",
      "\n",
      "step: 514  loss: = 144.760223 \n",
      "\n",
      "step: 515  loss: = 144.634644 \n",
      "\n",
      "step: 516  loss: = 144.823990 \n",
      "\n",
      "step: 517  loss: = 143.386871 \n",
      "\n",
      "step: 518  loss: = 144.375214 \n",
      "\n",
      "step: 519  loss: = 145.666885 \n",
      "\n",
      "step: 520  loss: = 143.285889 \n",
      "\n",
      "step: 521  loss: = 144.119751 \n",
      "\n",
      "step: 522  loss: = 143.497314 \n",
      "\n",
      "step: 523  loss: = 143.753860 \n",
      "\n",
      "step: 524  loss: = 144.846695 \n",
      "\n",
      "step: 525  loss: = 144.534073 \n",
      "\n",
      "step: 526  loss: = 144.400696 \n",
      "\n",
      "step: 527  loss: = 144.336365 \n",
      "\n",
      "step: 528  loss: = 144.541885 \n",
      "\n",
      "step: 529  loss: = 144.561066 \n",
      "\n",
      "step: 530  loss: = 144.253296 \n",
      "\n",
      "step: 531  loss: = 145.701141 \n",
      "\n",
      "step: 532  loss: = 144.536545 \n",
      "\n",
      "step: 533  loss: = 143.955582 \n",
      "\n",
      "step: 534  loss: = 144.478455 \n",
      "\n",
      "step: 535  loss: = 144.075333 \n",
      "\n",
      "step: 536  loss: = 143.207840 \n",
      "\n",
      "step: 537  loss: = 144.697540 \n",
      "\n",
      "step: 538  loss: = 144.027908 \n",
      "\n",
      "step: 539  loss: = 144.657089 \n",
      "\n",
      "step: 540  loss: = 144.217667 \n",
      "\n",
      "step: 541  loss: = 144.985214 \n",
      "\n",
      "step: 542  loss: = 144.587769 \n",
      "\n",
      "step: 543  loss: = 144.387299 \n",
      "\n",
      "step: 544  loss: = 143.789352 \n",
      "\n",
      "step: 545  loss: = 144.202332 \n",
      "\n",
      "step: 546  loss: = 144.394501 \n",
      "\n",
      "step: 547  loss: = 145.131302 \n",
      "\n",
      "step: 548  loss: = 143.926712 \n",
      "\n",
      "step: 549  loss: = 145.160675 \n",
      "\n",
      "step: 550  loss: = 146.624863 \n",
      "\n",
      "step: 551  loss: = 144.217041 \n",
      "\n",
      "step: 552  loss: = 143.680954 \n",
      "\n",
      "step: 553  loss: = 144.154236 \n",
      "\n",
      "step: 554  loss: = 143.931427 \n",
      "\n",
      "step: 555  loss: = 144.215332 \n",
      "\n",
      "step: 556  loss: = 144.059097 \n",
      "\n",
      "step: 557  loss: = 144.766602 \n",
      "\n",
      "step: 558  loss: = 144.013672 \n",
      "\n",
      "step: 559  loss: = 143.634918 \n",
      "\n",
      "step: 560  loss: = 143.203857 \n",
      "\n",
      "step: 561  loss: = 144.295502 \n",
      "\n",
      "step: 562  loss: = 144.902405 \n",
      "\n",
      "step: 563  loss: = 144.817261 \n",
      "\n",
      "step: 564  loss: = 143.455215 \n",
      "\n",
      "step: 565  loss: = 144.250214 \n",
      "\n",
      "step: 566  loss: = 144.139267 \n",
      "\n",
      "step: 567  loss: = 143.544861 \n",
      "\n",
      "step: 568  loss: = 144.179306 \n",
      "\n",
      "step: 569  loss: = 144.278030 \n",
      "\n",
      "step: 570  loss: = 143.722168 \n",
      "\n",
      "step: 571  loss: = 145.136993 \n",
      "\n",
      "step: 572  loss: = 143.861237 \n",
      "\n",
      "step: 573  loss: = 143.607712 \n",
      "\n",
      "step: 574  loss: = 144.353455 \n",
      "\n",
      "step: 575  loss: = 143.820648 \n",
      "\n",
      "step: 576  loss: = 143.915634 \n",
      "\n",
      "step: 577  loss: = 144.337677 \n",
      "\n",
      "step: 578  loss: = 145.921005 \n",
      "\n",
      "step: 579  loss: = 143.987656 \n",
      "\n",
      "step: 580  loss: = 143.853256 \n",
      "\n",
      "step: 581  loss: = 143.593155 \n",
      "\n",
      "step: 582  loss: = 145.232986 \n",
      "\n",
      "step: 583  loss: = 143.683502 \n",
      "\n",
      "step: 584  loss: = 143.973511 \n",
      "\n",
      "step: 585  loss: = 144.832108 \n",
      "\n",
      "step: 586  loss: = 143.087463 \n",
      "\n",
      "step: 587  loss: = 146.051926 \n",
      "\n",
      "step: 588  loss: = 144.750854 \n",
      "\n",
      "step: 589  loss: = 144.801193 \n",
      "\n",
      "step: 590  loss: = 143.731720 \n",
      "\n",
      "step: 591  loss: = 143.262222 \n",
      "\n",
      "step: 592  loss: = 143.653442 \n",
      "\n",
      "step: 593  loss: = 143.115189 \n",
      "\n",
      "step: 594  loss: = 143.970856 \n",
      "\n",
      "step: 595  loss: = 143.858307 \n",
      "\n",
      "step: 596  loss: = 144.167877 \n",
      "\n",
      "step: 597  loss: = 144.072784 \n",
      "\n",
      "step: 598  loss: = 143.157440 \n",
      "\n",
      "step: 599  loss: = 144.530746 \n",
      "\n",
      "step: 600  loss: = 143.328659 \n",
      "\n",
      "step: 601  loss: = 144.269653 \n",
      "\n",
      "step: 602  loss: = 143.699066 \n",
      "\n",
      "step: 603  loss: = 146.198700 \n",
      "\n",
      "step: 604  loss: = 144.307266 \n",
      "\n",
      "step: 605  loss: = 144.876740 \n",
      "\n",
      "step: 606  loss: = 143.984619 \n",
      "\n",
      "step: 607  loss: = 145.036041 \n",
      "\n",
      "step: 608  loss: = 144.341232 \n",
      "\n",
      "step: 609  loss: = 143.693954 \n",
      "\n",
      "step: 610  loss: = 144.943466 \n",
      "\n",
      "step: 611  loss: = 143.846375 \n",
      "\n",
      "step: 612  loss: = 144.373611 \n",
      "\n",
      "step: 613  loss: = 145.019867 \n",
      "\n",
      "step: 614  loss: = 144.263046 \n",
      "\n",
      "step: 615  loss: = 144.017365 \n",
      "\n",
      "step: 616  loss: = 143.704529 \n",
      "\n",
      "step: 617  loss: = 144.473785 \n",
      "\n",
      "step: 618  loss: = 144.987320 \n",
      "\n",
      "step: 619  loss: = 144.203537 \n",
      "\n",
      "step: 620  loss: = 146.000977 \n",
      "\n",
      "step: 621  loss: = 143.689621 \n",
      "\n",
      "step: 622  loss: = 144.109879 \n",
      "\n",
      "step: 623  loss: = 144.201019 \n",
      "\n",
      "step: 624  loss: = 143.451385 \n",
      "\n",
      "step: 625  loss: = 144.534439 \n",
      "\n",
      "step: 626  loss: = 144.737595 \n",
      "\n",
      "step: 627  loss: = 144.594666 \n",
      "\n",
      "step: 628  loss: = 143.554535 \n",
      "\n",
      "step: 629  loss: = 144.117798 \n",
      "\n",
      "step: 630  loss: = 143.527954 \n",
      "\n",
      "step: 631  loss: = 144.654160 \n",
      "\n",
      "step: 632  loss: = 143.527023 \n",
      "\n",
      "step: 633  loss: = 143.309708 \n",
      "\n",
      "step: 634  loss: = 145.661377 \n",
      "\n",
      "step: 635  loss: = 144.243240 \n",
      "\n",
      "step: 636  loss: = 145.115311 \n",
      "\n",
      "step: 637  loss: = 143.763077 \n",
      "\n",
      "step: 638  loss: = 144.204910 \n",
      "\n",
      "step: 639  loss: = 143.367020 \n",
      "\n",
      "step: 640  loss: = 144.390015 \n",
      "\n",
      "step: 641  loss: = 143.422333 \n",
      "\n",
      "step: 642  loss: = 145.278778 \n",
      "\n",
      "step: 643  loss: = 143.315552 \n",
      "\n",
      "step: 644  loss: = 145.876633 \n",
      "\n",
      "step: 645  loss: = 143.548920 \n",
      "\n",
      "step: 646  loss: = 144.373932 \n",
      "\n",
      "step: 647  loss: = 144.233170 \n",
      "\n",
      "step: 648  loss: = 143.512436 \n",
      "\n",
      "step: 649  loss: = 144.207138 \n",
      "\n",
      "step: 650  loss: = 144.179764 \n",
      "\n",
      "step: 651  loss: = 144.137939 \n",
      "\n",
      "step: 652  loss: = 144.680420 \n",
      "\n",
      "step: 653  loss: = 144.096848 \n",
      "\n",
      "step: 654  loss: = 143.730972 \n",
      "\n",
      "step: 655  loss: = 143.221634 \n",
      "\n",
      "step: 656  loss: = 145.033295 \n",
      "\n",
      "step: 657  loss: = 144.027405 \n",
      "\n",
      "step: 658  loss: = 144.871262 \n",
      "\n",
      "step: 659  loss: = 143.862000 \n",
      "\n",
      "step: 660  loss: = 143.246811 \n",
      "\n",
      "step: 661  loss: = 144.004669 \n",
      "\n",
      "step: 662  loss: = 145.048615 \n",
      "\n",
      "step: 663  loss: = 144.474014 \n",
      "\n",
      "step: 664  loss: = 144.284576 \n",
      "\n",
      "step: 665  loss: = 143.177933 \n",
      "\n",
      "step: 666  loss: = 145.463791 \n",
      "\n",
      "step: 667  loss: = 144.732101 \n",
      "\n",
      "step: 668  loss: = 143.859848 \n",
      "\n",
      "step: 669  loss: = 143.910645 \n",
      "\n",
      "step: 670  loss: = 143.653076 \n",
      "\n",
      "step: 671  loss: = 144.017334 \n",
      "\n",
      "step: 672  loss: = 143.894501 \n",
      "\n",
      "step: 673  loss: = 144.549637 \n",
      "\n",
      "step: 674  loss: = 143.693924 \n",
      "\n",
      "step: 675  loss: = 145.226364 \n",
      "\n",
      "step: 676  loss: = 144.432022 \n",
      "\n",
      "step: 677  loss: = 142.814438 \n",
      "\n",
      "step: 678  loss: = 143.520370 \n",
      "\n",
      "step: 679  loss: = 143.051804 \n",
      "\n",
      "step: 680  loss: = 143.620010 \n",
      "\n",
      "step: 681  loss: = 144.989365 \n",
      "\n",
      "step: 682  loss: = 145.300858 \n",
      "\n",
      "step: 683  loss: = 144.026199 \n",
      "\n",
      "step: 684  loss: = 144.773071 \n",
      "\n",
      "step: 685  loss: = 144.069824 \n",
      "\n",
      "step: 686  loss: = 144.302567 \n",
      "\n",
      "step: 687  loss: = 143.826584 \n",
      "\n",
      "step: 688  loss: = 145.433121 \n",
      "\n",
      "step: 689  loss: = 144.127884 \n",
      "\n",
      "step: 690  loss: = 143.466354 \n",
      "\n",
      "step: 691  loss: = 143.828964 \n",
      "\n",
      "step: 692  loss: = 144.777512 \n",
      "\n",
      "step: 693  loss: = 143.542648 \n",
      "\n",
      "step: 694  loss: = 144.252243 \n",
      "\n",
      "step: 695  loss: = 144.010162 \n",
      "\n",
      "step: 696  loss: = 144.214630 \n",
      "\n",
      "step: 697  loss: = 144.818588 \n",
      "\n",
      "step: 698  loss: = 143.870255 \n",
      "\n",
      "step: 699  loss: = 143.316208 \n",
      "\n",
      "step: 700  loss: = 143.924515 \n",
      "\n",
      "step: 701  loss: = 145.468689 \n",
      "\n",
      "step: 702  loss: = 142.924057 \n",
      "\n",
      "step: 703  loss: = 143.939728 \n",
      "\n",
      "step: 704  loss: = 144.885666 \n",
      "\n",
      "step: 705  loss: = 144.722916 \n",
      "\n",
      "step: 706  loss: = 144.247787 \n",
      "\n",
      "step: 707  loss: = 143.508118 \n",
      "\n",
      "step: 708  loss: = 143.562881 \n",
      "\n",
      "step: 709  loss: = 143.994431 \n",
      "\n",
      "step: 710  loss: = 143.765976 \n",
      "\n",
      "step: 711  loss: = 144.458740 \n",
      "\n",
      "step: 712  loss: = 144.965958 \n",
      "\n",
      "step: 713  loss: = 143.728195 \n",
      "\n",
      "step: 714  loss: = 143.881699 \n",
      "\n",
      "step: 715  loss: = 144.551773 \n",
      "\n",
      "step: 716  loss: = 143.818878 \n",
      "\n",
      "step: 717  loss: = 144.340744 \n",
      "\n",
      "step: 718  loss: = 144.901779 \n",
      "\n",
      "step: 719  loss: = 143.500824 \n",
      "\n",
      "step: 720  loss: = 143.842087 \n",
      "\n",
      "step: 721  loss: = 143.838608 \n",
      "\n",
      "step: 722  loss: = 143.674530 \n",
      "\n",
      "step: 723  loss: = 143.751984 \n",
      "\n",
      "step: 724  loss: = 143.423233 \n",
      "\n",
      "step: 725  loss: = 143.280487 \n",
      "\n",
      "step: 726  loss: = 143.357986 \n",
      "\n",
      "step: 727  loss: = 143.790344 \n",
      "\n",
      "step: 728  loss: = 144.403625 \n",
      "\n",
      "step: 729  loss: = 144.422470 \n",
      "\n",
      "step: 730  loss: = 144.216263 \n",
      "\n",
      "step: 731  loss: = 145.008530 \n",
      "\n",
      "step: 732  loss: = 143.595291 \n",
      "\n",
      "step: 733  loss: = 144.898804 \n",
      "\n",
      "step: 734  loss: = 143.692200 \n",
      "\n",
      "step: 735  loss: = 146.992050 \n",
      "\n",
      "step: 736  loss: = 144.416260 \n",
      "\n",
      "step: 737  loss: = 143.160172 \n",
      "\n",
      "step: 738  loss: = 144.575607 \n",
      "\n",
      "step: 739  loss: = 143.990540 \n",
      "\n",
      "step: 740  loss: = 144.836655 \n",
      "\n",
      "step: 741  loss: = 143.901688 \n",
      "\n",
      "step: 742  loss: = 144.073639 \n",
      "\n",
      "step: 743  loss: = 143.373703 \n",
      "\n",
      "step: 744  loss: = 144.467743 \n",
      "\n",
      "step: 745  loss: = 143.588348 \n",
      "\n",
      "step: 746  loss: = 144.360123 \n",
      "\n",
      "step: 747  loss: = 143.166946 \n",
      "\n",
      "step: 748  loss: = 143.846420 \n",
      "\n",
      "step: 749  loss: = 144.046967 \n",
      "\n",
      "step: 750  loss: = 143.857422 \n",
      "\n",
      "step: 751  loss: = 144.334167 \n",
      "\n",
      "step: 752  loss: = 146.018753 \n",
      "\n",
      "step: 753  loss: = 143.672791 \n",
      "\n",
      "step: 754  loss: = 143.665588 \n",
      "\n",
      "step: 755  loss: = 144.597382 \n",
      "\n",
      "step: 756  loss: = 143.557922 \n",
      "\n",
      "step: 757  loss: = 144.936203 \n",
      "\n",
      "step: 758  loss: = 143.822449 \n",
      "\n",
      "step: 759  loss: = 145.034653 \n",
      "\n",
      "step: 760  loss: = 147.166168 \n",
      "\n",
      "step: 761  loss: = 145.161011 \n",
      "\n",
      "step: 762  loss: = 144.957443 \n",
      "\n",
      "step: 763  loss: = 143.568985 \n",
      "\n",
      "step: 764  loss: = 143.831024 \n",
      "\n",
      "step: 765  loss: = 143.414230 \n",
      "\n",
      "step: 766  loss: = 143.634018 \n",
      "\n",
      "step: 767  loss: = 144.914139 \n",
      "\n",
      "step: 768  loss: = 143.722961 \n",
      "\n",
      "step: 769  loss: = 144.370102 \n",
      "\n",
      "step: 770  loss: = 144.206131 \n",
      "\n",
      "step: 771  loss: = 144.033188 \n",
      "\n",
      "step: 772  loss: = 144.183746 \n",
      "\n",
      "step: 773  loss: = 142.937027 \n",
      "\n",
      "step: 774  loss: = 144.537003 \n",
      "\n",
      "step: 775  loss: = 144.031464 \n",
      "\n",
      "step: 776  loss: = 143.293976 \n",
      "\n",
      "step: 777  loss: = 143.659607 \n",
      "\n",
      "step: 778  loss: = 143.539017 \n",
      "\n",
      "step: 779  loss: = 144.801666 \n",
      "\n",
      "step: 780  loss: = 144.563797 \n",
      "\n",
      "step: 781  loss: = 144.361877 \n",
      "\n",
      "step: 782  loss: = 144.206558 \n",
      "\n",
      "step: 783  loss: = 144.992828 \n",
      "\n",
      "step: 784  loss: = 144.925125 \n",
      "\n",
      "step: 785  loss: = 145.347763 \n",
      "\n",
      "step: 786  loss: = 143.655151 \n",
      "\n",
      "step: 787  loss: = 143.775894 \n",
      "\n",
      "step: 788  loss: = 143.921890 \n",
      "\n",
      "step: 789  loss: = 144.417892 \n",
      "\n",
      "step: 790  loss: = 143.144592 \n",
      "\n",
      "step: 791  loss: = 142.883774 \n",
      "\n",
      "step: 792  loss: = 144.135666 \n",
      "\n",
      "step: 793  loss: = 144.644882 \n",
      "\n",
      "step: 794  loss: = 143.449097 \n",
      "\n",
      "step: 795  loss: = 143.047180 \n",
      "\n",
      "step: 796  loss: = 145.079422 \n",
      "\n",
      "step: 797  loss: = 143.468781 \n",
      "\n",
      "step: 798  loss: = 144.564697 \n",
      "\n",
      "step: 799  loss: = 144.262680 \n",
      "\n",
      "step: 800  loss: = 145.369110 \n",
      "\n",
      "step: 801  loss: = 143.747284 \n",
      "\n",
      "step: 802  loss: = 143.947403 \n",
      "\n",
      "step: 803  loss: = 144.964371 \n",
      "\n",
      "step: 804  loss: = 143.593643 \n",
      "\n",
      "step: 805  loss: = 145.163971 \n",
      "\n",
      "step: 806  loss: = 144.000916 \n",
      "\n",
      "step: 807  loss: = 146.834518 \n",
      "\n",
      "step: 808  loss: = 144.968491 \n",
      "\n",
      "step: 809  loss: = 143.509491 \n",
      "\n",
      "step: 810  loss: = 143.619095 \n",
      "\n",
      "step: 811  loss: = 143.542419 \n",
      "\n",
      "step: 812  loss: = 143.591354 \n",
      "\n",
      "step: 813  loss: = 144.304932 \n",
      "\n",
      "step: 814  loss: = 142.974182 \n",
      "\n",
      "step: 815  loss: = 143.715439 \n",
      "\n",
      "step: 816  loss: = 143.540405 \n",
      "\n",
      "step: 817  loss: = 143.551636 \n",
      "\n",
      "step: 818  loss: = 144.016006 \n",
      "\n",
      "step: 819  loss: = 144.751450 \n",
      "\n",
      "step: 820  loss: = 143.273132 \n",
      "\n",
      "step: 821  loss: = 143.492050 \n",
      "\n",
      "step: 822  loss: = 143.845764 \n",
      "\n",
      "step: 823  loss: = 144.083557 \n",
      "\n",
      "step: 824  loss: = 143.642578 \n",
      "\n",
      "step: 825  loss: = 143.776840 \n",
      "\n",
      "step: 826  loss: = 143.748932 \n",
      "\n",
      "step: 827  loss: = 144.463303 \n",
      "\n",
      "step: 828  loss: = 145.219482 \n",
      "\n",
      "step: 829  loss: = 144.517090 \n",
      "\n",
      "step: 830  loss: = 144.570892 \n",
      "\n",
      "step: 831  loss: = 144.703537 \n",
      "\n",
      "step: 832  loss: = 143.254608 \n",
      "\n",
      "step: 833  loss: = 143.840820 \n",
      "\n",
      "step: 834  loss: = 144.305527 \n",
      "\n",
      "step: 835  loss: = 145.283051 \n",
      "\n",
      "step: 836  loss: = 144.075974 \n",
      "\n",
      "step: 837  loss: = 143.824524 \n",
      "\n",
      "step: 838  loss: = 143.534454 \n",
      "\n",
      "step: 839  loss: = 143.845734 \n",
      "\n",
      "step: 840  loss: = 143.818649 \n",
      "\n",
      "step: 841  loss: = 145.990509 \n",
      "\n",
      "step: 842  loss: = 143.142365 \n",
      "\n",
      "step: 843  loss: = 143.609619 \n",
      "\n",
      "step: 844  loss: = 144.173172 \n",
      "\n",
      "step: 845  loss: = 143.478821 \n",
      "\n",
      "step: 846  loss: = 143.655350 \n",
      "\n",
      "step: 847  loss: = 143.368225 \n",
      "\n",
      "step: 848  loss: = 143.786423 \n",
      "\n",
      "step: 849  loss: = 144.874084 \n",
      "\n",
      "step: 850  loss: = 143.648010 \n",
      "\n",
      "step: 851  loss: = 143.693649 \n",
      "\n",
      "step: 852  loss: = 144.399475 \n",
      "\n",
      "step: 853  loss: = 143.211929 \n",
      "\n",
      "step: 854  loss: = 146.029678 \n",
      "\n",
      "step: 855  loss: = 143.845398 \n",
      "\n",
      "step: 856  loss: = 143.419785 \n",
      "\n",
      "step: 857  loss: = 143.777908 \n",
      "\n",
      "step: 858  loss: = 144.247131 \n",
      "\n",
      "step: 859  loss: = 143.940659 \n",
      "\n",
      "step: 860  loss: = 143.211746 \n",
      "\n",
      "step: 861  loss: = 143.805908 \n",
      "\n",
      "step: 862  loss: = 144.174362 \n",
      "\n",
      "step: 863  loss: = 143.837128 \n",
      "\n",
      "step: 864  loss: = 144.100113 \n",
      "\n",
      "step: 865  loss: = 144.632004 \n",
      "\n",
      "step: 866  loss: = 145.809845 \n",
      "\n",
      "step: 867  loss: = 143.352310 \n",
      "\n",
      "step: 868  loss: = 143.812912 \n",
      "\n",
      "step: 869  loss: = 143.803299 \n",
      "\n",
      "step: 870  loss: = 143.525452 \n",
      "\n",
      "step: 871  loss: = 144.025360 \n",
      "\n",
      "step: 872  loss: = 143.923828 \n",
      "\n",
      "step: 873  loss: = 144.631180 \n",
      "\n",
      "step: 874  loss: = 143.981689 \n",
      "\n",
      "step: 875  loss: = 143.906555 \n",
      "\n",
      "step: 876  loss: = 143.123734 \n",
      "\n",
      "step: 877  loss: = 143.898987 \n",
      "\n",
      "step: 878  loss: = 143.776169 \n",
      "\n",
      "step: 879  loss: = 145.379883 \n",
      "\n",
      "step: 880  loss: = 143.935608 \n",
      "\n",
      "step: 881  loss: = 143.760574 \n",
      "\n",
      "step: 882  loss: = 142.966995 \n",
      "\n",
      "step: 883  loss: = 146.825470 \n",
      "\n",
      "step: 884  loss: = 143.788986 \n",
      "\n",
      "step: 885  loss: = 142.818085 \n",
      "\n",
      "step: 886  loss: = 143.888321 \n",
      "\n",
      "step: 887  loss: = 143.596436 \n",
      "\n",
      "step: 888  loss: = 144.857315 \n",
      "\n",
      "step: 889  loss: = 144.207733 \n",
      "\n",
      "step: 890  loss: = 144.272049 \n",
      "\n",
      "step: 891  loss: = 144.064209 \n",
      "\n",
      "step: 892  loss: = 143.953827 \n",
      "\n",
      "step: 893  loss: = 146.526871 \n",
      "\n",
      "step: 894  loss: = 144.911606 \n",
      "\n",
      "step: 895  loss: = 144.784576 \n",
      "\n",
      "step: 896  loss: = 143.523407 \n",
      "\n",
      "step: 897  loss: = 144.303894 \n",
      "\n",
      "step: 898  loss: = 144.753693 \n",
      "\n",
      "step: 899  loss: = 143.734879 \n",
      "\n",
      "step: 900  loss: = 144.160873 \n",
      "\n",
      "step: 901  loss: = 144.084946 \n",
      "\n",
      "step: 902  loss: = 143.775787 \n",
      "\n",
      "step: 903  loss: = 143.422684 \n",
      "\n",
      "step: 904  loss: = 143.943207 \n",
      "\n",
      "step: 905  loss: = 143.890625 \n",
      "\n",
      "step: 906  loss: = 143.270676 \n",
      "\n",
      "step: 907  loss: = 143.912857 \n",
      "\n",
      "step: 908  loss: = 143.612274 \n",
      "\n",
      "step: 909  loss: = 143.943069 \n",
      "\n",
      "step: 910  loss: = 144.068817 \n",
      "\n",
      "step: 911  loss: = 143.558899 \n",
      "\n",
      "step: 912  loss: = 144.936874 \n",
      "\n",
      "step: 913  loss: = 144.454193 \n",
      "\n",
      "step: 914  loss: = 144.676971 \n",
      "\n",
      "step: 915  loss: = 144.141998 \n",
      "\n",
      "step: 916  loss: = 143.709625 \n",
      "\n",
      "step: 917  loss: = 143.435349 \n",
      "\n",
      "step: 918  loss: = 143.940399 \n",
      "\n",
      "step: 919  loss: = 144.007507 \n",
      "\n",
      "step: 920  loss: = 144.479340 \n",
      "\n",
      "step: 921  loss: = 143.876938 \n",
      "\n",
      "step: 922  loss: = 142.234879 \n",
      "\n",
      "step: 923  loss: = 142.616409 \n",
      "\n",
      "step: 924  loss: = 143.412292 \n",
      "\n",
      "step: 925  loss: = 144.448227 \n",
      "\n",
      "step: 926  loss: = 145.240005 \n",
      "\n",
      "step: 927  loss: = 144.279922 \n",
      "\n",
      "step: 928  loss: = 143.931213 \n",
      "\n",
      "step: 929  loss: = 143.578445 \n",
      "\n",
      "step: 930  loss: = 143.778656 \n",
      "\n",
      "step: 931  loss: = 145.112473 \n",
      "\n",
      "step: 932  loss: = 145.416504 \n",
      "\n",
      "step: 933  loss: = 144.421555 \n",
      "\n",
      "step: 934  loss: = 144.665024 \n",
      "\n",
      "step: 935  loss: = 145.109299 \n",
      "\n",
      "step: 936  loss: = 144.180145 \n",
      "\n",
      "step: 937  loss: = 143.270767 \n",
      "\n",
      "step: 938  loss: = 143.767334 \n",
      "\n",
      "step: 939  loss: = 143.678253 \n",
      "\n",
      "step: 940  loss: = 143.529419 \n",
      "\n",
      "step: 941  loss: = 144.546295 \n",
      "\n",
      "step: 942  loss: = 143.512390 \n",
      "\n",
      "step: 943  loss: = 145.821838 \n",
      "\n",
      "step: 944  loss: = 143.820114 \n",
      "\n",
      "step: 945  loss: = 144.402267 \n",
      "\n",
      "step: 946  loss: = 143.389221 \n",
      "\n",
      "step: 947  loss: = 143.289642 \n",
      "\n",
      "step: 948  loss: = 142.855957 \n",
      "\n",
      "step: 949  loss: = 144.121658 \n",
      "\n",
      "step: 950  loss: = 144.550079 \n",
      "\n",
      "step: 951  loss: = 144.140442 \n",
      "\n",
      "step: 952  loss: = 145.490128 \n",
      "\n",
      "step: 953  loss: = 144.591995 \n",
      "\n",
      "step: 954  loss: = 143.203232 \n",
      "\n",
      "step: 955  loss: = 144.058060 \n",
      "\n",
      "step: 956  loss: = 144.435959 \n",
      "\n",
      "step: 957  loss: = 143.971146 \n",
      "\n",
      "step: 958  loss: = 143.573364 \n",
      "\n",
      "step: 959  loss: = 144.063385 \n",
      "\n",
      "step: 960  loss: = 143.902390 \n",
      "\n",
      "step: 961  loss: = 143.296371 \n",
      "\n",
      "step: 962  loss: = 144.767715 \n",
      "\n",
      "step: 963  loss: = 143.698013 \n",
      "\n",
      "step: 964  loss: = 143.962280 \n",
      "\n",
      "step: 965  loss: = 142.880325 \n",
      "\n",
      "step: 966  loss: = 143.479477 \n",
      "\n",
      "step: 967  loss: = 143.798767 \n",
      "\n",
      "step: 968  loss: = 143.419891 \n",
      "\n",
      "step: 969  loss: = 144.054367 \n",
      "\n",
      "step: 970  loss: = 143.418594 \n",
      "\n",
      "step: 971  loss: = 143.797134 \n",
      "\n",
      "step: 972  loss: = 143.515121 \n",
      "\n",
      "step: 973  loss: = 143.186798 \n",
      "\n",
      "step: 974  loss: = 142.837997 \n",
      "\n",
      "step: 975  loss: = 142.811829 \n",
      "\n",
      "step: 976  loss: = 144.686615 \n",
      "\n",
      "step: 977  loss: = 144.781036 \n",
      "\n",
      "step: 978  loss: = 144.495789 \n",
      "\n",
      "step: 979  loss: = 144.310226 \n",
      "\n",
      "step: 980  loss: = 145.978043 \n",
      "\n",
      "step: 981  loss: = 143.346024 \n",
      "\n",
      "step: 982  loss: = 143.241608 \n",
      "\n",
      "step: 983  loss: = 145.323074 \n",
      "\n",
      "step: 984  loss: = 145.480270 \n",
      "\n",
      "step: 985  loss: = 142.951294 \n",
      "\n",
      "step: 986  loss: = 144.111877 \n",
      "\n",
      "step: 987  loss: = 143.455704 \n",
      "\n",
      "step: 988  loss: = 143.412704 \n",
      "\n",
      "step: 989  loss: = 143.660385 \n",
      "\n",
      "step: 990  loss: = 144.688492 \n",
      "\n",
      "step: 991  loss: = 144.291641 \n",
      "\n",
      "step: 992  loss: = 142.138046 \n",
      "\n",
      "step: 993  loss: = 143.064392 \n",
      "\n",
      "step: 994  loss: = 143.337448 \n",
      "\n",
      "step: 995  loss: = 145.098190 \n",
      "\n",
      "step: 996  loss: = 143.413528 \n",
      "\n",
      "step: 997  loss: = 144.415878 \n",
      "\n",
      "step: 998  loss: = 142.878128 \n",
      "\n",
      "step: 999  loss: = 144.257919 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE NETWORK\n",
    "\n",
    "for step in range(100): \n",
    "    \n",
    "    inds = np.reshape(np.random.permutation(range(input_bip1_train.shape[1])), [-1, batchsize])\n",
    "\n",
    "    for n in range(len(inds)):  \n",
    "        fdd = {batchsize_: batchsize, input_filt1_: input_bip1_train[:, inds[n, :], :], \\\n",
    "               input_filt2_: input_bip2_train[:, inds[n, :], :], input_filt3_: input_bip3_train[:, inds[n, :], :],\\\n",
    "               input_filt4_: input_bip4_train[:, inds[n, :], :], input_filt5_: input_bip5_train[:, inds[n, :], :],\\\n",
    "               input_filt6_: input_bip6_train[:, inds[n, :], :], input_filt7_: input_bip7_train[:, inds[n, :], :],\\\n",
    "               input_filt8_: input_bip8_train[:, inds[n, :], :], input_filt9_: input_bip9_train[:, inds[n, :], :],\\\n",
    "               input_filt10_: input_bip10_train[:, inds[n, :], :], input_filt11_: input_bip11_train[:, inds[n, :], :],\\\n",
    "               input_filt12_: input_bip12_train[:, inds[n, :], :], input_filt13_: input_bip13_train[:, inds[n, :], :],\\\n",
    "               input_filt14_: input_bip14_train[:, inds[n, :], :], input_filt15_: input_bip15_train[:, inds[n, :], :],\\\n",
    "               input_filt16_: input_bip16_train[:, inds[n, :], :], y_:y_train[inds[n, :], :, :]}\n",
    "        sess.run(train_step, feed_dict=fdd, options = run_opts)\n",
    "        \n",
    "    batch_loss=sess.run(loss, feed_dict=fdd)\n",
    "    batch_loss_hist=np.concatenate([batch_loss_hist, np.array([batch_loss])], axis=0)\n",
    "    L1=sess.run(regularizer, feed_dict=fdd)\n",
    "    L1_hist=np.concatenate([L1_hist, np.array([L1])], axis=0)\n",
    "    loss_val = (batchsize/train_loss_size)*sess.run(loss, feed_dict= trainsampfd)\n",
    "    loss_hist=np.concatenate([loss_hist, np.array([loss_val])], axis=0)\n",
    "    check=loss_val\n",
    "\n",
    "    print(\"step: %d  loss: = %9f \\n\" % (step, loss_val))\n",
    "    \n",
    "    if (step % 10 == 0):\n",
    "        test_loss = (batchsize/input_bip1_test.shape[1])*sess.run(loss, feed_dict= fddd)\n",
    "        test_hist=np.concatenate([test_hist, np.array([test_loss])], axis=0)\n",
    " \n",
    "\n",
    "    if (step % 10 == 0):\n",
    "        \n",
    "        f1b1_syn_hist=tf.concat([f1b1_syn_hist, tf.reshape(f1b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f1b1_syn_concat')\n",
    "        f2b1_syn_hist=tf.concat([f2b1_syn_hist, tf.reshape(f2b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f2b1_syn_concat')\n",
    "        f3b1_syn_hist=tf.concat([f3b1_syn_hist, tf.reshape(f3b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f3b1_syn_concat')\n",
    "        f4b1_syn_hist=tf.concat([f4b1_syn_hist, tf.reshape(f4b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f4b1_syn_concat')\n",
    "        f5b1_syn_hist=tf.concat([f5b1_syn_hist, tf.reshape(f5b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f5b1_syn_concat')\n",
    "        f6b1_syn_hist=tf.concat([f6b1_syn_hist, tf.reshape(f6b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f6b1_syn_concat')\n",
    "        f7b1_syn_hist=tf.concat([f7b1_syn_hist, tf.reshape(f7b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f7b1_syn_concat')\n",
    "        f8b1_syn_hist=tf.concat([f8b1_syn_hist, tf.reshape(f8b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f8b1_syn_concat')\n",
    "        f9b1_syn_hist=tf.concat([f9b1_syn_hist, tf.reshape(f9b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f9b1_syn_concat')\n",
    "        f10b1_syn_hist=tf.concat([f10b1_syn_hist, tf.reshape(f10b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f10b1_syn_concat')\n",
    "        f11b1_syn_hist=tf.concat([f11b1_syn_hist, tf.reshape(f11b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f11b1_syn_concat')\n",
    "        f12b1_syn_hist=tf.concat([f12b1_syn_hist, tf.reshape(f12b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f12b1_syn_concat')\n",
    "        f13b1_syn_hist=tf.concat([f13b1_syn_hist, tf.reshape(f13b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f13b1_syn_concat')\n",
    "        f14b1_syn_hist=tf.concat([f14b1_syn_hist, tf.reshape(f14b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f14b1_syn_concat')\n",
    "        f15b1_syn_hist=tf.concat([f15b1_syn_hist, tf.reshape(f15b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f15b1_syn_concat')\n",
    "        f16b1_syn_hist=tf.concat([f16b1_syn_hist, tf.reshape(f16b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f16b1_syn_concat')\n",
    "        \n",
    "        f1b2_syn_hist=tf.concat([f1b2_syn_hist, tf.reshape(f1b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f1b2_syn_concat')\n",
    "        f2b2_syn_hist=tf.concat([f2b2_syn_hist, tf.reshape(f2b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f2b2_syn_concat')\n",
    "        f3b2_syn_hist=tf.concat([f3b2_syn_hist, tf.reshape(f3b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f3b2_syn_concat')\n",
    "        f4b2_syn_hist=tf.concat([f4b2_syn_hist, tf.reshape(f4b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f4b2_syn_concat')\n",
    "        f5b2_syn_hist=tf.concat([f5b2_syn_hist, tf.reshape(f5b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f5b2_syn_concat')\n",
    "        f6b2_syn_hist=tf.concat([f6b2_syn_hist, tf.reshape(f6b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f6b2_syn_concat')\n",
    "        f7b2_syn_hist=tf.concat([f7b2_syn_hist, tf.reshape(f7b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f7b2_syn_concat')\n",
    "        f8b2_syn_hist=tf.concat([f8b2_syn_hist, tf.reshape(f8b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f8b2_syn_concat')\n",
    "        f9b2_syn_hist=tf.concat([f9b2_syn_hist, tf.reshape(f9b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f9b2_syn_concat')\n",
    "        f10b2_syn_hist=tf.concat([f10b2_syn_hist, tf.reshape(f10b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f10b2_syn_concat')\n",
    "        f11b2_syn_hist=tf.concat([f11b2_syn_hist, tf.reshape(f11b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f11b2_syn_concat')\n",
    "        f12b2_syn_hist=tf.concat([f12b2_syn_hist, tf.reshape(f12b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f12b2_syn_concat')\n",
    "        f13b2_syn_hist=tf.concat([f13b2_syn_hist, tf.reshape(f13b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f13b2_syn_concat')\n",
    "        f14b2_syn_hist=tf.concat([f14b2_syn_hist, tf.reshape(f14b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f14b2_syn_concat')\n",
    "        f15b2_syn_hist=tf.concat([f15b2_syn_hist, tf.reshape(f15b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f15b2_syn_concat')\n",
    "        f16b2_syn_hist=tf.concat([f16b2_syn_hist, tf.reshape(f16b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f16b2_syn_concat')\n",
    "        \n",
    "        f1b11_syn_hist=tf.concat([f1b11_syn_hist, tf.reshape(f1b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f1b11_syn_concat')\n",
    "        f2b11_syn_hist=tf.concat([f2b11_syn_hist, tf.reshape(f2b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f2b11_syn_concat')\n",
    "        f3b11_syn_hist=tf.concat([f3b11_syn_hist, tf.reshape(f3b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f3b11_syn_concat')\n",
    "        f4b11_syn_hist=tf.concat([f4b11_syn_hist, tf.reshape(f4b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f4b11_syn_concat')\n",
    "        f5b11_syn_hist=tf.concat([f5b11_syn_hist, tf.reshape(f5b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f5b11_syn_concat')\n",
    "        f6b11_syn_hist=tf.concat([f6b11_syn_hist, tf.reshape(f6b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f6b11_syn_concat')\n",
    "        f7b11_syn_hist=tf.concat([f7b11_syn_hist, tf.reshape(f7b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f7b11_syn_concat')\n",
    "        f8b11_syn_hist=tf.concat([f8b11_syn_hist, tf.reshape(f8b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f8b11_syn_concat')\n",
    "        f9b11_syn_hist=tf.concat([f9b11_syn_hist, tf.reshape(f9b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f9b11_syn_concat')\n",
    "        f10b11_syn_hist=tf.concat([f10b11_syn_hist, tf.reshape(f10b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f10b11_syn_concat')\n",
    "        f11b11_syn_hist=tf.concat([f11b11_syn_hist, tf.reshape(f11b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f11b11_syn_concat')\n",
    "        f12b11_syn_hist=tf.concat([f12b11_syn_hist, tf.reshape(f12b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f12b11_syn_concat')\n",
    "        f13b11_syn_hist=tf.concat([f13b11_syn_hist, tf.reshape(f13b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f13b11_syn_concat')\n",
    "        f14b11_syn_hist=tf.concat([f14b11_syn_hist, tf.reshape(f14b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f14b11_syn_concat')\n",
    "        f15b11_syn_hist=tf.concat([f15b11_syn_hist, tf.reshape(f15b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f15b11_syn_concat')\n",
    "        f16b11_syn_hist=tf.concat([f16b11_syn_hist, tf.reshape(f16b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f16b11_syn_concat')\n",
    "        \n",
    "        bip1_gc_syn_hist=tf.concat([bip1_gc_syn_hist, tf.reshape(bip1_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip1_gc_syn_concat')\n",
    "        bip2_gc_syn_hist=tf.concat([bip2_gc_syn_hist, tf.reshape(bip2_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip2_gc_syn_concat')\n",
    "        bip11_gc_syn_hist=tf.concat([bip11_gc_syn_hist, tf.reshape(bip11_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip11_gc_syn_concat')\n",
    "\n",
    "        bip1_copy_gc_syn_hist=tf.concat([bip1_copy_gc_syn_hist, tf.reshape(bip1_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip1_copy_gc_syn_concat')\n",
    "        bip2_copy_gc_syn_hist=tf.concat([bip2_copy_gc_syn_hist, tf.reshape(bip2_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip2_copy_gc_syn_concat')\n",
    "        bip11_copy_gc_syn_hist=tf.concat([bip11_copy_gc_syn_hist, tf.reshape(bip11_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip11_copy_gc_syn_concat')\n",
    "\n",
    "        bip1_am1_syn_hist=tf.concat([bip1_am1_syn_hist, tf.reshape(bip1_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])], 0, name = 'bip1_am1_syn_concat')\n",
    "        bip2_am1_syn_hist=tf.concat([bip2_am1_syn_hist, tf.reshape(bip2_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])], 0, name = 'bip2_am1_syn_concat')\n",
    "        bip11_am1_syn_hist=tf.concat([bip11_am1_syn_hist, tf.reshape(bip11_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])], 0, name = 'bip11_am1_syn_concat')\n",
    "        \n",
    "        am1_gc_syn_hist=tf.concat([am1_gc_syn_hist, tf.reshape(am1_gc_syn.eval(session=sess), [1, no_am1, no_gc])], 0, name = 'am1_gc_syn_concat')\n",
    "\n",
    "        am1_b1copy_syn_hist=tf.concat([am1_b1copy_syn_hist, tf.reshape(am1_b1copy_syn.eval(session=sess), [1, no_am1, no_bipolars])], 0, name = 'am1_b1copy_syn_concat')\n",
    "        am1_b2copy_syn_hist=tf.concat([am1_b2copy_syn_hist, tf.reshape(am1_b2copy_syn.eval(session=sess), [1, no_am1, no_bipolars])], 0, name = 'am1_b2copy_syn_concat')\n",
    "\n",
    "        b1_bias_hist=tf.concat([b1_bias_hist, tf.reshape(b1_bias.eval(session=sess), [1, no_bipolars])], 0, name = 'bip1_bias_concat')\n",
    "        b2_bias_hist=tf.concat([b2_bias_hist, tf.reshape(b2_bias.eval(session=sess), [1, no_bipolars])], 0, name = 'bip2_bias_concat')\n",
    "        b11_bias_hist=tf.concat([b11_bias_hist, tf.reshape(b11_bias.eval(session=sess), [1, no_bipolars])], 0, name = 'bip11_bias_concat')\n",
    "\n",
    "        am1_bias_hist=tf.concat([am1_bias_hist, tf.reshape(am1_bias.eval(session=sess), [1, no_am1])], 0, name = 'am1_bias_concat')\n",
    "        gc_bias_hist=tf.concat([gc_bias_hist, tf.reshape(gc_bias.eval(session=sess), [1, no_gc])], 0, name = 'gc_bias_concat')\n",
    "        gc_stretch_hist=tf.concat([gc_stretch_hist, tf.reshape(gc_stretch.eval(session=sess), [1, no_gc])], 0, name = 'gc_bias_concat')\n",
    "\n",
    "        output_hist=tf.concat([output_hist, tf.reshape(output.eval(session=sess, feed_dict=singlefd), [1, 32, data_duration])], 0, name = 'output_concat')\n",
    "    \n",
    "        db={}\n",
    "        \n",
    "        db['f1b1_syn_hist']=f1b1_syn_hist.eval(session=sess)\n",
    "        db['f2b1_syn_hist']=f2b1_syn_hist.eval(session=sess)\n",
    "        db['f3b1_syn_hist']=f3b1_syn_hist.eval(session=sess)\n",
    "        db['f4b1_syn_hist']=f4b1_syn_hist.eval(session=sess)\n",
    "        db['f5b1_syn_hist']=f5b1_syn_hist.eval(session=sess)\n",
    "        db['f6b1_syn_hist']=f6b1_syn_hist.eval(session=sess)\n",
    "        db['f7b1_syn_hist']=f7b1_syn_hist.eval(session=sess)\n",
    "        db['f8b1_syn_hist']=f8b1_syn_hist.eval(session=sess)\n",
    "        db['f9b1_syn_hist']=f9b1_syn_hist.eval(session=sess)\n",
    "        db['f10b1_syn_hist']=f10b1_syn_hist.eval(session=sess)\n",
    "        db['f11b1_syn_hist']=f11b1_syn_hist.eval(session=sess)\n",
    "        db['f12b1_syn_hist']=f12b1_syn_hist.eval(session=sess)\n",
    "        db['f13b1_syn_hist']=f13b1_syn_hist.eval(session=sess)\n",
    "        db['f14b1_syn_hist']=f14b1_syn_hist.eval(session=sess)\n",
    "        db['f15b1_syn_hist']=f15b1_syn_hist.eval(session=sess)\n",
    "        db['f16b1_syn_hist']=f16b1_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['f1b2_syn_hist']=f1b2_syn_hist.eval(session=sess)\n",
    "        db['f2b2_syn_hist']=f2b2_syn_hist.eval(session=sess)\n",
    "        db['f3b2_syn_hist']=f3b2_syn_hist.eval(session=sess)\n",
    "        db['f4b2_syn_hist']=f4b2_syn_hist.eval(session=sess)\n",
    "        db['f5b2_syn_hist']=f5b2_syn_hist.eval(session=sess)\n",
    "        db['f6b2_syn_hist']=f6b2_syn_hist.eval(session=sess)\n",
    "        db['f7b2_syn_hist']=f7b2_syn_hist.eval(session=sess)\n",
    "        db['f8b2_syn_hist']=f8b2_syn_hist.eval(session=sess)\n",
    "        db['f9b2_syn_hist']=f9b2_syn_hist.eval(session=sess)\n",
    "        db['f10b2_syn_hist']=f10b2_syn_hist.eval(session=sess)\n",
    "        db['f11b2_syn_hist']=f11b2_syn_hist.eval(session=sess)\n",
    "        db['f12b2_syn_hist']=f12b2_syn_hist.eval(session=sess)\n",
    "        db['f13b2_syn_hist']=f13b2_syn_hist.eval(session=sess)\n",
    "        db['f14b2_syn_hist']=f14b2_syn_hist.eval(session=sess)\n",
    "        db['f15b2_syn_hist']=f15b2_syn_hist.eval(session=sess)\n",
    "        db['f16b2_syn_hist']=f16b2_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['f1b11_syn_hist']=f1b11_syn_hist.eval(session=sess)\n",
    "        db['f2b11_syn_hist']=f2b11_syn_hist.eval(session=sess)\n",
    "        db['f3b11_syn_hist']=f3b11_syn_hist.eval(session=sess)\n",
    "        db['f4b11_syn_hist']=f4b11_syn_hist.eval(session=sess)\n",
    "        db['f5b11_syn_hist']=f5b11_syn_hist.eval(session=sess)\n",
    "        db['f6b11_syn_hist']=f6b11_syn_hist.eval(session=sess)\n",
    "        db['f7b11_syn_hist']=f7b11_syn_hist.eval(session=sess)\n",
    "        db['f8b11_syn_hist']=f8b11_syn_hist.eval(session=sess)\n",
    "        db['f9b11_syn_hist']=f9b11_syn_hist.eval(session=sess)\n",
    "        db['f10b11_syn_hist']=f10b11_syn_hist.eval(session=sess)\n",
    "        db['f11b11_syn_hist']=f11b11_syn_hist.eval(session=sess)\n",
    "        db['f12b11_syn_hist']=f12b11_syn_hist.eval(session=sess)\n",
    "        db['f13b11_syn_hist']=f13b11_syn_hist.eval(session=sess)\n",
    "        db['f14b11_syn_hist']=f14b11_syn_hist.eval(session=sess)\n",
    "        db['f15b11_syn_hist']=f15b11_syn_hist.eval(session=sess)\n",
    "        db['f16b11_syn_hist']=f16b11_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['loss_hist']=loss_hist\n",
    "        db['test_hist']=test_hist   \n",
    "        \n",
    "        db['output_hist']=output_hist.eval(session=sess)\n",
    "        db['bip1_gc_syn_hist']=bip1_gc_syn_hist.eval(session=sess)\n",
    "        db['bip2_gc_syn_hist']=bip2_gc_syn_hist.eval(session=sess)\n",
    "        db['bip11_gc_syn_hist']=bip11_gc_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['bip1_copy_gc_syn_hist']=bip1_copy_gc_syn_hist.eval(session=sess)\n",
    "        db['bip2_copy_gc_syn_hist']=bip2_copy_gc_syn_hist.eval(session=sess)\n",
    "        db['bip11_copy_gc_syn_hist']=bip11_copy_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "        db['bip1_am1_syn_hist']=bip1_am1_syn_hist.eval(session=sess)\n",
    "        db['bip2_am1_syn_hist']=bip2_am1_syn_hist.eval(session=sess)\n",
    "        db['bip11_am1_syn_hist']=bip11_am1_syn_hist.eval(session=sess)\n",
    "       \n",
    "        db['am1_gc_syn_hist']=am1_gc_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['am1_b1copy_syn_hist']=am1_b1copy_syn_hist.eval(session=sess)\n",
    "        db['am1_b2copy_syn_hist']=am1_b2copy_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['b1_bias_hist']=b1_bias_hist.eval(session=sess)\n",
    "        db['b2_bias_hist']=b2_bias_hist.eval(session=sess)\n",
    "\n",
    "        db['b11_bias_hist']=b11_bias_hist.eval(session=sess)\n",
    "\n",
    "        db['am1_bias_hist']=am1_bias_hist.eval(session=sess)\n",
    "        db['gc_bias_hist']=gc_bias_hist.eval(session=sess)\n",
    "        db['gc_stretch_hist']=gc_stretch_hist.eval(session=sess)\n",
    "\n",
    "        db['learning_rate']=learn_rate\n",
    "        db['lambda']=lambda1\n",
    "        \n",
    "        if algorithm_choice==1: \n",
    "            db['algorithm']='Gradient_Descent'\n",
    "        elif algorithm_choice==2:\n",
    "            db['algorithm']='Adam'\n",
    "            db['epsilon']=my_epsilon\n",
    "        elif algorithm_choice==3:\n",
    "            db['algorithm']='Momentum'\n",
    "            db['momentum']=momentum_par\n",
    "        elif algorithm_choice==4:\n",
    "            db['algorithm']='Adagrad'\n",
    "        elif algorithm_choice==5:\n",
    "            db['algorithm']='RMSProp'\n",
    "\n",
    "        sio.savemat(wheretosave, db)        \n",
    "\n",
    "    step=step+1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# COMPUTE TRAINED NETWORK OUTPUT\n",
    "\n",
    "o_output=zeros([1024, dur])\n",
    "\n",
    "batchsz=32\n",
    "for bbatch in range(32):\n",
    "    startind=(bbatch)*batchsz\n",
    "    endind=(bbatch+1)*batchsz\n",
    "    fd={batchsize_: train_loss_size, input_filt1_: input_bip1_train[:, startind:endind, :], \\\n",
    "             input_filt2_: input_bip2_train[:, startind:endind, :], input_filt3_: input_bip3_train[:, startind:endind, :],\\\n",
    "             input_filt4_: input_bip4_train[:, startind:endind, :], input_filt5_: input_bip5_train[:, startind:endind, :],\\\n",
    "             input_filt6_: input_bip6_train[:, startind:endind, :], input_filt7_: input_bip7_train[:, startind:endind, :],\\\n",
    "             input_filt8_: input_bip8_train[:, startind:endind, :], input_filt9_: input_bip9_train[:, startind:endind, :],\\\n",
    "             input_filt10_: input_bip10_train[:, startind:endind, :], input_filt11_: input_bip11_train[:, startind:endind, :],\\\n",
    "             input_filt12_: input_bip12_train[:, startind:endind, :], input_filt13_: input_bip13_train[:, startind:endind, :],\\\n",
    "             input_filt14_: input_bip14_train[:, startind:endind, :], input_filt15_: input_bip15_train[:, startind:endind, :],\\\n",
    "             input_filt16_: input_bip16_train[:, startind:endind, :]}\n",
    "    o_output[startind:endind, :]=np.reshape(sess.run([output], fd), [32, dur]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/Notebooks/kdd_sona43_sd95000.mat\n"
     ]
    }
   ],
   "source": [
    "# SAVE PARAMETER HISTORIES AND TRAINING HYPERPARAMSIB\n",
    "\n",
    "db={}\n",
    "\n",
    "# db['b1_out']=b1copy_out\n",
    "# db['am1_out']=am1_out\n",
    "# db['b11a1_mult']=b11a1_mult.eval(session=sess, feed_dict=singlefd)\n",
    "# db['b1copy_out']=b1copy_out\n",
    "# db['b2_out']=b2_out\n",
    "# db['b11_out']=b11_out\n",
    "# db['input1']=input1\n",
    "\n",
    "db['f1b1_syn_hist']=f1b1_syn_hist.eval(session=sess)\n",
    "db['f2b1_syn_hist']=f2b1_syn_hist.eval(session=sess)\n",
    "db['f3b1_syn_hist']=f3b1_syn_hist.eval(session=sess)\n",
    "db['f4b1_syn_hist']=f4b1_syn_hist.eval(session=sess)\n",
    "db['f5b1_syn_hist']=f5b1_syn_hist.eval(session=sess)\n",
    "db['f6b1_syn_hist']=f6b1_syn_hist.eval(session=sess)\n",
    "db['f7b1_syn_hist']=f7b1_syn_hist.eval(session=sess)\n",
    "db['f8b1_syn_hist']=f8b1_syn_hist.eval(session=sess)\n",
    "db['f9b1_syn_hist']=f9b1_syn_hist.eval(session=sess)\n",
    "db['f10b1_syn_hist']=f10b1_syn_hist.eval(session=sess)\n",
    "db['f11b1_syn_hist']=f11b1_syn_hist.eval(session=sess)\n",
    "db['f12b1_syn_hist']=f12b1_syn_hist.eval(session=sess)\n",
    "db['f13b1_syn_hist']=f13b1_syn_hist.eval(session=sess)\n",
    "db['f14b1_syn_hist']=f14b1_syn_hist.eval(session=sess)\n",
    "db['f15b1_syn_hist']=f15b1_syn_hist.eval(session=sess)\n",
    "db['f16b1_syn_hist']=f16b1_syn_hist.eval(session=sess)\n",
    "\n",
    "db['f1b2_syn_hist']=f1b2_syn_hist.eval(session=sess)\n",
    "db['f2b2_syn_hist']=f2b2_syn_hist.eval(session=sess)\n",
    "db['f3b2_syn_hist']=f3b2_syn_hist.eval(session=sess)\n",
    "db['f4b2_syn_hist']=f4b2_syn_hist.eval(session=sess)\n",
    "db['f5b2_syn_hist']=f5b2_syn_hist.eval(session=sess)\n",
    "db['f6b2_syn_hist']=f6b2_syn_hist.eval(session=sess)\n",
    "db['f7b2_syn_hist']=f7b2_syn_hist.eval(session=sess)\n",
    "db['f8b2_syn_hist']=f8b2_syn_hist.eval(session=sess)\n",
    "db['f9b2_syn_hist']=f9b2_syn_hist.eval(session=sess)\n",
    "db['f10b2_syn_hist']=f10b2_syn_hist.eval(session=sess)\n",
    "db['f11b2_syn_hist']=f11b2_syn_hist.eval(session=sess)\n",
    "db['f12b2_syn_hist']=f12b2_syn_hist.eval(session=sess)\n",
    "db['f13b2_syn_hist']=f13b2_syn_hist.eval(session=sess)\n",
    "db['f14b2_syn_hist']=f14b2_syn_hist.eval(session=sess)\n",
    "db['f15b2_syn_hist']=f15b2_syn_hist.eval(session=sess)\n",
    "db['f16b2_syn_hist']=f16b2_syn_hist.eval(session=sess)\n",
    "\n",
    "db['f1b11_syn_hist']=f1b11_syn_hist.eval(session=sess)\n",
    "db['f2b11_syn_hist']=f2b11_syn_hist.eval(session=sess)\n",
    "db['f3b11_syn_hist']=f3b11_syn_hist.eval(session=sess)\n",
    "db['f4b11_syn_hist']=f4b11_syn_hist.eval(session=sess)\n",
    "db['f5b11_syn_hist']=f5b11_syn_hist.eval(session=sess)\n",
    "db['f6b11_syn_hist']=f6b11_syn_hist.eval(session=sess)\n",
    "db['f7b11_syn_hist']=f7b11_syn_hist.eval(session=sess)\n",
    "db['f8b11_syn_hist']=f8b11_syn_hist.eval(session=sess)\n",
    "db['f9b11_syn_hist']=f9b11_syn_hist.eval(session=sess)\n",
    "db['f10b11_syn_hist']=f10b11_syn_hist.eval(session=sess)\n",
    "db['f11b11_syn_hist']=f11b11_syn_hist.eval(session=sess)\n",
    "db['f12b11_syn_hist']=f12b11_syn_hist.eval(session=sess)\n",
    "db['f13b11_syn_hist']=f13b11_syn_hist.eval(session=sess)\n",
    "db['f14b11_syn_hist']=f14b11_syn_hist.eval(session=sess)\n",
    "db['f15b11_syn_hist']=f15b11_syn_hist.eval(session=sess)\n",
    "db['f16b11_syn_hist']=f16b11_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip1_gc_syn_hist']=bip1_gc_syn_hist.eval(session=sess)\n",
    "db['bip2_gc_syn_hist']=bip2_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip11_gc_syn_hist']=bip11_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip1_copy_gc_syn_hist']=bip1_copy_gc_syn_hist.eval(session=sess)\n",
    "db['bip2_copy_gc_syn_hist']=bip2_copy_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip11_copy_gc_syn_hist']=bip11_copy_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip1_am1_syn_hist']=bip1_am1_syn_hist.eval(session=sess)\n",
    "db['bip2_am1_syn_hist']=bip2_am1_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip11_am1_syn_hist']=bip11_am1_syn_hist.eval(session=sess)\n",
    "\n",
    "db['am1_gc_syn_hist']=am1_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['am1_b1copy_syn_hist']=am1_b1copy_syn_hist.eval(session=sess)\n",
    "db['am1_b2copy_syn_hist']=am1_b2copy_syn_hist.eval(session=sess)\n",
    "\n",
    "db['b1_bias_hist']=b1_bias_hist.eval(session=sess)\n",
    "db['b2_bias_hist']=b2_bias_hist.eval(session=sess)\n",
    "db['b11_bias_hist']=b11_bias_hist.eval(session=sess)\n",
    "\n",
    "db['am1_bias_hist']=am1_bias_hist.eval(session=sess)\n",
    "db['gc_bias_hist']=gc_bias_hist.eval(session=sess)\n",
    "db['gc_stretch_hist']=gc_stretch_hist.eval(session=sess)\n",
    "\n",
    "db['output']=o_output\n",
    "\n",
    "db['loss_hist']=loss_hist\n",
    "db['batch_loss_hist']=batch_loss_hist\n",
    "db['test_hist']=test_hist\n",
    "\n",
    "db['learning_rate']=learn_rate\n",
    "db['lambda']=lambda1\n",
    "db['batch_size']=batchsize\n",
    "db['no_data_ex']=no_data_ex\n",
    "\n",
    "db['datapath']=datapath\n",
    "\n",
    "db['L1_hist']=L1_hist\n",
    "db['output_hist']=output_hist.eval(session=sess)\n",
    "\n",
    "\n",
    "\n",
    "if algorithm_choice==1: \n",
    "    db['algorithm']='Gradient_Descent'\n",
    "elif algorithm_choice==2:\n",
    "    db['algorithm']='Adam'\n",
    "    db['epsilon']=my_epsilon\n",
    "elif algorithm_choice==3:\n",
    "    db['algorithm']='Momentum'\n",
    "    db['momentum']=momentum_par\n",
    "elif algorithm_choice==4:\n",
    "    db['algorithm']='Adagrad'\n",
    "elif algorithm_choice==5:\n",
    "    db['algorithm']='RMSProp'\n",
    "\n",
    "sio.savemat(wheretosave, db)\n",
    "print(wheretosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
