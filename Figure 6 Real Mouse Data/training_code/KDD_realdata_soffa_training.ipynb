{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#path to save trained model\n",
    "sd=95000\n",
    "\n",
    "wheretosave='/home/ubuntu/Notebooks/kdd_soffa10_sd' + str(sd) + '.mat'\n",
    "\n",
    "no_data_ex=1600\n",
    "no_data_validation=162 \n",
    "no_data_test=160\n",
    "train_loss_size = 32 \n",
    "total_data_ex=5858 \n",
    "\n",
    "#number of pixels in training images\n",
    "numpix=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import hdf5storage\n",
    "from __future__ import division\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Handle training data: Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#load preconvolved stimuli\n",
    "\n",
    "datapath='/home/ubuntu/Notebooks/kdd_soffa_preconv_data.mat'\n",
    "\n",
    "data = hdf5storage.loadmat(datapath)\n",
    "\n",
    "## Handle training data: Stimuli convolved with bipolar cell kernels\n",
    "\n",
    "input_bip1_0 = data['b1_input']\n",
    "input_bip2_0 = data['b2_input']\n",
    "input_bip3_0 = data['b3_input']\n",
    "input_bip4_0 = data['b4_input']\n",
    "input_bip5_0 = data['b5_input']\n",
    "input_bip6_0 = data['b6_input']\n",
    "input_bip7_0 = data['b7_input']\n",
    "input_bip8_0 = data['b8_input']\n",
    "input_bip9_0 = data['b9_input']\n",
    "input_bip10_0 = data['b10_input']\n",
    "input_bip11_0 = data['b11_input']\n",
    "input_bip12_0 = data['b12_input']\n",
    "input_bip13_0 = data['b13_input']\n",
    "input_bip14_0 = data['b14_input']\n",
    "input_bip15_0 = data['b15_input']\n",
    "input_bip16_0 = data['b16_input']\n",
    "\n",
    "\n",
    "\n",
    "data_duration1=input_bip1_0.shape[1]\n",
    "print(data_duration1)\n",
    "\n",
    "data_duration = 990\n",
    "\n",
    "def rearrange_bip_input(input_bip_0, startind, endind):\n",
    "    input_bip_1 = reshape(input_bip_0, [1, total_data_ex, data_duration1, numpix])\n",
    "    input_bip_11 = input_bip_1[:, startind:endind, 7:997, :]\n",
    "    input_bip_2 = np.swapaxes(input_bip_11, 0, 3)\n",
    "    input_bip_3 = reshape(input_bip_2, [numpix, total_data_ex, data_duration])\n",
    "    return input_bip_3\n",
    "\n",
    "startind = 0\n",
    "endind = total_data_ex\n",
    "\n",
    "input_bip1_3 = rearrange_bip_input(input_bip1_0, startind, endind)\n",
    "input_bip2_3 = rearrange_bip_input(input_bip2_0, startind, endind)\n",
    "input_bip3_3 = rearrange_bip_input(input_bip3_0, startind, endind)\n",
    "input_bip4_3 = rearrange_bip_input(input_bip4_0, startind, endind)\n",
    "input_bip5_3 = rearrange_bip_input(input_bip5_0, startind, endind)\n",
    "input_bip6_3 = rearrange_bip_input(input_bip6_0, startind, endind)\n",
    "input_bip7_3 = rearrange_bip_input(input_bip7_0, startind, endind)\n",
    "input_bip8_3 = rearrange_bip_input(input_bip8_0, startind, endind)\n",
    "input_bip9_3 = rearrange_bip_input(input_bip9_0, startind, endind)\n",
    "input_bip10_3 = rearrange_bip_input(input_bip10_0, startind, endind)\n",
    "input_bip11_3 = rearrange_bip_input(input_bip11_0, startind, endind)\n",
    "input_bip12_3 = rearrange_bip_input(input_bip12_0, startind, endind)\n",
    "input_bip13_3 = rearrange_bip_input(input_bip13_0, startind, endind)\n",
    "input_bip14_3 = rearrange_bip_input(input_bip14_0, startind, endind)\n",
    "input_bip15_3 = rearrange_bip_input(input_bip15_0, startind, endind)\n",
    "input_bip16_3 = rearrange_bip_input(input_bip16_0, startind, endind)\n",
    "\n",
    "\n",
    "input_bip1_valid = input_bip1_3[:, 0:no_data_validation, :]\n",
    "input_bip1_train = input_bip1_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip1_test = input_bip1_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip2_valid = input_bip2_3[:, 0:no_data_validation, :]\n",
    "input_bip2_train = input_bip2_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip2_test = input_bip2_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip3_valid = input_bip3_3[:, 0:no_data_validation, :]\n",
    "input_bip3_train = input_bip3_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip3_test = input_bip3_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip4_valid = input_bip4_3[:, 0:no_data_validation, :]\n",
    "input_bip4_train = input_bip4_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip4_test = input_bip4_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip5_valid = input_bip5_3[:, 0:no_data_validation, :]\n",
    "input_bip5_train = input_bip5_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip5_test = input_bip5_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip6_valid = input_bip6_3[:, 0:no_data_validation, :]\n",
    "input_bip6_train = input_bip6_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip6_test = input_bip6_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip7_valid = input_bip7_3[:, 0:no_data_validation, :]\n",
    "input_bip7_train = input_bip7_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip7_test = input_bip7_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip8_valid = input_bip8_3[:, 0:no_data_validation, :]\n",
    "input_bip8_train = input_bip8_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip8_test = input_bip8_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip9_valid = input_bip9_3[:, 0:no_data_validation, :]\n",
    "input_bip9_train = input_bip9_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip9_test = input_bip9_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip10_valid = input_bip10_3[:, 0:no_data_validation, :]\n",
    "input_bip10_train = input_bip10_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip10_test = input_bip10_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "\n",
    "input_bip11_valid = input_bip11_3[:, 0:no_data_validation, :]\n",
    "input_bip11_train = input_bip11_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip11_test = input_bip11_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "\n",
    "input_bip12_valid = input_bip12_3[:, 0:no_data_validation, :]\n",
    "input_bip12_train = input_bip12_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip12_test = input_bip12_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip13_valid = input_bip13_3[:, 0:no_data_validation, :]\n",
    "input_bip13_train = input_bip13_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip13_test = input_bip13_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip14_valid = input_bip14_3[:, 0:no_data_validation, :]\n",
    "input_bip14_train = input_bip14_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip14_test = input_bip14_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip15_valid = input_bip15_3[:, 0:no_data_validation, :]\n",
    "input_bip15_train = input_bip15_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip15_test = input_bip15_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip16_valid = input_bip16_3[:, 0:no_data_validation, :]\n",
    "input_bip16_train = input_bip16_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip16_test = input_bip16_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load and handle ganglion cell responses\n",
    "\n",
    "\n",
    "datapath='/home/ubuntu/Notebooks/cell10_y_train.mat'\n",
    "data = hdf5storage.loadmat(datapath)\n",
    "\n",
    "y_train0 = 0.5*reshape(data['y_train'], [total_data_ex, 1, data_duration1])\n",
    "y_train0 = y_train0[0:total_data_ex, :, 0:990]\n",
    "\n",
    "y_valid = y_train0[ 0:no_data_validation, :, :]\n",
    "y_train = y_train0[no_data_validation:no_data_validation+no_data_ex, :, :]\n",
    "y_test = y_train0[no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :, :]\n",
    "\n",
    "gen_gc_w=[0.0, -0.5, 0.0, 1.0, 0.0]\n",
    "gen_gc_w=np.reshape(gen_gc_w, [5, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SET NUMBER OF NEURONS IN EACH LAYER\n",
    "no_filters=16 \n",
    "no_filters_per_bc_type=1\n",
    "\n",
    "no_bipolar_rows = 1\n",
    "no_bipolars= numpix*no_bipolar_rows\n",
    "no_bipolar_types=2 \n",
    "no_relu=0\n",
    "no_am_types = 5\n",
    "no_am1=8 \n",
    "no_am2=21\n",
    "no_am3=21\n",
    "no_gc=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## load and handle filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "\n",
    "def bias_var(shape, initial_val):\n",
    "    initial = tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "#     initial = tf.random_uniform(shape, minval=-1.0, maxval=0.0, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bg_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.1, maxval=0.8, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def ba_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.05, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def zero_synapse_var(shape, initial_val):\n",
    "#     initial_val=tf.zeros(shape=shape)\n",
    "    initial=tf.constant(0.0*initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "#     initial = tf.random_uniform(shape, minval=0.05, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.15, maxval=0.18, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def linear_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.05, maxval=0.08, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def fb_synapse_var(shape, initial_val):\n",
    "    initial_val = initial_val.astype(float32)\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "    \n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "#     initial = tf.random_uniform(shape, minval=0.1, maxval=0.8, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def ab_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.1, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def ag_synapse_var(shape, true_initial_val, train_initial_val):\n",
    "    initial=tf.constant(true_initial_val, shape=shape)\n",
    "#     initial=tf.constant(train_initial_val, shape=shape)\n",
    "    \n",
    "#     initial=tf.constant(true_initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.1, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def pbconv2d(x, W):\n",
    "    padsize=175 #200 #W.shape[0]\n",
    "    paddedx=tf.pad(x, [[0, 0], [padsize, 0], [0, 0], [0, 0]], 'CONSTANT')\n",
    "    outconv=tf.nn.conv2d(paddedx, W, strides=[1, 1, 1, 1], padding='SAME') #250 for movingdot and noise\n",
    "    #return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+250, 0, 0], [-1, 250, 1, 1])\n",
    "    return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+x_train.shape[1], 0, 0], [-1, x_train.shape[1], 1, 1])\n",
    "\n",
    "\n",
    "def gcconv2d(x, W):\n",
    "    padsize=5 #200 #W.shape[0]\n",
    "    paddedx=tf.pad(x, [[0, 0], [padsize, 0], [0, 0], [0, 0]], 'CONSTANT')\n",
    "    outconv=tf.nn.conv2d(paddedx, W, strides=[1, 1, 1, 1], padding='SAME') #250 for movingdot and noise\n",
    "    #return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+250, 0, 0], [-1, 250, 1, 1])\n",
    "    return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+data_duration, 0, 0], [-1, data_duration, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create input placeholder variables\n",
    "\n",
    "input_filt1_ = tf.placeholder(\"float32\", name=\"input_filt1\")\n",
    "input_filt2_ = tf.placeholder(\"float32\", name=\"input_filt2\")\n",
    "input_filt3_ = tf.placeholder(\"float32\", name=\"input_filt3\")\n",
    "input_filt4_ = tf.placeholder(\"float32\", name=\"input_filt4\")\n",
    "input_filt5_ = tf.placeholder(\"float32\", name=\"input_filt5\")\n",
    "input_filt6_ = tf.placeholder(\"float32\", name=\"input_filt6\")\n",
    "input_filt7_ = tf.placeholder(\"float32\", name=\"input_filt7\")\n",
    "input_filt8_ = tf.placeholder(\"float32\", name=\"input_filt8\")\n",
    "input_filt9_ = tf.placeholder(\"float32\", name=\"input_filt9\")\n",
    "input_filt10_ = tf.placeholder(\"float32\", name=\"input_filt10\")\n",
    "input_filt11_ = tf.placeholder(\"float32\", name=\"input_filt11\")\n",
    "input_filt12_ = tf.placeholder(\"float32\", name=\"input_filt12\")\n",
    "input_filt13_ = tf.placeholder(\"float32\", name=\"input_filt13\")\n",
    "input_filt14_ = tf.placeholder(\"float32\", name=\"input_filt14\")\n",
    "input_filt15_ = tf.placeholder(\"float32\", name=\"input_filt15\")\n",
    "input_filt16_ = tf.placeholder(\"float32\", name=\"input_filt16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO HAND ADJUST INITIALIZATIONS, USE PARAMS BELOW\n",
    "# NB: THIS IS FOR PLAYING AROUND/INSPECTION ONLY. \n",
    "# DURING ACTUAL TRAINING, VARIABLES ARE RANDOMLY INITIALIZED (see helper functions)\n",
    "\n",
    "b1g = [0.0]\n",
    "b2g = [0.0]\n",
    "b11g = [0.0]\n",
    "\n",
    "b1copyg = [0.0]\n",
    "b2copyg = [0.0]\n",
    "b11copyg = [0.0]\n",
    "\n",
    "b1b = 0.0\n",
    "b2b = -10.0\n",
    "b11b = -0.0 \n",
    "\n",
    "b1a1 = 0.0\n",
    "b2a1 = 0.0\n",
    "b11a1 = 1.0\n",
    "\n",
    "a1g = [0.0]\n",
    "\n",
    "a1b1copy = 5.0\n",
    "a1b2copy = 0.0\n",
    "\n",
    "\n",
    "bip1_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip1_gc_initial[bip_i, gc_i]=b1g[gc_i]\n",
    "bip1_gc_initial=bip1_gc_initial.astype(float32)\n",
    "\n",
    "bip2_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip2_gc_initial[bip_i, gc_i]=b2g[gc_i]\n",
    "bip2_gc_initial=bip2_gc_initial.astype(float32)\n",
    "\n",
    "\n",
    "bip11_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip11_gc_initial[bip_i, gc_i]=b11g[gc_i]\n",
    "bip11_gc_initial=bip11_gc_initial.astype(float32)\n",
    "\n",
    "\n",
    "\n",
    "bip1_copy_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip1_copy_gc_initial[bip_i, gc_i]=b1copyg[gc_i]\n",
    "bip1_copy_gc_initial=bip1_copy_gc_initial.astype(float32)\n",
    "\n",
    "bip2_copy_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(8):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip2_copy_gc_initial[bip_i, gc_i]=b2copyg[gc_i]\n",
    "bip2_copy_gc_initial=bip2_copy_gc_initial.astype(float32)\n",
    "\n",
    "\n",
    "bip11_copy_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(8):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip11_gc_initial[bip_i, gc_i]=b11copyg[gc_i]\n",
    "bip11_copy_gc_initial=bip11_copy_gc_initial.astype(float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "am1_b1copy_initial=np.zeros([no_am1, no_bipolars])\n",
    "for am_i in range(1):\n",
    "    for bip_i in range(4, 12):\n",
    "        am1_b1copy_initial[bip_i-4, bip_i]=a1b1copy\n",
    "am1_b1copy_initial=am1_b1copy_initial.astype(float32)\n",
    "\n",
    "am1_b2copy_initial=np.zeros([no_am1, no_bipolars])\n",
    "for am_i in range(3):\n",
    "    for bip_i in range(8):\n",
    "        am1_b2copy_initial[am_i, bip_i]=a1b2copy\n",
    "am1_b2copy_initial=am1_b2copy_initial.astype(float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "am1_gc_initial=np.zeros([no_am1, no_gc])\n",
    "for am_i in range(3):\n",
    "    for gc_i in range(no_gc):\n",
    "        am1_gc_initial[am_i, gc_i]=a1g[gc_i]\n",
    "am1_gc_initial=am1_gc_initial.astype(float32)\n",
    "\n",
    "am1_gc_train_initial=np.zeros([no_am1, no_gc])\n",
    "for am_i in range(no_am1):\n",
    "    am1_gc_train_initial[am_i, 0]=0.0*np.random.uniform()\n",
    "am1_gc_train_initial=am1_gc_train_initial.astype(float32)\n",
    "\n",
    "\n",
    "bip1_am1_initial=np.zeros([no_bipolars, no_am1])\n",
    "for am_i in range(1):\n",
    "    for bip_i in range(8, 16):\n",
    "        bip1_am1_initial[bip_i, am_i]=b1a1\n",
    "bip1_am1_initial=bip1_am1_initial.astype(float32)\n",
    "\n",
    "bip2_am1_initial=np.zeros([no_bipolars, no_am1])\n",
    "for am_i in range(1):\n",
    "    for bip_i in range(8, 16):\n",
    "        bip2_am1_initial[bip_i, am_i]=b2a1\n",
    "bip2_am1_initial=bip2_am1_initial.astype(float32)\n",
    "\n",
    "bip11_am1_initial=np.zeros([no_bipolars, no_am1])\n",
    "for bip_i in range(4, 12):\n",
    "#     for bip_i in range(4, 12):\n",
    "    bip11_am1_initial[bip_i-1, bip_i-4]=b11a1\n",
    "    bip11_am1_initial[bip_i, bip_i-4]=b11a1\n",
    "    bip11_am1_initial[bip_i+1, bip_i-4]=b11a1\n",
    "bip11_am1_initial=bip11_am1_initial.astype(float32)\n",
    "\n",
    "\n",
    "gc_stretch_initial=1.0*np.ones([no_gc, 1])\n",
    "gc_stretch_initial=gc_stretch_initial.astype(float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# load synaptic weight masks (derived from IPL address book)\n",
    "\n",
    "maskpath='/home/ubuntu/Notebooks/alpha_realdata_syn_weight_masks_2D_30pix.mat'\n",
    "mask=sio.loadmat(maskpath)\n",
    "\n",
    "bip1_gc_mask = mask['bip1_gc_mask']\n",
    "bip2_gc_mask = mask['bip2_gc_mask']\n",
    "bip11_gc_mask = mask['bip11_gc_mask']\n",
    "\n",
    "bip1_am1_mask = mask['bip1_am1_mask']\n",
    "bip2_am1_mask = mask['bip2_am1_mask']\n",
    "bip11_am1_mask = mask['bip11_am1_mask']\n",
    "\n",
    "am1_gc_mask = mask['am1_gc_mask']+1.0\n",
    "\n",
    "print(am1_gc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# INITIALIZE SYNAPTIC WEIGHT AND BIAS VARIABLES\n",
    "\n",
    "bip1_gc_syn=tf.math.multiply(synapse_var([no_bipolars, no_gc], bip1_gc_initial), bip1_gc_mask)\n",
    "\n",
    "bip2_gc_syn=tf.math.multiply(linear_synapse_var([no_bipolars, no_gc], bip2_gc_initial), bip2_gc_mask)\n",
    "# bip2_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip2_gc_initial), bip2_gc_mask)\n",
    "\n",
    "bip11_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip11_gc_initial), bip11_gc_mask)\n",
    "\n",
    "bip1_copy_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip1_copy_gc_initial), bip1_gc_mask)#20201215\n",
    "\n",
    "bip2_copy_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip2_copy_gc_initial), bip2_gc_mask)\n",
    "\n",
    "bip11_copy_gc_syn=tf.math.multiply(bg_synapse_var([no_bipolars, no_gc], bip11_copy_gc_initial), bip11_gc_mask)\n",
    "\n",
    "bip1_am1_syn = tf.math.multiply(ba_synapse_var([no_bipolars, no_am1], bip1_am1_initial), bip1_am1_mask)\n",
    "bip2_am1_syn = tf.math.multiply(ba_synapse_var([no_bipolars, no_am1], bip2_am1_initial), bip2_am1_mask)\n",
    "bip11_am1_syn = tf.math.multiply(ba_synapse_var([no_bipolars, no_am1], bip11_am1_initial), bip11_am1_mask)\n",
    "\n",
    "\n",
    "\n",
    "am1_gc_syn = tf.math.multiply(ag_synapse_var([no_am1, no_gc], am1_gc_initial, am1_gc_train_initial), am1_gc_mask)\n",
    "\n",
    "am1_b1copy_syn = ab_synapse_var([no_am1, no_bipolars], am1_b1copy_initial)\n",
    "\n",
    "am1_b2copy_syn = zero_synapse_var([no_am1, no_bipolars], am1_b2copy_initial)\n",
    "\n",
    "\n",
    "b1_bias_initial=b1b*np.ones([no_bipolars, 1])\n",
    "b1_bias_initial=b1_bias_initial.astype(float32)\n",
    "\n",
    "b2_bias_initial=b2b*np.ones([no_bipolars, 1])\n",
    "b2_bias_initial=b2_bias_initial.astype(float32)\n",
    "\n",
    "\n",
    "b11_bias_initial=b11b*np.ones([no_bipolars, 1])\n",
    "b11_bias_initial=b11_bias_initial.astype(float32)\n",
    "\n",
    "\n",
    "\n",
    "b1_bias=bias_var([no_bipolars, 1], b1_bias_initial)\n",
    "b2_bias=bias_var([no_bipolars, 1], b2_bias_initial)\n",
    "\n",
    "b11_bias=bias_var([no_bipolars, 1], b11_bias_initial)\n",
    "\n",
    "\n",
    "am1_bias_initial=-50.0*np.ones([no_am1, 1])\n",
    "am1_bias_initial=am1_bias_initial.astype(float32)\n",
    "am1_bias=bias_var([no_am1, 1], am1_bias_initial)\n",
    "\n",
    "gc_bias_initial = np.array([[0.0]])\n",
    "gc_bias_initial=gc_bias_initial.astype(float32)\n",
    "gc_bias=bias_var([no_gc, 1], gc_bias_initial)\n",
    "\n",
    "gc_stretch=synapse_var([no_gc, 1], gc_stretch_initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#INITIALIZE BIPOLAR CELL TEMPORAL KERNELS. three parameter sets modeled after biological bipolar cells.\n",
    "\n",
    "\n",
    "\n",
    "## slow filt\n",
    "f1b1=8.9629\n",
    "f2b1=-14.8934\n",
    "f3b1=-3.7342\n",
    "f4b1=-2.4524\n",
    "f5b1=-2.2385\n",
    "f6b1=4.8663\n",
    "f7b1=1.0306\n",
    "f8b1=-0.1179\n",
    "f9b1=-0.1026\n",
    "f10b1=0.1568\n",
    "f11b1=0.1731\n",
    "f12b1=0.1854\n",
    "f13b1=0.0526\n",
    "f14b1=-0.0769\n",
    "f15b1=-0.0104\n",
    "f16b1=-0.0069\n",
    "\n",
    "f1b2=8.9629\n",
    "f2b2=-14.8934\n",
    "f3b2=-3.7342\n",
    "f4b2=-2.4524\n",
    "f5b2=-2.2385\n",
    "f6b2=4.8663\n",
    "f7b2=1.0306\n",
    "f8b2=-0.1179\n",
    "f9b2=-0.1026\n",
    "f10b2=0.1568\n",
    "f11b2=0.1731\n",
    "f12b2=0.1854\n",
    "f13b2=0.0526\n",
    "f14b2=-0.0769\n",
    "f15b2=-0.0104\n",
    "f16b2=-0.0069\n",
    "\n",
    "f1b11=-8.9629\n",
    "f2b11=14.8934\n",
    "f3b11=3.7342\n",
    "f4b11=2.4524\n",
    "f5b11=2.2385\n",
    "f6b11=-4.8663\n",
    "f7b11=-1.0306\n",
    "f8b11=0.1179\n",
    "f9b11=0.1026\n",
    "f10b11=-0.1568\n",
    "f11b11=-0.1731\n",
    "f12b11=-0.1854\n",
    "f13b11=-0.0526\n",
    "f14b11=0.0769\n",
    "f15b11=0.0104\n",
    "f16b11=0.0069\n",
    "\n",
    "\n",
    "\n",
    "f1b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f1b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f2b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f2b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f3b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f3b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f4b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f4b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f5b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f5b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f6b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f6b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f7b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f7b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f8b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f8b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f9b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f9b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f10b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f10b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f11b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f11b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f12b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f12b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f13b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f13b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f14b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f14b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f15b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f15b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f16b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f16b1*np.ones([1, no_filters_per_bc_type]))\n",
    "\n",
    "f1b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f1b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f2b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f2b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f3b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f3b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f4b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f4b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f5b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f5b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f6b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f6b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f7b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f7b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f8b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f8b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f9b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f9b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f10b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f10b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f11b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f11b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f12b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f12b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f13b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f13b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f14b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f14b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f15b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f15b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f16b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f16b2*np.ones([1, no_filters_per_bc_type]))\n",
    "\n",
    "f1b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f1b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f2b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f2b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f3b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f3b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f4b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f4b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f5b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f5b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f6b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f6b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f7b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f7b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f8b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f8b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f9b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f9b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f10b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f10b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f11b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f11b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f12b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f12b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f13b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f13b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f14b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f14b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f15b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f15b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f16b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f16b11*np.ones([1, no_filters_per_bc_type]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dur=data_duration\n",
    "batchsize=32\n",
    "no_bip=no_bipolars\n",
    "\n",
    "batchsize_ = tf.placeholder(\"int32\", name=\"batch_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DEFINE ANN GRAPH\n",
    "\n",
    "@tf.function\n",
    "def biplayer(f1_input, f2_input, f3_input, f4_input, f5_input, f6_input, f7_input, f8_input, \n",
    "                f9_input, f10_input, f11_input, f12_input, f13_input, f14_input, f15_input, f16_input, \n",
    "                f1b_syn, f2b_syn, f3b_syn, f4b_syn, f5b_syn, f6b_syn, f7b_syn, f8b_syn, f9b_syn, f10b_syn, \n",
    "                f11b_syn, f12b_syn, f13b_syn, f14b_syn, f15b_syn, f16b_syn, b_bias, bip_gc_syn, no_bip, no_gc, batchsize, dur): #, no_bip, no_filt, batchsize, dur):\n",
    "    \n",
    "    f1b_syn=tf.broadcast_to(tf.reshape(f1b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f2b_syn=tf.broadcast_to(tf.reshape(f2b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f3b_syn=tf.broadcast_to(tf.reshape(f3b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f4b_syn=tf.broadcast_to(tf.reshape(f4b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f5b_syn=tf.broadcast_to(tf.reshape(f5b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f6b_syn=tf.broadcast_to(tf.reshape(f6b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f7b_syn=tf.broadcast_to(tf.reshape(f7b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f8b_syn=tf.broadcast_to(tf.reshape(f8b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f9b_syn=tf.broadcast_to(tf.reshape(f9b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f10b_syn=tf.broadcast_to(tf.reshape(f10b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f11b_syn=tf.broadcast_to(tf.reshape(f11b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f12b_syn=tf.broadcast_to(tf.reshape(f12b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f13b_syn=tf.broadcast_to(tf.reshape(f13b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f14b_syn=tf.broadcast_to(tf.reshape(f14b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f15b_syn=tf.broadcast_to(tf.reshape(f15b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f16b_syn=tf.broadcast_to(tf.reshape(f16b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    \n",
    "    f1_input=tf.tile(f1_input, [no_bipolar_rows, 1, 1])\n",
    "    f2_input=tf.tile(f2_input, [no_bipolar_rows, 1, 1])\n",
    "    f3_input=tf.tile(f3_input, [no_bipolar_rows, 1, 1])\n",
    "    f4_input=tf.tile(f4_input, [no_bipolar_rows, 1, 1])\n",
    "    f5_input=tf.tile(f5_input, [no_bipolar_rows, 1, 1])\n",
    "    f6_input=tf.tile(f6_input, [no_bipolar_rows, 1, 1])\n",
    "    f7_input=tf.tile(f7_input, [no_bipolar_rows, 1, 1])\n",
    "    f8_input=tf.tile(f8_input, [no_bipolar_rows, 1, 1])\n",
    "    f9_input=tf.tile(f9_input, [no_bipolar_rows, 1, 1])\n",
    "    f10_input=tf.tile(f10_input, [no_bipolar_rows, 1, 1])\n",
    "    f11_input=tf.tile(f11_input, [no_bipolar_rows, 1, 1])\n",
    "    f12_input=tf.tile(f12_input, [no_bipolar_rows, 1, 1])\n",
    "    f13_input=tf.tile(f13_input, [no_bipolar_rows, 1, 1])\n",
    "    f14_input=tf.tile(f14_input, [no_bipolar_rows, 1, 1])\n",
    "    f15_input=tf.tile(f15_input, [no_bipolar_rows, 1, 1])\n",
    "    f16_input=tf.tile(f16_input, [no_bipolar_rows, 1, 1])\n",
    "\n",
    "    \n",
    "    b_input = tf.add_n([tf.math.multiply(f1b_syn, f1_input), tf.math.multiply(f2b_syn, f2_input), tf.math.multiply(f3b_syn, f3_input),\\\n",
    "                        tf.math.multiply(f4b_syn, f4_input), tf.math.multiply(f5b_syn, f5_input), tf.math.multiply(f6b_syn, f6_input),\\\n",
    "                        tf.math.multiply(f7b_syn, f7_input), tf.math.multiply(f8b_syn, f8_input), tf.math.multiply(f9b_syn, f9_input),\\\n",
    "                        tf.math.multiply(f10b_syn, f10_input), tf.math.multiply(f11b_syn, f11_input), tf.math.multiply(f12b_syn, f12_input), \\\n",
    "                        tf.math.multiply(f13b_syn, f13_input), tf.math.multiply(f14b_syn, f14_input), tf.math.multiply(f15b_syn, f15_input), tf.math.multiply(f16b_syn, f16_input)])\n",
    "    b_bias_expand=tf.broadcast_to(tf.reshape(b_bias, [no_bipolars, 1, 1]), [no_bipolars, batchsize_, dur], name=\"bro1\")\n",
    "    b_bias_add=tf.add(b_input, b_bias_expand)\n",
    "    del b_input\n",
    "    del b_bias_expand\n",
    "    b_relu=tf.nn.relu(b_bias_add)\n",
    "    del b_bias_add\n",
    "    bip_layer_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize_, 1, dur]), [no_bip, batchsize_, no_gc, dur], name=\"bro2\")\n",
    "    \n",
    "    bg_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(bip_gc_syn), [no_bip, 1, no_gc, 1]), [no_bip, batchsize_, no_gc, dur], name=\"bro3\")\n",
    "    bg_mult=tf.math.multiply(bip_layer_expand, bg_syn_expand)\n",
    "    del bip_layer_expand \n",
    "    del bg_syn_expand\n",
    "    bg_sum=tf.reduce_sum(bg_mult, 0)\n",
    "    del bg_mult\n",
    "    return b_relu, bg_sum\n",
    "    \n",
    "@tf.function\n",
    "def linear_biplayer(f1_input, f2_input, f3_input, f4_input, f5_input, f6_input, f7_input, f8_input, \n",
    "                f9_input, f10_input, f11_input, f12_input, f13_input, f14_input, f15_input, f16_input, \n",
    "                f1b_syn, f2b_syn, f3b_syn, f4b_syn, f5b_syn, f6b_syn, f7b_syn, f8b_syn, f9b_syn, f10b_syn, \n",
    "                f11b_syn, f12b_syn, f13b_syn, f14b_syn, f15b_syn, f16b_syn, b_bias, bip_gc_syn, no_bip, no_gc, batchsize, dur): #, no_bip, no_filt, batchsize, dur):\n",
    "    \n",
    "    f1b_syn=tf.broadcast_to(tf.reshape(f1b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur], name='brosyn1')\n",
    "    f2b_syn=tf.broadcast_to(tf.reshape(f2b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f3b_syn=tf.broadcast_to(tf.reshape(f3b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f4b_syn=tf.broadcast_to(tf.reshape(f4b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f5b_syn=tf.broadcast_to(tf.reshape(f5b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f6b_syn=tf.broadcast_to(tf.reshape(f6b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f7b_syn=tf.broadcast_to(tf.reshape(f7b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f8b_syn=tf.broadcast_to(tf.reshape(f8b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f9b_syn=tf.broadcast_to(tf.reshape(f9b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f10b_syn=tf.broadcast_to(tf.reshape(f10b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f11b_syn=tf.broadcast_to(tf.reshape(f11b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f12b_syn=tf.broadcast_to(tf.reshape(f12b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f13b_syn=tf.broadcast_to(tf.reshape(f13b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f14b_syn=tf.broadcast_to(tf.reshape(f14b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f15b_syn=tf.broadcast_to(tf.reshape(f15b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f16b_syn=tf.broadcast_to(tf.reshape(f16b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    \n",
    "    f1_input=tf.tile(f1_input, [no_bipolar_rows, 1, 1])\n",
    "    f2_input=tf.tile(f2_input, [no_bipolar_rows, 1, 1])\n",
    "    f3_input=tf.tile(f3_input, [no_bipolar_rows, 1, 1])\n",
    "    f4_input=tf.tile(f4_input, [no_bipolar_rows, 1, 1])\n",
    "    f5_input=tf.tile(f5_input, [no_bipolar_rows, 1, 1])\n",
    "    f6_input=tf.tile(f6_input, [no_bipolar_rows, 1, 1])\n",
    "    f7_input=tf.tile(f7_input, [no_bipolar_rows, 1, 1])\n",
    "    f8_input=tf.tile(f8_input, [no_bipolar_rows, 1, 1])\n",
    "    f9_input=tf.tile(f9_input, [no_bipolar_rows, 1, 1])\n",
    "    f10_input=tf.tile(f10_input, [no_bipolar_rows, 1, 1])\n",
    "    f11_input=tf.tile(f11_input, [no_bipolar_rows, 1, 1])\n",
    "    f12_input=tf.tile(f12_input, [no_bipolar_rows, 1, 1])\n",
    "    f13_input=tf.tile(f13_input, [no_bipolar_rows, 1, 1])\n",
    "    f14_input=tf.tile(f14_input, [no_bipolar_rows, 1, 1])\n",
    "    f15_input=tf.tile(f15_input, [no_bipolar_rows, 1, 1])\n",
    "    f16_input=tf.tile(f16_input, [no_bipolar_rows, 1, 1])\n",
    "\n",
    "    \n",
    "\n",
    "    b_input = tf.add_n([tf.math.multiply(f1b_syn, f1_input), tf.math.multiply(f2b_syn, f2_input), tf.math.multiply(f3b_syn, f3_input),\\\n",
    "                        tf.math.multiply(f4b_syn, f4_input), tf.math.multiply(f5b_syn, f5_input), tf.math.multiply(f6b_syn, f6_input),\\\n",
    "                        tf.math.multiply(f7b_syn, f7_input), tf.math.multiply(f8b_syn, f8_input), tf.math.multiply(f9b_syn, f9_input),\\\n",
    "                        tf.math.multiply(f10b_syn, f10_input), tf.math.multiply(f11b_syn, f11_input), tf.math.multiply(f12b_syn, f12_input), \\\n",
    "                        tf.math.multiply(f13b_syn, f13_input), tf.math.multiply(f14b_syn, f14_input), tf.math.multiply(f15b_syn, f15_input), tf.math.multiply(f16b_syn, f16_input)])\n",
    "    b_bias_expand=tf.broadcast_to(tf.reshape(b_bias, [no_bipolars, 1, 1]), [no_bipolars, batchsize_, dur], name=\"bro1\")\n",
    "    b_bias_add=tf.add(b_input, b_bias_expand)\n",
    "    del b_input\n",
    "    del b_bias_expand\n",
    "    b_relu=b_bias_add\n",
    "    del b_bias_add\n",
    "    bip_layer_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize_, 1, dur]), [no_bip, batchsize_, no_gc, dur], name=\"bro2\")\n",
    "\n",
    "    bg_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(bip_gc_syn), [no_bip, 1, no_gc, 1]), [no_bip, batchsize_, no_gc, dur], name=\"bro3\")\n",
    "    bg_mult=tf.math.multiply(bip_layer_expand, bg_syn_expand)\n",
    "    del bip_layer_expand\n",
    "    del bg_syn_expand\n",
    "    bg_sum=tf.reduce_sum(bg_mult, 0)\n",
    "    del bg_mult\n",
    "    return b_relu, bg_sum\n",
    "    \n",
    "\n",
    "b1_relu, b1g_sum = biplayer(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                            input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                            input_filt14_, input_filt15_, input_filt16_, f1b1_syn, f2b1_syn, f3b1_syn, f4b1_syn, f5b1_syn,\n",
    "                            f6b1_syn, f7b1_syn, f8b1_syn, f9b1_syn, f10b1_syn, f11b1_syn, f12b1_syn, f13b1_syn, f14b1_syn, \n",
    "                            f15b1_syn, f16b1_syn, b1_bias, bip1_gc_syn, no_bip, no_gc, batchsize_, dur)\n",
    "\n",
    "b2_relu, b2g_sum = linear_biplayer(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                                   input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                                   input_filt14_, input_filt15_, input_filt16_, f1b2_syn, f2b2_syn, f3b2_syn, f4b2_syn, f5b2_syn,\n",
    "                                   f6b2_syn, f7b2_syn, f8b2_syn, f9b2_syn, f10b2_syn, f11b2_syn, f12b2_syn, f13b2_syn, f14b2_syn, \n",
    "                                   f15b2_syn, f16b2_syn, b2_bias, bip2_gc_syn, no_bip, no_gc, batchsize_, dur)\n",
    "\n",
    "\n",
    "b11_relu, b11g_sum = biplayer(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                              input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                              input_filt14_, input_filt15_, input_filt16_, f1b11_syn, f2b11_syn, f3b11_syn, f4b11_syn, f5b11_syn,\n",
    "                              f6b11_syn, f7b11_syn, f8b11_syn, f9b11_syn, f10b11_syn, f11b11_syn, f12b11_syn, f13b11_syn, f14b11_syn, \n",
    "                              f15b11_syn, f16b11_syn, b11_bias, bip11_gc_syn, no_bip, no_gc, batchsize_, dur)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def bip_to_am_input(b_relu, bip_am_syn, no_bip, no_am, batchsize, dur):\n",
    "    bip_layer_am_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize, 1, dur]), [no_bip, batchsize, no_am, dur], name=\"bro10\")\n",
    "    ba_syn_expand = tf.broadcast_to(tf.reshape(tf.abs(bip_am_syn), [no_bip, 1, no_am, 1]), [no_bip, batchsize, no_am, dur], name=\"bro11\")\n",
    "    del b_relu\n",
    "    ba_mult = tf.math.multiply(bip_layer_am_expand, ba_syn_expand)\n",
    "    del bip_layer_am_expand\n",
    "    del ba_syn_expand\n",
    "    ba_sum = tf.reduce_sum(ba_mult, 0)\n",
    "    return ba_mult, ba_sum\n",
    "\n",
    "b11a1_mult, b11a1_sum = bip_to_am_input(b11_relu, bip11_am1_syn, no_bip, no_am1, batchsize_, dur)\n",
    "\n",
    "am1_activation = tf.add_n([b11a1_sum])\n",
    "\n",
    "am1_bias_expand = tf.broadcast_to(am1_bias, [batchsize_, no_am1, dur], name=\"bro20\")\n",
    "\n",
    "am1_bias_add = tf.add(am1_activation, am1_bias_expand)\n",
    "del am1_bias_expand\n",
    "\n",
    "\n",
    "am1_output = tf.nn.relu(am1_bias_add)\n",
    "del am1_bias_add\n",
    "\n",
    "am1_reshape = tf.reshape(am1_output, [batchsize_, no_am1, 1, dur])\n",
    "am1_expand=tf.broadcast_to(am1_reshape, [batchsize_, no_am1, no_gc, dur], name=\"bro22\")\n",
    "am1g_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(am1_gc_syn), [1, no_am1, no_gc, 1]), [batchsize_, no_am1, no_gc, dur], name=\"bro23\")\n",
    "am1g_mult=tf.math.multiply(am1_expand, am1g_syn_expand)\n",
    "del am1_expand\n",
    "del am1g_syn_expand\n",
    "am1g_sum=tf.reduce_sum(am1g_mult, 1)\n",
    "del am1g_mult\n",
    "\n",
    "\n",
    "\n",
    "am1_bcopy_expand=tf.broadcast_to(am1_reshape, [batchsize_, no_am1, no_bip, dur], name=\"bro26\")\n",
    "del am1_reshape\n",
    "\n",
    "@tf.function\n",
    "def biplayer_copy_input(f1_input, f2_input, f3_input, f4_input, f5_input, f6_input, f7_input, f8_input, \n",
    "                        f9_input, f10_input, f11_input, f12_input, f13_input, f14_input, f15_input, f16_input, \n",
    "                        f1b_syn, f2b_syn, f3b_syn, f4b_syn, f5b_syn, f6b_syn, f7b_syn, f8b_syn, f9b_syn, f10b_syn, \n",
    "                        f11b_syn, f12b_syn, f13b_syn, f14b_syn, f15b_syn, f16b_syn,am_bcopy_expand, am_bcopy_syn, b_bias, bip_copy_gc_syn, no_bip, no_am, no_gc, batchsize, dur):\n",
    "    \n",
    "    f1b_syn=tf.broadcast_to(tf.reshape(f1b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f2b_syn=tf.broadcast_to(tf.reshape(f2b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f3b_syn=tf.broadcast_to(tf.reshape(f3b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f4b_syn=tf.broadcast_to(tf.reshape(f4b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f5b_syn=tf.broadcast_to(tf.reshape(f5b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f6b_syn=tf.broadcast_to(tf.reshape(f6b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f7b_syn=tf.broadcast_to(tf.reshape(f7b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f8b_syn=tf.broadcast_to(tf.reshape(f8b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f9b_syn=tf.broadcast_to(tf.reshape(f9b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f10b_syn=tf.broadcast_to(tf.reshape(f10b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f11b_syn=tf.broadcast_to(tf.reshape(f11b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f12b_syn=tf.broadcast_to(tf.reshape(f12b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f13b_syn=tf.broadcast_to(tf.reshape(f13b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f14b_syn=tf.broadcast_to(tf.reshape(f14b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f15b_syn=tf.broadcast_to(tf.reshape(f15b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f16b_syn=tf.broadcast_to(tf.reshape(f16b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    \n",
    "    f1_input=tf.tile(f1_input, [no_bipolar_rows, 1, 1])\n",
    "    f2_input=tf.tile(f2_input, [no_bipolar_rows, 1, 1])\n",
    "    f3_input=tf.tile(f3_input, [no_bipolar_rows, 1, 1])\n",
    "    f4_input=tf.tile(f4_input, [no_bipolar_rows, 1, 1])\n",
    "    f5_input=tf.tile(f5_input, [no_bipolar_rows, 1, 1])\n",
    "    f6_input=tf.tile(f6_input, [no_bipolar_rows, 1, 1])\n",
    "    f7_input=tf.tile(f7_input, [no_bipolar_rows, 1, 1])\n",
    "    f8_input=tf.tile(f8_input, [no_bipolar_rows, 1, 1])\n",
    "    f9_input=tf.tile(f9_input, [no_bipolar_rows, 1, 1])\n",
    "    f10_input=tf.tile(f10_input, [no_bipolar_rows, 1, 1])\n",
    "    f11_input=tf.tile(f11_input, [no_bipolar_rows, 1, 1])\n",
    "    f12_input=tf.tile(f12_input, [no_bipolar_rows, 1, 1])\n",
    "    f13_input=tf.tile(f13_input, [no_bipolar_rows, 1, 1])\n",
    "    f14_input=tf.tile(f14_input, [no_bipolar_rows, 1, 1])\n",
    "    f15_input=tf.tile(f15_input, [no_bipolar_rows, 1, 1])\n",
    "    f16_input=tf.tile(f16_input, [no_bipolar_rows, 1, 1])\n",
    "\n",
    "    \n",
    "    b_input = tf.add_n([tf.math.multiply(f1b_syn, f1_input), tf.math.multiply(f2b_syn, f2_input), tf.math.multiply(f3b_syn, f3_input),\\\n",
    "                        tf.math.multiply(f4b_syn, f4_input), tf.math.multiply(f5b_syn, f5_input), tf.math.multiply(f6b_syn, f6_input),\\\n",
    "                        tf.math.multiply(f7b_syn, f7_input), tf.math.multiply(f8b_syn, f8_input), tf.math.multiply(f9b_syn, f9_input),\\\n",
    "                        tf.math.multiply(f10b_syn, f10_input), tf.math.multiply(f11b_syn, f11_input), tf.math.multiply(f12b_syn, f12_input), \\\n",
    "                        tf.math.multiply(f13b_syn, f13_input), tf.math.multiply(f14b_syn, f14_input), tf.math.multiply(f15b_syn, f15_input), tf.math.multiply(f16b_syn, f16_input)])\n",
    "    ambcopy_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(am_bcopy_syn), [1, no_am, no_bip, 1]), [batchsize, no_am, no_bip, dur], name=\"bro33\")\n",
    "    ambcopy_mult=tf.math.multiply(am_bcopy_expand, ambcopy_syn_expand)\n",
    "    del am_bcopy_expand\n",
    "    del ambcopy_syn_expand\n",
    "    ambcopy_sum1=tf.squeeze(tf.reduce_sum(ambcopy_mult, 1))\n",
    "    ambcopy_sum=tf.transpose(ambcopy_sum1, [1, 0, 2])\n",
    "    \n",
    "    del ambcopy_mult\n",
    "    del ambcopy_sum1\n",
    "    \n",
    "    b_bias_expand=tf.broadcast_to(tf.reshape(b_bias, [no_bipolars, 1, 1]), [no_bipolars, batchsize, dur], name=\"bro1\")\n",
    "    b_bias_add=tf.add_n([b_input,-1.0*ambcopy_sum, b_bias_expand])\n",
    "    del b_input\n",
    "    del b_bias_expand\n",
    "    b_relu=tf.nn.relu(b_bias_add)\n",
    "    del b_bias_add\n",
    "    bip_layer_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize_, 1, dur]), [no_bip, batchsize, no_gc, dur], name=\"bro2\")\n",
    "\n",
    "    bg_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(10.0*bip_copy_gc_syn), [no_bip, 1, no_gc, 1]), [no_bip, batchsize, no_gc, dur], name=\"bro3\")\n",
    "    bg_mult=tf.math.multiply(bip_layer_expand, bg_syn_expand)\n",
    "    del bip_layer_expand\n",
    "    del bg_syn_expand\n",
    "    bg_sum=tf.reduce_sum(bg_mult, 0)\n",
    "    del bg_mult\n",
    "    return b_relu, bg_sum\n",
    "\n",
    "b1copy_relu, b1copyg_sum = biplayer_copy_input(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                                  input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                                  input_filt14_, input_filt15_, input_filt16_, f1b1_syn, f2b1_syn, f3b1_syn, f4b1_syn, f5b1_syn,\n",
    "                                  f6b1_syn, f7b1_syn, f8b1_syn, f9b1_syn, f10b1_syn, f11b1_syn, f12b1_syn, f13b1_syn, f14b1_syn, \n",
    "                                  f15b1_syn, f16b1_syn, am1_bcopy_expand, am1_b1copy_syn, b1_bias, bip1_copy_gc_syn, no_bip, \n",
    "                                  no_am1, no_gc, batchsize_, dur)\n",
    "b2copy_relu, b2copyg_sum = biplayer_copy_input(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                                  input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                                  input_filt14_, input_filt15_, input_filt16_, f1b2_syn, f2b2_syn, f3b2_syn, f4b2_syn, f5b2_syn,\n",
    "                                  f6b2_syn, f7b2_syn, f8b2_syn, f9b2_syn, f10b2_syn, f11b2_syn, f12b2_syn, f13b2_syn, f14b2_syn, \n",
    "                                  f15b2_syn, f16b2_syn,am1_bcopy_expand, am1_b2copy_syn, b2_bias, bip2_copy_gc_syn, \n",
    "                                  no_bip, no_am1, no_gc, batchsize_, dur)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gc_activation=tf.add_n([b1copyg_sum, b2copyg_sum, b1g_sum, b2g_sum, -1.0*am1g_sum])\n",
    "\n",
    "\n",
    "pre_gc=tf.reshape(tf.squeeze(gcconv2d(tf.reshape(gc_activation, [batchsize_, dur, 1, 1]) , gen_gc_w)), [batchsize_, no_gc, dur])\n",
    "# pre_gc=gc_activation\n",
    "\n",
    "del b1copyg_sum\n",
    "del b2copyg_sum\n",
    "del b1g_sum\n",
    "del b2g_sum\n",
    "del am1g_sum\n",
    "\n",
    "\n",
    "gc_bias_expand=tf.broadcast_to(gc_bias, [batchsize_, no_gc, dur])\n",
    "\n",
    "gc_bias_add=tf.add(pre_gc, gc_bias_expand)\n",
    "\n",
    "output=4.0*gc_stretch*tf.nn.relu(gc_bias_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(\"float\", name=\"output_spikes\")\n",
    "learn_rate=1e-3\n",
    "\n",
    "trainsampfd={batchsize_: train_loss_size, input_filt1_: input_bip1_train[:, 0:train_loss_size, :], \\\n",
    "             input_filt2_: input_bip2_train[:, 0:train_loss_size, :], input_filt3_: input_bip3_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt4_: input_bip4_train[:, 0:train_loss_size, :], input_filt5_: input_bip5_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt6_: input_bip6_train[:, 0:train_loss_size, :], input_filt7_: input_bip7_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt8_: input_bip8_train[:, 0:train_loss_size, :], input_filt9_: input_bip9_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt10_: input_bip10_train[:, 0:train_loss_size, :], input_filt11_: input_bip11_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt12_: input_bip12_train[:, 0:train_loss_size, :], input_filt13_: input_bip13_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt14_: input_bip14_train[:, 0:train_loss_size, :], input_filt15_: input_bip15_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt16_: input_bip16_train[:, 0:train_loss_size, :], y_:y_train[0:train_loss_size, :, :]}\n",
    "\n",
    "singlefd={batchsize_: 32, input_filt1_: input_bip1_train[:, 0:32, :], \\\n",
    "          input_filt2_: input_bip2_train[:, 0:32, :], input_filt3_: input_bip3_train[:, 0:32, :],\\\n",
    "          input_filt4_: input_bip4_train[:, 0:32, :], input_filt5_: input_bip5_train[:, 0:32, :],\\\n",
    "          input_filt6_: input_bip6_train[:, 0:32, :], input_filt7_: input_bip7_train[:, 0:32, :],\\\n",
    "          input_filt8_: input_bip8_train[:, 0:32, :], input_filt9_: input_bip9_train[:, 0:32, :],\\\n",
    "          input_filt10_: input_bip10_train[:, 0:32, :], input_filt11_: input_bip11_train[:, 0:32, :],\\\n",
    "          input_filt12_: input_bip12_train[:, 0:32, :], input_filt13_: input_bip13_train[:, 0:32, :],\\\n",
    "          input_filt14_: input_bip14_train[:, 0:32, :], input_filt15_: input_bip15_train[:, 0:32, :],\\\n",
    "          input_filt16_: input_bip16_train[:, 0:32, :], y_:y_train[0:32, :, :]}\n",
    "\n",
    "\n",
    "batchsize= 32\n",
    "\n",
    "# L2 loss (normalized)\n",
    "loss = (tf.nn.l2_loss((output - y_), name='loss'))/(batchsize*data_duration) \n",
    "single_loss = tf.reduce_sum((abs(output - y_))/(batchsize*data_duration), 1)\n",
    "\n",
    "# L1 regularization on weights and output\n",
    "reg1 = tf.add_n([tf.reduce_sum(tf.abs(bip1_gc_syn)), tf.reduce_sum(tf.abs(bip2_gc_syn)),  tf.reduce_sum(tf.abs(bip11_gc_syn))])\n",
    "reg2 = tf.add_n([tf.reduce_sum(tf.abs(bip1_copy_gc_syn)), tf.reduce_sum(tf.abs(bip2_copy_gc_syn)), tf.reduce_sum(tf.abs(bip11_copy_gc_syn))])\n",
    "reg3 = tf.add_n([tf.reduce_sum(tf.abs(bip1_am1_syn)), tf.reduce_sum(tf.abs(bip2_am1_syn)), tf.reduce_sum(tf.abs(bip11_am1_syn))])\n",
    "reg5 = tf.add_n([tf.reduce_sum(tf.abs(am1_gc_syn))])\n",
    "reg6 = tf.add_n([tf.reduce_sum(tf.abs(am1_b1copy_syn)), tf.reduce_sum(tf.abs(am1_b2copy_syn))])\n",
    "reg7 = 1e-4*tf.reduce_sum(tf.abs(output))\n",
    "# regularizer=tf.add_n([reg1, reg2, reg3, reg5, reg6, reg7])\n",
    "regularizer=tf.add_n([reg1, reg3, reg5])\n",
    "\n",
    "\n",
    "\n",
    "# lambda1=1e-1 \n",
    "lambda1=1e1 \n",
    "\n",
    "objective=tf.add(loss, lambda1*regularizer)\n",
    "\n",
    "algorithm_choice=2  #1\n",
    "\n",
    "if algorithm_choice==1:\n",
    "    train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(objective)\n",
    "elif algorithm_choice==2:\n",
    "    my_epsilon=1e-4 #1e-8\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=learn_rate, epsilon=my_epsilon).minimize(objective)\n",
    "elif algorithm_choice==3:\n",
    "    momentum_par=0.9\n",
    "    train_step = tf.train.MomentumOptimizer(learn_rate, momentum_par).minimize(objective)\n",
    "elif algorithm_choice==4:\n",
    "    train_step = tf.train.AdagradOptimizer(learn_rate).minimize(objective)\n",
    "elif algorithm_choice==5:\n",
    "    train_step = tf.train.RMSPropOptimizer(learn_rate).minimize(objective)\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialize arrays to store weight histories\n",
    "\n",
    "f1b1_syn_hist=tf.reshape(f1b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f2b1_syn_hist=tf.reshape(f2b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f3b1_syn_hist=tf.reshape(f3b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f4b1_syn_hist=tf.reshape(f4b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f5b1_syn_hist=tf.reshape(f5b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f6b1_syn_hist=tf.reshape(f6b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f7b1_syn_hist=tf.reshape(f7b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f8b1_syn_hist=tf.reshape(f8b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f9b1_syn_hist=tf.reshape(f9b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f10b1_syn_hist=tf.reshape(f10b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f11b1_syn_hist=tf.reshape(f11b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f12b1_syn_hist=tf.reshape(f12b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f13b1_syn_hist=tf.reshape(f13b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f14b1_syn_hist=tf.reshape(f14b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f15b1_syn_hist=tf.reshape(f15b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f16b1_syn_hist=tf.reshape(f16b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "\n",
    "f1b2_syn_hist=tf.reshape(f1b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f2b2_syn_hist=tf.reshape(f2b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f3b2_syn_hist=tf.reshape(f3b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f4b2_syn_hist=tf.reshape(f4b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f5b2_syn_hist=tf.reshape(f5b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f6b2_syn_hist=tf.reshape(f6b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f7b2_syn_hist=tf.reshape(f7b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f8b2_syn_hist=tf.reshape(f8b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f9b2_syn_hist=tf.reshape(f9b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f10b2_syn_hist=tf.reshape(f10b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f11b2_syn_hist=tf.reshape(f11b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f12b2_syn_hist=tf.reshape(f12b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f13b2_syn_hist=tf.reshape(f13b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f14b2_syn_hist=tf.reshape(f14b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f15b2_syn_hist=tf.reshape(f15b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f16b2_syn_hist=tf.reshape(f16b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "\n",
    "f1b11_syn_hist=tf.reshape(f1b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f2b11_syn_hist=tf.reshape(f2b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f3b11_syn_hist=tf.reshape(f3b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f4b11_syn_hist=tf.reshape(f4b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f5b11_syn_hist=tf.reshape(f5b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f6b11_syn_hist=tf.reshape(f6b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f7b11_syn_hist=tf.reshape(f7b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f8b11_syn_hist=tf.reshape(f8b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f9b11_syn_hist=tf.reshape(f9b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f10b11_syn_hist=tf.reshape(f10b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f11b11_syn_hist=tf.reshape(f11b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f12b11_syn_hist=tf.reshape(f12b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f13b11_syn_hist=tf.reshape(f13b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f14b11_syn_hist=tf.reshape(f14b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f15b11_syn_hist=tf.reshape(f15b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f16b11_syn_hist=tf.reshape(f16b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "\n",
    "bip1_gc_syn_hist=tf.reshape(bip1_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip2_gc_syn_hist=tf.reshape(bip2_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip11_gc_syn_hist=tf.reshape(bip11_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "\n",
    "\n",
    "bip1_copy_gc_syn_hist=tf.reshape(bip1_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip2_copy_gc_syn_hist=tf.reshape(bip2_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip11_copy_gc_syn_hist=tf.reshape(bip11_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "\n",
    "\n",
    "b1_bias_hist=tf.reshape(b1_bias.eval(session=sess), [1, no_bipolars])\n",
    "b2_bias_hist=tf.reshape(b2_bias.eval(session=sess), [1, no_bipolars])\n",
    "b11_bias_hist=tf.reshape(b11_bias.eval(session=sess), [1, no_bipolars])\n",
    "\n",
    "\n",
    "am1_bias_hist=tf.reshape(am1_bias.eval(session=sess), [1, no_am1])\n",
    "gc_bias_hist=tf.reshape(gc_bias.eval(session=sess), [1, no_gc])\n",
    "\n",
    "gc_stretch_hist=tf.reshape(gc_stretch.eval(session=sess), [1, no_gc])\n",
    "\n",
    "bip1_am1_syn_hist=tf.reshape(bip1_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])\n",
    "bip2_am1_syn_hist=tf.reshape(bip2_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])\n",
    "bip11_am1_syn_hist=tf.reshape(bip11_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])\n",
    "\n",
    "am1_b1copy_syn_hist=tf.reshape(am1_b1copy_syn.eval(session=sess), [1, no_am1, no_bipolars])\n",
    "am1_b2copy_syn_hist=tf.reshape(am1_b2copy_syn.eval(session=sess), [1, no_am1, no_bipolars])\n",
    "\n",
    "am1_gc_syn_hist=tf.reshape(am1_gc_syn.eval(session=sess), [1, no_am1, no_gc])\n",
    "\n",
    "output_hist=tf.reshape(output.eval(session=sess, feed_dict=singlefd), [1, 32, data_duration])\n",
    "\n",
    "#loss\n",
    "loss_hist = ones([1])\n",
    "valid_hist = ones([1])\n",
    "test_hist = ones([1])\n",
    "\n",
    "\n",
    "check=1.0\n",
    "step=0\n",
    "end_flag=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.95381986177884\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE LOSS AT ANN INITIALIZATION\n",
    "\n",
    "loss_val = (batchsize/78.0)*sess.run(loss, feed_dict= trainsampfd)\n",
    "print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# INITIALIZE LOSS HISTORIES\n",
    "\n",
    "fddd={batchsize_: no_data_test, input_filt1_: input_bip1_test, \\\n",
    "          input_filt2_: input_bip2_test, input_filt3_: input_bip3_test,\\\n",
    "          input_filt4_: input_bip4_test, input_filt5_: input_bip5_test,\\\n",
    "          input_filt6_: input_bip6_test, input_filt7_: input_bip7_test,\\\n",
    "          input_filt8_: input_bip8_test, input_filt9_: input_bip9_test,\\\n",
    "          input_filt10_: input_bip10_test, input_filt11_: input_bip11_test,\\\n",
    "          input_filt12_: input_bip12_test, input_filt13_: input_bip13_test,\\\n",
    "          input_filt14_: input_bip14_test, input_filt15_: input_bip15_test,\\\n",
    "          input_filt16_: input_bip16_test, y_:y_test}\n",
    "\n",
    "test_loss = (batchsize/input_bip1_test.shape[1])*sess.run(loss, feed_dict=fddd)\n",
    "\n",
    "loss_hist=loss_val*loss_hist\n",
    "test_hist=test_loss*test_hist\n",
    "\n",
    "batch_loss_hist=np.zeros([1])\n",
    "batch_loss_hist=batch_loss_hist.astype(float32)\n",
    "L1_hist=np.zeros([1])\n",
    "L1_hist=L1_hist.astype(float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_bias_hist.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  loss: = 170.437027 \n",
      "\n",
      "step: 1  loss: = 153.893250 \n",
      "\n",
      "step: 2  loss: = 145.033569 \n",
      "\n",
      "step: 3  loss: = 140.046677 \n",
      "\n",
      "step: 4  loss: = 138.214630 \n",
      "\n",
      "step: 5  loss: = 138.503555 \n",
      "\n",
      "step: 6  loss: = 138.793747 \n",
      "\n",
      "step: 7  loss: = 139.186050 \n",
      "\n",
      "step: 8  loss: = 139.582352 \n",
      "\n",
      "step: 9  loss: = 139.341583 \n",
      "\n",
      "step: 10  loss: = 139.429123 \n",
      "\n",
      "step: 11  loss: = 139.558182 \n",
      "\n",
      "step: 12  loss: = 138.933777 \n",
      "\n",
      "step: 13  loss: = 139.036209 \n",
      "\n",
      "step: 14  loss: = 138.589737 \n",
      "\n",
      "step: 15  loss: = 138.382736 \n",
      "\n",
      "step: 16  loss: = 137.772156 \n",
      "\n",
      "step: 17  loss: = 137.836090 \n",
      "\n",
      "step: 18  loss: = 137.329742 \n",
      "\n",
      "step: 19  loss: = 137.342514 \n",
      "\n",
      "step: 20  loss: = 136.659210 \n",
      "\n",
      "step: 21  loss: = 136.417664 \n",
      "\n",
      "step: 22  loss: = 136.429398 \n",
      "\n",
      "step: 23  loss: = 136.035309 \n",
      "\n",
      "step: 24  loss: = 135.697037 \n",
      "\n",
      "step: 25  loss: = 135.520737 \n",
      "\n",
      "step: 26  loss: = 135.116165 \n",
      "\n",
      "step: 27  loss: = 135.527939 \n",
      "\n",
      "step: 28  loss: = 134.966309 \n",
      "\n",
      "step: 29  loss: = 134.767014 \n",
      "\n",
      "step: 30  loss: = 134.463882 \n",
      "\n",
      "step: 31  loss: = 134.332901 \n",
      "\n",
      "step: 32  loss: = 134.307098 \n",
      "\n",
      "step: 33  loss: = 133.785583 \n",
      "\n",
      "step: 34  loss: = 133.823715 \n",
      "\n",
      "step: 35  loss: = 133.268784 \n",
      "\n",
      "step: 36  loss: = 133.130081 \n",
      "\n",
      "step: 37  loss: = 133.165787 \n",
      "\n",
      "step: 38  loss: = 132.891327 \n",
      "\n",
      "step: 39  loss: = 133.102020 \n",
      "\n",
      "step: 40  loss: = 132.349762 \n",
      "\n",
      "step: 41  loss: = 132.022629 \n",
      "\n",
      "step: 42  loss: = 132.257843 \n",
      "\n",
      "step: 43  loss: = 132.299988 \n",
      "\n",
      "step: 44  loss: = 132.006454 \n",
      "\n",
      "step: 45  loss: = 131.784805 \n",
      "\n",
      "step: 46  loss: = 131.393982 \n",
      "\n",
      "step: 47  loss: = 131.605499 \n",
      "\n",
      "step: 48  loss: = 131.341751 \n",
      "\n",
      "step: 49  loss: = 130.883743 \n",
      "\n",
      "step: 50  loss: = 130.987640 \n",
      "\n",
      "step: 51  loss: = 130.390335 \n",
      "\n",
      "step: 52  loss: = 131.084137 \n",
      "\n",
      "step: 53  loss: = 130.561523 \n",
      "\n",
      "step: 54  loss: = 130.397537 \n",
      "\n",
      "step: 55  loss: = 130.861862 \n",
      "\n",
      "step: 56  loss: = 130.359299 \n",
      "\n",
      "step: 57  loss: = 130.168396 \n",
      "\n",
      "step: 58  loss: = 130.279236 \n",
      "\n",
      "step: 59  loss: = 130.208817 \n",
      "\n",
      "step: 60  loss: = 129.690430 \n",
      "\n",
      "step: 61  loss: = 129.615250 \n",
      "\n",
      "step: 62  loss: = 129.352310 \n",
      "\n",
      "step: 63  loss: = 129.425415 \n",
      "\n",
      "step: 64  loss: = 129.466934 \n",
      "\n",
      "step: 65  loss: = 129.167282 \n",
      "\n",
      "step: 66  loss: = 129.693314 \n",
      "\n",
      "step: 67  loss: = 129.156586 \n",
      "\n",
      "step: 68  loss: = 129.372803 \n",
      "\n",
      "step: 69  loss: = 128.932816 \n",
      "\n",
      "step: 70  loss: = 128.551346 \n",
      "\n",
      "step: 71  loss: = 128.773071 \n",
      "\n",
      "step: 72  loss: = 128.573944 \n",
      "\n",
      "step: 73  loss: = 128.801437 \n",
      "\n",
      "step: 74  loss: = 128.575333 \n",
      "\n",
      "step: 75  loss: = 128.816223 \n",
      "\n",
      "step: 76  loss: = 129.099686 \n",
      "\n",
      "step: 77  loss: = 128.370377 \n",
      "\n",
      "step: 78  loss: = 128.811569 \n",
      "\n",
      "step: 79  loss: = 128.328445 \n",
      "\n",
      "step: 80  loss: = 127.952713 \n",
      "\n",
      "step: 81  loss: = 128.001968 \n",
      "\n",
      "step: 82  loss: = 127.697441 \n",
      "\n",
      "step: 83  loss: = 128.192749 \n",
      "\n",
      "step: 84  loss: = 127.952148 \n",
      "\n",
      "step: 85  loss: = 127.949448 \n",
      "\n",
      "step: 86  loss: = 127.586250 \n",
      "\n",
      "step: 87  loss: = 128.221664 \n",
      "\n",
      "step: 88  loss: = 128.428833 \n",
      "\n",
      "step: 89  loss: = 127.447731 \n",
      "\n",
      "step: 90  loss: = 127.611298 \n",
      "\n",
      "step: 91  loss: = 128.208618 \n",
      "\n",
      "step: 92  loss: = 127.527580 \n",
      "\n",
      "step: 93  loss: = 127.429810 \n",
      "\n",
      "step: 94  loss: = 127.438606 \n",
      "\n",
      "step: 95  loss: = 127.293152 \n",
      "\n",
      "step: 96  loss: = 127.036377 \n",
      "\n",
      "step: 97  loss: = 127.649483 \n",
      "\n",
      "step: 98  loss: = 127.075768 \n",
      "\n",
      "step: 99  loss: = 127.433174 \n",
      "\n",
      "step: 100  loss: = 128.102173 \n",
      "\n",
      "step: 101  loss: = 127.333496 \n",
      "\n",
      "step: 102  loss: = 127.346695 \n",
      "\n",
      "step: 103  loss: = 127.828323 \n",
      "\n",
      "step: 104  loss: = 127.292023 \n",
      "\n",
      "step: 105  loss: = 127.598930 \n",
      "\n",
      "step: 106  loss: = 127.021851 \n",
      "\n",
      "step: 107  loss: = 127.324097 \n",
      "\n",
      "step: 108  loss: = 127.227623 \n",
      "\n",
      "step: 109  loss: = 127.466682 \n",
      "\n",
      "step: 110  loss: = 127.120026 \n",
      "\n",
      "step: 111  loss: = 127.437492 \n",
      "\n",
      "step: 112  loss: = 127.348404 \n",
      "\n",
      "step: 113  loss: = 126.931137 \n",
      "\n",
      "step: 114  loss: = 127.180428 \n",
      "\n",
      "step: 115  loss: = 126.987617 \n",
      "\n",
      "step: 116  loss: = 127.305481 \n",
      "\n",
      "step: 117  loss: = 127.092239 \n",
      "\n",
      "step: 118  loss: = 127.680176 \n",
      "\n",
      "step: 119  loss: = 127.029945 \n",
      "\n",
      "step: 120  loss: = 127.104149 \n",
      "\n",
      "step: 121  loss: = 128.355087 \n",
      "\n",
      "step: 122  loss: = 127.599335 \n",
      "\n",
      "step: 123  loss: = 127.232895 \n",
      "\n",
      "step: 124  loss: = 127.099747 \n",
      "\n",
      "step: 125  loss: = 127.060951 \n",
      "\n",
      "step: 126  loss: = 127.451088 \n",
      "\n",
      "step: 127  loss: = 128.100037 \n",
      "\n",
      "step: 128  loss: = 127.732071 \n",
      "\n",
      "step: 129  loss: = 127.924545 \n",
      "\n",
      "step: 130  loss: = 127.442375 \n",
      "\n",
      "step: 131  loss: = 127.533554 \n",
      "\n",
      "step: 132  loss: = 126.948769 \n",
      "\n",
      "step: 133  loss: = 126.532387 \n",
      "\n",
      "step: 134  loss: = 127.277084 \n",
      "\n",
      "step: 135  loss: = 127.469635 \n",
      "\n",
      "step: 136  loss: = 127.264076 \n",
      "\n",
      "step: 137  loss: = 127.605515 \n",
      "\n",
      "step: 138  loss: = 127.662216 \n",
      "\n",
      "step: 139  loss: = 127.143860 \n",
      "\n",
      "step: 140  loss: = 127.680084 \n",
      "\n",
      "step: 141  loss: = 127.134567 \n",
      "\n",
      "step: 142  loss: = 126.754677 \n",
      "\n",
      "step: 143  loss: = 126.954819 \n",
      "\n",
      "step: 144  loss: = 126.974968 \n",
      "\n",
      "step: 145  loss: = 127.168297 \n",
      "\n",
      "step: 146  loss: = 126.559311 \n",
      "\n",
      "step: 147  loss: = 127.264603 \n",
      "\n",
      "step: 148  loss: = 128.288498 \n",
      "\n",
      "step: 149  loss: = 128.317459 \n",
      "\n",
      "step: 150  loss: = 126.996681 \n",
      "\n",
      "step: 151  loss: = 127.821098 \n",
      "\n",
      "step: 152  loss: = 127.390419 \n",
      "\n",
      "step: 153  loss: = 127.856773 \n",
      "\n",
      "step: 154  loss: = 127.447220 \n",
      "\n",
      "step: 155  loss: = 127.088921 \n",
      "\n",
      "step: 156  loss: = 129.723404 \n",
      "\n",
      "step: 157  loss: = 127.432648 \n",
      "\n",
      "step: 158  loss: = 129.802460 \n",
      "\n",
      "step: 159  loss: = 127.406456 \n",
      "\n",
      "step: 160  loss: = 127.170433 \n",
      "\n",
      "step: 161  loss: = 128.456223 \n",
      "\n",
      "step: 162  loss: = 128.798904 \n",
      "\n",
      "step: 163  loss: = 126.859108 \n",
      "\n",
      "step: 164  loss: = 127.183128 \n",
      "\n",
      "step: 165  loss: = 126.749374 \n",
      "\n",
      "step: 166  loss: = 128.077469 \n",
      "\n",
      "step: 167  loss: = 127.450035 \n",
      "\n",
      "step: 168  loss: = 127.526581 \n",
      "\n",
      "step: 169  loss: = 128.309067 \n",
      "\n",
      "step: 170  loss: = 127.591423 \n",
      "\n",
      "step: 171  loss: = 128.003342 \n",
      "\n",
      "step: 172  loss: = 126.786255 \n",
      "\n",
      "step: 173  loss: = 127.053741 \n",
      "\n",
      "step: 174  loss: = 126.883087 \n",
      "\n",
      "step: 175  loss: = 127.553345 \n",
      "\n",
      "step: 176  loss: = 126.959991 \n",
      "\n",
      "step: 177  loss: = 127.544441 \n",
      "\n",
      "step: 178  loss: = 127.422951 \n",
      "\n",
      "step: 179  loss: = 127.223579 \n",
      "\n",
      "step: 180  loss: = 126.882271 \n",
      "\n",
      "step: 181  loss: = 127.379753 \n",
      "\n",
      "step: 182  loss: = 127.196678 \n",
      "\n",
      "step: 183  loss: = 127.166405 \n",
      "\n",
      "step: 184  loss: = 127.570709 \n",
      "\n",
      "step: 185  loss: = 127.461945 \n",
      "\n",
      "step: 186  loss: = 126.841064 \n",
      "\n",
      "step: 187  loss: = 128.116058 \n",
      "\n",
      "step: 188  loss: = 127.115685 \n",
      "\n",
      "step: 189  loss: = 128.365921 \n",
      "\n",
      "step: 190  loss: = 128.483124 \n",
      "\n",
      "step: 191  loss: = 126.873833 \n",
      "\n",
      "step: 192  loss: = 126.927612 \n",
      "\n",
      "step: 193  loss: = 128.042465 \n",
      "\n",
      "step: 194  loss: = 127.235512 \n",
      "\n",
      "step: 195  loss: = 127.264870 \n",
      "\n",
      "step: 196  loss: = 126.951324 \n",
      "\n",
      "step: 197  loss: = 127.898117 \n",
      "\n",
      "step: 198  loss: = 127.139099 \n",
      "\n",
      "step: 199  loss: = 127.291176 \n",
      "\n",
      "step: 200  loss: = 127.555099 \n",
      "\n",
      "step: 201  loss: = 128.235504 \n",
      "\n",
      "step: 202  loss: = 127.100777 \n",
      "\n",
      "step: 203  loss: = 126.942169 \n",
      "\n",
      "step: 204  loss: = 127.645996 \n",
      "\n",
      "step: 205  loss: = 127.343765 \n",
      "\n",
      "step: 206  loss: = 129.495560 \n",
      "\n",
      "step: 207  loss: = 127.338646 \n",
      "\n",
      "step: 208  loss: = 127.834740 \n",
      "\n",
      "step: 209  loss: = 127.346909 \n",
      "\n",
      "step: 210  loss: = 127.592247 \n",
      "\n",
      "step: 211  loss: = 126.753281 \n",
      "\n",
      "step: 212  loss: = 127.021507 \n",
      "\n",
      "step: 213  loss: = 127.140289 \n",
      "\n",
      "step: 214  loss: = 127.528709 \n",
      "\n",
      "step: 215  loss: = 127.257919 \n",
      "\n",
      "step: 216  loss: = 127.418785 \n",
      "\n",
      "step: 217  loss: = 127.580811 \n",
      "\n",
      "step: 218  loss: = 127.333305 \n",
      "\n",
      "step: 219  loss: = 127.258835 \n",
      "\n",
      "step: 220  loss: = 127.822731 \n",
      "\n",
      "step: 221  loss: = 127.358376 \n",
      "\n",
      "step: 222  loss: = 127.352524 \n",
      "\n",
      "step: 223  loss: = 126.954758 \n",
      "\n",
      "step: 224  loss: = 127.653519 \n",
      "\n",
      "step: 225  loss: = 127.504265 \n",
      "\n",
      "step: 226  loss: = 127.667038 \n",
      "\n",
      "step: 227  loss: = 127.768944 \n",
      "\n",
      "step: 228  loss: = 127.606392 \n",
      "\n",
      "step: 229  loss: = 126.895050 \n",
      "\n",
      "step: 230  loss: = 126.896606 \n",
      "\n",
      "step: 231  loss: = 127.549179 \n",
      "\n",
      "step: 232  loss: = 128.001465 \n",
      "\n",
      "step: 233  loss: = 127.490639 \n",
      "\n",
      "step: 234  loss: = 127.038887 \n",
      "\n",
      "step: 235  loss: = 126.937538 \n",
      "\n",
      "step: 236  loss: = 127.039375 \n",
      "\n",
      "step: 237  loss: = 128.306320 \n",
      "\n",
      "step: 238  loss: = 127.100235 \n",
      "\n",
      "step: 239  loss: = 127.344627 \n",
      "\n",
      "step: 240  loss: = 127.306824 \n",
      "\n",
      "step: 241  loss: = 127.773438 \n",
      "\n",
      "step: 242  loss: = 127.392204 \n",
      "\n",
      "step: 243  loss: = 127.114601 \n",
      "\n",
      "step: 244  loss: = 126.957909 \n",
      "\n",
      "step: 245  loss: = 126.693825 \n",
      "\n",
      "step: 246  loss: = 127.844193 \n",
      "\n",
      "step: 247  loss: = 127.192657 \n",
      "\n",
      "step: 248  loss: = 127.173744 \n",
      "\n",
      "step: 249  loss: = 127.191399 \n",
      "\n",
      "step: 250  loss: = 128.246231 \n",
      "\n",
      "step: 251  loss: = 127.993027 \n",
      "\n",
      "step: 252  loss: = 126.668343 \n",
      "\n",
      "step: 253  loss: = 127.592422 \n",
      "\n",
      "step: 254  loss: = 127.244553 \n",
      "\n",
      "step: 255  loss: = 128.840973 \n",
      "\n",
      "step: 256  loss: = 127.405609 \n",
      "\n",
      "step: 257  loss: = 126.787086 \n",
      "\n",
      "step: 258  loss: = 127.911316 \n",
      "\n",
      "step: 259  loss: = 126.894104 \n",
      "\n",
      "step: 260  loss: = 127.627907 \n",
      "\n",
      "step: 261  loss: = 127.419991 \n",
      "\n",
      "step: 262  loss: = 127.515594 \n",
      "\n",
      "step: 263  loss: = 126.823761 \n",
      "\n",
      "step: 264  loss: = 126.911240 \n",
      "\n",
      "step: 265  loss: = 127.918510 \n",
      "\n",
      "step: 266  loss: = 127.121986 \n",
      "\n",
      "step: 267  loss: = 127.359138 \n",
      "\n",
      "step: 268  loss: = 127.885925 \n",
      "\n",
      "step: 269  loss: = 127.143089 \n",
      "\n",
      "step: 270  loss: = 127.510796 \n",
      "\n",
      "step: 271  loss: = 127.445526 \n",
      "\n",
      "step: 272  loss: = 127.177856 \n",
      "\n",
      "step: 273  loss: = 127.988808 \n",
      "\n",
      "step: 274  loss: = 127.319763 \n",
      "\n",
      "step: 275  loss: = 126.931465 \n",
      "\n",
      "step: 276  loss: = 128.457520 \n",
      "\n",
      "step: 277  loss: = 127.374298 \n",
      "\n",
      "step: 278  loss: = 126.712166 \n",
      "\n",
      "step: 279  loss: = 128.194153 \n",
      "\n",
      "step: 280  loss: = 126.987793 \n",
      "\n",
      "step: 281  loss: = 126.487831 \n",
      "\n",
      "step: 282  loss: = 126.955223 \n",
      "\n",
      "step: 283  loss: = 126.658371 \n",
      "\n",
      "step: 284  loss: = 126.956581 \n",
      "\n",
      "step: 285  loss: = 127.078285 \n",
      "\n",
      "step: 286  loss: = 127.276268 \n",
      "\n",
      "step: 287  loss: = 127.008163 \n",
      "\n",
      "step: 288  loss: = 127.661079 \n",
      "\n",
      "step: 289  loss: = 127.194763 \n",
      "\n",
      "step: 290  loss: = 126.776718 \n",
      "\n",
      "step: 291  loss: = 127.724045 \n",
      "\n",
      "step: 292  loss: = 127.028503 \n",
      "\n",
      "step: 293  loss: = 127.462021 \n",
      "\n",
      "step: 294  loss: = 126.513489 \n",
      "\n",
      "step: 295  loss: = 127.755852 \n",
      "\n",
      "step: 296  loss: = 126.778343 \n",
      "\n",
      "step: 297  loss: = 126.510033 \n",
      "\n",
      "step: 298  loss: = 126.865486 \n",
      "\n",
      "step: 299  loss: = 127.046310 \n",
      "\n",
      "step: 300  loss: = 126.936470 \n",
      "\n",
      "step: 301  loss: = 127.138611 \n",
      "\n",
      "step: 302  loss: = 127.075523 \n",
      "\n",
      "step: 303  loss: = 126.821320 \n",
      "\n",
      "step: 304  loss: = 126.821701 \n",
      "\n",
      "step: 305  loss: = 126.499298 \n",
      "\n",
      "step: 306  loss: = 127.447220 \n",
      "\n",
      "step: 307  loss: = 126.963005 \n",
      "\n",
      "step: 308  loss: = 126.990639 \n",
      "\n",
      "step: 309  loss: = 126.799309 \n",
      "\n",
      "step: 310  loss: = 127.288841 \n",
      "\n",
      "step: 311  loss: = 127.355034 \n",
      "\n",
      "step: 312  loss: = 127.223137 \n",
      "\n",
      "step: 313  loss: = 126.832085 \n",
      "\n",
      "step: 314  loss: = 126.855331 \n",
      "\n",
      "step: 315  loss: = 127.902954 \n",
      "\n",
      "step: 316  loss: = 128.679886 \n",
      "\n",
      "step: 317  loss: = 127.679253 \n",
      "\n",
      "step: 318  loss: = 127.106300 \n",
      "\n",
      "step: 319  loss: = 127.254395 \n",
      "\n",
      "step: 320  loss: = 127.613640 \n",
      "\n",
      "step: 321  loss: = 127.581787 \n",
      "\n",
      "step: 322  loss: = 127.172585 \n",
      "\n",
      "step: 323  loss: = 127.046638 \n",
      "\n",
      "step: 324  loss: = 126.745590 \n",
      "\n",
      "step: 325  loss: = 127.837883 \n",
      "\n",
      "step: 326  loss: = 126.873756 \n",
      "\n",
      "step: 327  loss: = 127.527618 \n",
      "\n",
      "step: 328  loss: = 127.133110 \n",
      "\n",
      "step: 329  loss: = 127.600922 \n",
      "\n",
      "step: 330  loss: = 127.402412 \n",
      "\n",
      "step: 331  loss: = 128.378616 \n",
      "\n",
      "step: 332  loss: = 126.873344 \n",
      "\n",
      "step: 333  loss: = 127.263191 \n",
      "\n",
      "step: 334  loss: = 127.369041 \n",
      "\n",
      "step: 335  loss: = 126.542564 \n",
      "\n",
      "step: 336  loss: = 127.354584 \n",
      "\n",
      "step: 337  loss: = 127.276802 \n",
      "\n",
      "step: 338  loss: = 127.370026 \n",
      "\n",
      "step: 339  loss: = 127.071701 \n",
      "\n",
      "step: 340  loss: = 127.109978 \n",
      "\n",
      "step: 341  loss: = 126.558800 \n",
      "\n",
      "step: 342  loss: = 126.814705 \n",
      "\n",
      "step: 343  loss: = 127.063133 \n",
      "\n",
      "step: 344  loss: = 127.141335 \n",
      "\n",
      "step: 345  loss: = 126.889839 \n",
      "\n",
      "step: 346  loss: = 127.199387 \n",
      "\n",
      "step: 347  loss: = 126.940231 \n",
      "\n",
      "step: 348  loss: = 127.062286 \n",
      "\n",
      "step: 349  loss: = 126.359093 \n",
      "\n",
      "step: 350  loss: = 126.756989 \n",
      "\n",
      "step: 351  loss: = 127.001671 \n",
      "\n",
      "step: 352  loss: = 126.581856 \n",
      "\n",
      "step: 353  loss: = 127.026161 \n",
      "\n",
      "step: 354  loss: = 127.711098 \n",
      "\n",
      "step: 355  loss: = 126.698997 \n",
      "\n",
      "step: 356  loss: = 126.398987 \n",
      "\n",
      "step: 357  loss: = 127.011360 \n",
      "\n",
      "step: 358  loss: = 128.359390 \n",
      "\n",
      "step: 359  loss: = 127.339424 \n",
      "\n",
      "step: 360  loss: = 127.662460 \n",
      "\n",
      "step: 361  loss: = 127.292221 \n",
      "\n",
      "step: 362  loss: = 127.620529 \n",
      "\n",
      "step: 363  loss: = 127.486427 \n",
      "\n",
      "step: 364  loss: = 127.683083 \n",
      "\n",
      "step: 365  loss: = 127.360023 \n",
      "\n",
      "step: 366  loss: = 127.468643 \n",
      "\n",
      "step: 367  loss: = 126.949829 \n",
      "\n",
      "step: 368  loss: = 127.029633 \n",
      "\n",
      "step: 369  loss: = 127.084984 \n",
      "\n",
      "step: 370  loss: = 126.946075 \n",
      "\n",
      "step: 371  loss: = 127.288826 \n",
      "\n",
      "step: 372  loss: = 127.513847 \n",
      "\n",
      "step: 373  loss: = 127.507843 \n",
      "\n",
      "step: 374  loss: = 127.665878 \n",
      "\n",
      "step: 375  loss: = 126.863159 \n",
      "\n",
      "step: 376  loss: = 127.779205 \n",
      "\n",
      "step: 377  loss: = 130.512848 \n",
      "\n",
      "step: 378  loss: = 126.921654 \n",
      "\n",
      "step: 379  loss: = 127.834137 \n",
      "\n",
      "step: 380  loss: = 127.170586 \n",
      "\n",
      "step: 381  loss: = 128.096497 \n",
      "\n",
      "step: 382  loss: = 126.823914 \n",
      "\n",
      "step: 383  loss: = 128.590668 \n",
      "\n",
      "step: 384  loss: = 126.738434 \n",
      "\n",
      "step: 385  loss: = 126.668053 \n",
      "\n",
      "step: 386  loss: = 126.383095 \n",
      "\n",
      "step: 387  loss: = 126.835022 \n",
      "\n",
      "step: 388  loss: = 127.467216 \n",
      "\n",
      "step: 389  loss: = 128.513687 \n",
      "\n",
      "step: 390  loss: = 128.554153 \n",
      "\n",
      "step: 391  loss: = 126.591408 \n",
      "\n",
      "step: 392  loss: = 127.302948 \n",
      "\n",
      "step: 393  loss: = 127.242043 \n",
      "\n",
      "step: 394  loss: = 127.188004 \n",
      "\n",
      "step: 395  loss: = 127.710495 \n",
      "\n",
      "step: 396  loss: = 126.612701 \n",
      "\n",
      "step: 397  loss: = 127.455635 \n",
      "\n",
      "step: 398  loss: = 126.477638 \n",
      "\n",
      "step: 399  loss: = 127.401833 \n",
      "\n",
      "step: 400  loss: = 126.380127 \n",
      "\n",
      "step: 401  loss: = 126.633362 \n",
      "\n",
      "step: 402  loss: = 127.080460 \n",
      "\n",
      "step: 403  loss: = 127.336304 \n",
      "\n",
      "step: 404  loss: = 126.762642 \n",
      "\n",
      "step: 405  loss: = 126.504372 \n",
      "\n",
      "step: 406  loss: = 127.164833 \n",
      "\n",
      "step: 407  loss: = 127.066399 \n",
      "\n",
      "step: 408  loss: = 126.635712 \n",
      "\n",
      "step: 409  loss: = 127.160545 \n",
      "\n",
      "step: 410  loss: = 127.144623 \n",
      "\n",
      "step: 411  loss: = 127.109550 \n",
      "\n",
      "step: 412  loss: = 126.255997 \n",
      "\n",
      "step: 413  loss: = 127.550240 \n",
      "\n",
      "step: 414  loss: = 126.608788 \n",
      "\n",
      "step: 415  loss: = 128.011017 \n",
      "\n",
      "step: 416  loss: = 127.077003 \n",
      "\n",
      "step: 417  loss: = 126.177238 \n",
      "\n",
      "step: 418  loss: = 127.031395 \n",
      "\n",
      "step: 419  loss: = 126.570923 \n",
      "\n",
      "step: 420  loss: = 127.043800 \n",
      "\n",
      "step: 421  loss: = 126.887245 \n",
      "\n",
      "step: 422  loss: = 126.869347 \n",
      "\n",
      "step: 423  loss: = 126.722855 \n",
      "\n",
      "step: 424  loss: = 128.002304 \n",
      "\n",
      "step: 425  loss: = 126.648895 \n",
      "\n",
      "step: 426  loss: = 127.682510 \n",
      "\n",
      "step: 427  loss: = 127.021706 \n",
      "\n",
      "step: 428  loss: = 127.701675 \n",
      "\n",
      "step: 429  loss: = 127.118355 \n",
      "\n",
      "step: 430  loss: = 127.538681 \n",
      "\n",
      "step: 431  loss: = 126.327339 \n",
      "\n",
      "step: 432  loss: = 126.969948 \n",
      "\n",
      "step: 433  loss: = 127.706604 \n",
      "\n",
      "step: 434  loss: = 127.697845 \n",
      "\n",
      "step: 435  loss: = 127.169731 \n",
      "\n",
      "step: 436  loss: = 127.732407 \n",
      "\n",
      "step: 437  loss: = 127.314743 \n",
      "\n",
      "step: 438  loss: = 127.817963 \n",
      "\n",
      "step: 439  loss: = 126.492455 \n",
      "\n",
      "step: 440  loss: = 126.507362 \n",
      "\n",
      "step: 441  loss: = 127.446098 \n",
      "\n",
      "step: 442  loss: = 126.679642 \n",
      "\n",
      "step: 443  loss: = 126.826797 \n",
      "\n",
      "step: 444  loss: = 127.417786 \n",
      "\n",
      "step: 445  loss: = 126.878769 \n",
      "\n",
      "step: 446  loss: = 126.955231 \n",
      "\n",
      "step: 447  loss: = 126.955849 \n",
      "\n",
      "step: 448  loss: = 126.877419 \n",
      "\n",
      "step: 449  loss: = 127.516739 \n",
      "\n",
      "step: 450  loss: = 127.199120 \n",
      "\n",
      "step: 451  loss: = 126.567772 \n",
      "\n",
      "step: 452  loss: = 126.728172 \n",
      "\n",
      "step: 453  loss: = 126.472443 \n",
      "\n",
      "step: 454  loss: = 127.932152 \n",
      "\n",
      "step: 455  loss: = 127.015732 \n",
      "\n",
      "step: 456  loss: = 126.606888 \n",
      "\n",
      "step: 457  loss: = 127.756615 \n",
      "\n",
      "step: 458  loss: = 126.524055 \n",
      "\n",
      "step: 459  loss: = 126.662598 \n",
      "\n",
      "step: 460  loss: = 126.950233 \n",
      "\n",
      "step: 461  loss: = 126.315224 \n",
      "\n",
      "step: 462  loss: = 127.798470 \n",
      "\n",
      "step: 463  loss: = 127.026985 \n",
      "\n",
      "step: 464  loss: = 126.353027 \n",
      "\n",
      "step: 465  loss: = 127.833916 \n",
      "\n",
      "step: 466  loss: = 126.324196 \n",
      "\n",
      "step: 467  loss: = 127.780083 \n",
      "\n",
      "step: 468  loss: = 127.140228 \n",
      "\n",
      "step: 469  loss: = 127.240593 \n",
      "\n",
      "step: 470  loss: = 127.334969 \n",
      "\n",
      "step: 471  loss: = 126.572472 \n",
      "\n",
      "step: 472  loss: = 127.654259 \n",
      "\n",
      "step: 473  loss: = 127.517883 \n",
      "\n",
      "step: 474  loss: = 126.277580 \n",
      "\n",
      "step: 475  loss: = 127.791794 \n",
      "\n",
      "step: 476  loss: = 126.247025 \n",
      "\n",
      "step: 477  loss: = 126.521019 \n",
      "\n",
      "step: 478  loss: = 126.221123 \n",
      "\n",
      "step: 479  loss: = 126.425613 \n",
      "\n",
      "step: 480  loss: = 126.008377 \n",
      "\n",
      "step: 481  loss: = 126.724098 \n",
      "\n",
      "step: 482  loss: = 126.490341 \n",
      "\n",
      "step: 483  loss: = 127.363052 \n",
      "\n",
      "step: 484  loss: = 126.016373 \n",
      "\n",
      "step: 485  loss: = 128.195007 \n",
      "\n",
      "step: 486  loss: = 127.368973 \n",
      "\n",
      "step: 487  loss: = 127.507103 \n",
      "\n",
      "step: 488  loss: = 127.447899 \n",
      "\n",
      "step: 489  loss: = 127.350014 \n",
      "\n",
      "step: 490  loss: = 126.672325 \n",
      "\n",
      "step: 491  loss: = 126.498032 \n",
      "\n",
      "step: 492  loss: = 127.390320 \n",
      "\n",
      "step: 493  loss: = 126.484329 \n",
      "\n",
      "step: 494  loss: = 126.942490 \n",
      "\n",
      "step: 495  loss: = 128.216721 \n",
      "\n",
      "step: 496  loss: = 127.106880 \n",
      "\n",
      "step: 497  loss: = 127.718163 \n",
      "\n",
      "step: 498  loss: = 126.953819 \n",
      "\n",
      "step: 499  loss: = 126.502022 \n",
      "\n",
      "step: 500  loss: = 126.563637 \n",
      "\n",
      "step: 501  loss: = 126.578804 \n",
      "\n",
      "step: 502  loss: = 126.224892 \n",
      "\n",
      "step: 503  loss: = 126.268204 \n",
      "\n",
      "step: 504  loss: = 126.372330 \n",
      "\n",
      "step: 505  loss: = 126.715874 \n",
      "\n",
      "step: 506  loss: = 126.512894 \n",
      "\n",
      "step: 507  loss: = 126.440788 \n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-983b48910b44>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mbatchsize_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_filt1_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip1_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0minput_filt2_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip2_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_filt3_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip3_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0minput_filt4_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip4_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_filt5_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip5_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0minput_filt6_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip6_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_filt7_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip7_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0minput_filt8_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip8_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_filt9_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip9_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0minput_filt10_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip10_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_filt11_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip11_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0minput_filt12_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip12_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_filt13_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip13_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0minput_filt14_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip14_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_filt15_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip15_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m               \u001b[0minput_filt16_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_bip16_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TRAIN THE NETWORK\n",
    "\n",
    "for step in range(1000): \n",
    "    \n",
    "    inds = np.reshape(np.random.permutation(range(input_bip1_train.shape[1])), [-1, batchsize])\n",
    "\n",
    "    for n in range(len(inds)):  \n",
    "        fdd = {batchsize_: batchsize, input_filt1_: input_bip1_train[:, inds[n, :], :], \\\n",
    "               input_filt2_: input_bip2_train[:, inds[n, :], :], input_filt3_: input_bip3_train[:, inds[n, :], :],\\\n",
    "               input_filt4_: input_bip4_train[:, inds[n, :], :], input_filt5_: input_bip5_train[:, inds[n, :], :],\\\n",
    "               input_filt6_: input_bip6_train[:, inds[n, :], :], input_filt7_: input_bip7_train[:, inds[n, :], :],\\\n",
    "               input_filt8_: input_bip8_train[:, inds[n, :], :], input_filt9_: input_bip9_train[:, inds[n, :], :],\\\n",
    "               input_filt10_: input_bip10_train[:, inds[n, :], :], input_filt11_: input_bip11_train[:, inds[n, :], :],\\\n",
    "               input_filt12_: input_bip12_train[:, inds[n, :], :], input_filt13_: input_bip13_train[:, inds[n, :], :],\\\n",
    "               input_filt14_: input_bip14_train[:, inds[n, :], :], input_filt15_: input_bip15_train[:, inds[n, :], :],\\\n",
    "               input_filt16_: input_bip16_train[:, inds[n, :], :], y_:y_train[inds[n, :], :, :]}\n",
    "        sess.run(train_step, feed_dict=fdd, options = run_opts)\n",
    "        \n",
    "    batch_loss=sess.run(loss, feed_dict=fdd)\n",
    "    batch_loss_hist=np.concatenate([batch_loss_hist, np.array([batch_loss])], axis=0)\n",
    "    L1=sess.run(regularizer, feed_dict=fdd)\n",
    "    L1_hist=np.concatenate([L1_hist, np.array([L1])], axis=0)\n",
    "    loss_val = (batchsize/train_loss_size)*sess.run(loss, feed_dict= trainsampfd)\n",
    "    loss_hist=np.concatenate([loss_hist, np.array([loss_val])], axis=0)\n",
    "    check=loss_val\n",
    "\n",
    "    print(\"step: %d  loss: = %9f \\n\" % (step, loss_val))\n",
    "    \n",
    "    if (step % 10 == 0):\n",
    "        test_loss = (batchsize/input_bip1_test.shape[1])*sess.run(loss, feed_dict= fddd)\n",
    "        test_hist=np.concatenate([test_hist, np.array([test_loss])], axis=0)\n",
    " \n",
    "\n",
    "    if (step % 10 == 0):\n",
    "        \n",
    "        f1b1_syn_hist=tf.concat([f1b1_syn_hist, tf.reshape(f1b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f1b1_syn_concat')\n",
    "        f2b1_syn_hist=tf.concat([f2b1_syn_hist, tf.reshape(f2b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f2b1_syn_concat')\n",
    "        f3b1_syn_hist=tf.concat([f3b1_syn_hist, tf.reshape(f3b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f3b1_syn_concat')\n",
    "        f4b1_syn_hist=tf.concat([f4b1_syn_hist, tf.reshape(f4b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f4b1_syn_concat')\n",
    "        f5b1_syn_hist=tf.concat([f5b1_syn_hist, tf.reshape(f5b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f5b1_syn_concat')\n",
    "        f6b1_syn_hist=tf.concat([f6b1_syn_hist, tf.reshape(f6b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f6b1_syn_concat')\n",
    "        f7b1_syn_hist=tf.concat([f7b1_syn_hist, tf.reshape(f7b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f7b1_syn_concat')\n",
    "        f8b1_syn_hist=tf.concat([f8b1_syn_hist, tf.reshape(f8b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f8b1_syn_concat')\n",
    "        f9b1_syn_hist=tf.concat([f9b1_syn_hist, tf.reshape(f9b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f9b1_syn_concat')\n",
    "        f10b1_syn_hist=tf.concat([f10b1_syn_hist, tf.reshape(f10b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f10b1_syn_concat')\n",
    "        f11b1_syn_hist=tf.concat([f11b1_syn_hist, tf.reshape(f11b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f11b1_syn_concat')\n",
    "        f12b1_syn_hist=tf.concat([f12b1_syn_hist, tf.reshape(f12b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f12b1_syn_concat')\n",
    "        f13b1_syn_hist=tf.concat([f13b1_syn_hist, tf.reshape(f13b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f13b1_syn_concat')\n",
    "        f14b1_syn_hist=tf.concat([f14b1_syn_hist, tf.reshape(f14b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f14b1_syn_concat')\n",
    "        f15b1_syn_hist=tf.concat([f15b1_syn_hist, tf.reshape(f15b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f15b1_syn_concat')\n",
    "        f16b1_syn_hist=tf.concat([f16b1_syn_hist, tf.reshape(f16b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f16b1_syn_concat')\n",
    "        \n",
    "        f1b2_syn_hist=tf.concat([f1b2_syn_hist, tf.reshape(f1b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f1b2_syn_concat')\n",
    "        f2b2_syn_hist=tf.concat([f2b2_syn_hist, tf.reshape(f2b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f2b2_syn_concat')\n",
    "        f3b2_syn_hist=tf.concat([f3b2_syn_hist, tf.reshape(f3b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f3b2_syn_concat')\n",
    "        f4b2_syn_hist=tf.concat([f4b2_syn_hist, tf.reshape(f4b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f4b2_syn_concat')\n",
    "        f5b2_syn_hist=tf.concat([f5b2_syn_hist, tf.reshape(f5b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f5b2_syn_concat')\n",
    "        f6b2_syn_hist=tf.concat([f6b2_syn_hist, tf.reshape(f6b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f6b2_syn_concat')\n",
    "        f7b2_syn_hist=tf.concat([f7b2_syn_hist, tf.reshape(f7b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f7b2_syn_concat')\n",
    "        f8b2_syn_hist=tf.concat([f8b2_syn_hist, tf.reshape(f8b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f8b2_syn_concat')\n",
    "        f9b2_syn_hist=tf.concat([f9b2_syn_hist, tf.reshape(f9b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f9b2_syn_concat')\n",
    "        f10b2_syn_hist=tf.concat([f10b2_syn_hist, tf.reshape(f10b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f10b2_syn_concat')\n",
    "        f11b2_syn_hist=tf.concat([f11b2_syn_hist, tf.reshape(f11b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f11b2_syn_concat')\n",
    "        f12b2_syn_hist=tf.concat([f12b2_syn_hist, tf.reshape(f12b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f12b2_syn_concat')\n",
    "        f13b2_syn_hist=tf.concat([f13b2_syn_hist, tf.reshape(f13b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f13b2_syn_concat')\n",
    "        f14b2_syn_hist=tf.concat([f14b2_syn_hist, tf.reshape(f14b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f14b2_syn_concat')\n",
    "        f15b2_syn_hist=tf.concat([f15b2_syn_hist, tf.reshape(f15b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f15b2_syn_concat')\n",
    "        f16b2_syn_hist=tf.concat([f16b2_syn_hist, tf.reshape(f16b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f16b2_syn_concat')\n",
    "        \n",
    "        f1b11_syn_hist=tf.concat([f1b11_syn_hist, tf.reshape(f1b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f1b11_syn_concat')\n",
    "        f2b11_syn_hist=tf.concat([f2b11_syn_hist, tf.reshape(f2b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f2b11_syn_concat')\n",
    "        f3b11_syn_hist=tf.concat([f3b11_syn_hist, tf.reshape(f3b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f3b11_syn_concat')\n",
    "        f4b11_syn_hist=tf.concat([f4b11_syn_hist, tf.reshape(f4b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f4b11_syn_concat')\n",
    "        f5b11_syn_hist=tf.concat([f5b11_syn_hist, tf.reshape(f5b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f5b11_syn_concat')\n",
    "        f6b11_syn_hist=tf.concat([f6b11_syn_hist, tf.reshape(f6b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f6b11_syn_concat')\n",
    "        f7b11_syn_hist=tf.concat([f7b11_syn_hist, tf.reshape(f7b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f7b11_syn_concat')\n",
    "        f8b11_syn_hist=tf.concat([f8b11_syn_hist, tf.reshape(f8b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f8b11_syn_concat')\n",
    "        f9b11_syn_hist=tf.concat([f9b11_syn_hist, tf.reshape(f9b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f9b11_syn_concat')\n",
    "        f10b11_syn_hist=tf.concat([f10b11_syn_hist, tf.reshape(f10b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f10b11_syn_concat')\n",
    "        f11b11_syn_hist=tf.concat([f11b11_syn_hist, tf.reshape(f11b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f11b11_syn_concat')\n",
    "        f12b11_syn_hist=tf.concat([f12b11_syn_hist, tf.reshape(f12b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f12b11_syn_concat')\n",
    "        f13b11_syn_hist=tf.concat([f13b11_syn_hist, tf.reshape(f13b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f13b11_syn_concat')\n",
    "        f14b11_syn_hist=tf.concat([f14b11_syn_hist, tf.reshape(f14b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f14b11_syn_concat')\n",
    "        f15b11_syn_hist=tf.concat([f15b11_syn_hist, tf.reshape(f15b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f15b11_syn_concat')\n",
    "        f16b11_syn_hist=tf.concat([f16b11_syn_hist, tf.reshape(f16b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f16b11_syn_concat')\n",
    "        \n",
    "        bip1_gc_syn_hist=tf.concat([bip1_gc_syn_hist, tf.reshape(bip1_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip1_gc_syn_concat')\n",
    "        bip2_gc_syn_hist=tf.concat([bip2_gc_syn_hist, tf.reshape(bip2_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip2_gc_syn_concat')\n",
    "        bip11_gc_syn_hist=tf.concat([bip11_gc_syn_hist, tf.reshape(bip11_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip11_gc_syn_concat')\n",
    "\n",
    "        bip1_copy_gc_syn_hist=tf.concat([bip1_copy_gc_syn_hist, tf.reshape(bip1_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip1_copy_gc_syn_concat')\n",
    "        bip2_copy_gc_syn_hist=tf.concat([bip2_copy_gc_syn_hist, tf.reshape(bip2_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip2_copy_gc_syn_concat')\n",
    "        bip11_copy_gc_syn_hist=tf.concat([bip11_copy_gc_syn_hist, tf.reshape(bip11_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip11_copy_gc_syn_concat')\n",
    "\n",
    "        bip1_am1_syn_hist=tf.concat([bip1_am1_syn_hist, tf.reshape(bip1_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])], 0, name = 'bip1_am1_syn_concat')\n",
    "        bip2_am1_syn_hist=tf.concat([bip2_am1_syn_hist, tf.reshape(bip2_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])], 0, name = 'bip2_am1_syn_concat')\n",
    "        bip11_am1_syn_hist=tf.concat([bip11_am1_syn_hist, tf.reshape(bip11_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])], 0, name = 'bip11_am1_syn_concat')\n",
    "        \n",
    "        am1_gc_syn_hist=tf.concat([am1_gc_syn_hist, tf.reshape(am1_gc_syn.eval(session=sess), [1, no_am1, no_gc])], 0, name = 'am1_gc_syn_concat')\n",
    "\n",
    "        am1_b1copy_syn_hist=tf.concat([am1_b1copy_syn_hist, tf.reshape(am1_b1copy_syn.eval(session=sess), [1, no_am1, no_bipolars])], 0, name = 'am1_b1copy_syn_concat')\n",
    "        am1_b2copy_syn_hist=tf.concat([am1_b2copy_syn_hist, tf.reshape(am1_b2copy_syn.eval(session=sess), [1, no_am1, no_bipolars])], 0, name = 'am1_b2copy_syn_concat')\n",
    "\n",
    "        b1_bias_hist=tf.concat([b1_bias_hist, tf.reshape(b1_bias.eval(session=sess), [1, no_bipolars])], 0, name = 'bip1_bias_concat')\n",
    "        b2_bias_hist=tf.concat([b2_bias_hist, tf.reshape(b2_bias.eval(session=sess), [1, no_bipolars])], 0, name = 'bip2_bias_concat')\n",
    "        b11_bias_hist=tf.concat([b11_bias_hist, tf.reshape(b11_bias.eval(session=sess), [1, no_bipolars])], 0, name = 'bip11_bias_concat')\n",
    "\n",
    "        am1_bias_hist=tf.concat([am1_bias_hist, tf.reshape(am1_bias.eval(session=sess), [1, no_am1])], 0, name = 'am1_bias_concat')\n",
    "        gc_bias_hist=tf.concat([gc_bias_hist, tf.reshape(gc_bias.eval(session=sess), [1, no_gc])], 0, name = 'gc_bias_concat')\n",
    "        gc_stretch_hist=tf.concat([gc_stretch_hist, tf.reshape(gc_stretch.eval(session=sess), [1, no_gc])], 0, name = 'gc_bias_concat')\n",
    "\n",
    "        output_hist=tf.concat([output_hist, tf.reshape(output.eval(session=sess, feed_dict=singlefd), [1, 32, data_duration])], 0, name = 'output_concat')\n",
    "    \n",
    "        db={}\n",
    "        \n",
    "        db['f1b1_syn_hist']=f1b1_syn_hist.eval(session=sess)\n",
    "        db['f2b1_syn_hist']=f2b1_syn_hist.eval(session=sess)\n",
    "        db['f3b1_syn_hist']=f3b1_syn_hist.eval(session=sess)\n",
    "        db['f4b1_syn_hist']=f4b1_syn_hist.eval(session=sess)\n",
    "        db['f5b1_syn_hist']=f5b1_syn_hist.eval(session=sess)\n",
    "        db['f6b1_syn_hist']=f6b1_syn_hist.eval(session=sess)\n",
    "        db['f7b1_syn_hist']=f7b1_syn_hist.eval(session=sess)\n",
    "        db['f8b1_syn_hist']=f8b1_syn_hist.eval(session=sess)\n",
    "        db['f9b1_syn_hist']=f9b1_syn_hist.eval(session=sess)\n",
    "        db['f10b1_syn_hist']=f10b1_syn_hist.eval(session=sess)\n",
    "        db['f11b1_syn_hist']=f11b1_syn_hist.eval(session=sess)\n",
    "        db['f12b1_syn_hist']=f12b1_syn_hist.eval(session=sess)\n",
    "        db['f13b1_syn_hist']=f13b1_syn_hist.eval(session=sess)\n",
    "        db['f14b1_syn_hist']=f14b1_syn_hist.eval(session=sess)\n",
    "        db['f15b1_syn_hist']=f15b1_syn_hist.eval(session=sess)\n",
    "        db['f16b1_syn_hist']=f16b1_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['f1b2_syn_hist']=f1b2_syn_hist.eval(session=sess)\n",
    "        db['f2b2_syn_hist']=f2b2_syn_hist.eval(session=sess)\n",
    "        db['f3b2_syn_hist']=f3b2_syn_hist.eval(session=sess)\n",
    "        db['f4b2_syn_hist']=f4b2_syn_hist.eval(session=sess)\n",
    "        db['f5b2_syn_hist']=f5b2_syn_hist.eval(session=sess)\n",
    "        db['f6b2_syn_hist']=f6b2_syn_hist.eval(session=sess)\n",
    "        db['f7b2_syn_hist']=f7b2_syn_hist.eval(session=sess)\n",
    "        db['f8b2_syn_hist']=f8b2_syn_hist.eval(session=sess)\n",
    "        db['f9b2_syn_hist']=f9b2_syn_hist.eval(session=sess)\n",
    "        db['f10b2_syn_hist']=f10b2_syn_hist.eval(session=sess)\n",
    "        db['f11b2_syn_hist']=f11b2_syn_hist.eval(session=sess)\n",
    "        db['f12b2_syn_hist']=f12b2_syn_hist.eval(session=sess)\n",
    "        db['f13b2_syn_hist']=f13b2_syn_hist.eval(session=sess)\n",
    "        db['f14b2_syn_hist']=f14b2_syn_hist.eval(session=sess)\n",
    "        db['f15b2_syn_hist']=f15b2_syn_hist.eval(session=sess)\n",
    "        db['f16b2_syn_hist']=f16b2_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['f1b11_syn_hist']=f1b11_syn_hist.eval(session=sess)\n",
    "        db['f2b11_syn_hist']=f2b11_syn_hist.eval(session=sess)\n",
    "        db['f3b11_syn_hist']=f3b11_syn_hist.eval(session=sess)\n",
    "        db['f4b11_syn_hist']=f4b11_syn_hist.eval(session=sess)\n",
    "        db['f5b11_syn_hist']=f5b11_syn_hist.eval(session=sess)\n",
    "        db['f6b11_syn_hist']=f6b11_syn_hist.eval(session=sess)\n",
    "        db['f7b11_syn_hist']=f7b11_syn_hist.eval(session=sess)\n",
    "        db['f8b11_syn_hist']=f8b11_syn_hist.eval(session=sess)\n",
    "        db['f9b11_syn_hist']=f9b11_syn_hist.eval(session=sess)\n",
    "        db['f10b11_syn_hist']=f10b11_syn_hist.eval(session=sess)\n",
    "        db['f11b11_syn_hist']=f11b11_syn_hist.eval(session=sess)\n",
    "        db['f12b11_syn_hist']=f12b11_syn_hist.eval(session=sess)\n",
    "        db['f13b11_syn_hist']=f13b11_syn_hist.eval(session=sess)\n",
    "        db['f14b11_syn_hist']=f14b11_syn_hist.eval(session=sess)\n",
    "        db['f15b11_syn_hist']=f15b11_syn_hist.eval(session=sess)\n",
    "        db['f16b11_syn_hist']=f16b11_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['loss_hist']=loss_hist\n",
    "        db['test_hist']=test_hist   \n",
    "        \n",
    "        db['output_hist']=output_hist.eval(session=sess)\n",
    "        db['bip1_gc_syn_hist']=bip1_gc_syn_hist.eval(session=sess)\n",
    "        db['bip2_gc_syn_hist']=bip2_gc_syn_hist.eval(session=sess)\n",
    "        db['bip11_gc_syn_hist']=bip11_gc_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['bip1_copy_gc_syn_hist']=bip1_copy_gc_syn_hist.eval(session=sess)\n",
    "        db['bip2_copy_gc_syn_hist']=bip2_copy_gc_syn_hist.eval(session=sess)\n",
    "        db['bip11_copy_gc_syn_hist']=bip11_copy_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "        db['bip1_am1_syn_hist']=bip1_am1_syn_hist.eval(session=sess)\n",
    "        db['bip2_am1_syn_hist']=bip2_am1_syn_hist.eval(session=sess)\n",
    "        db['bip11_am1_syn_hist']=bip11_am1_syn_hist.eval(session=sess)\n",
    "       \n",
    "        db['am1_gc_syn_hist']=am1_gc_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['am1_b1copy_syn_hist']=am1_b1copy_syn_hist.eval(session=sess)\n",
    "        db['am1_b2copy_syn_hist']=am1_b2copy_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['b1_bias_hist']=b1_bias_hist.eval(session=sess)\n",
    "        db['b2_bias_hist']=b2_bias_hist.eval(session=sess)\n",
    "\n",
    "        db['b11_bias_hist']=b11_bias_hist.eval(session=sess)\n",
    "\n",
    "        db['am1_bias_hist']=am1_bias_hist.eval(session=sess)\n",
    "        db['gc_bias_hist']=gc_bias_hist.eval(session=sess)\n",
    "        db['gc_stretch_hist']=gc_stretch_hist.eval(session=sess)\n",
    "\n",
    "        db['learning_rate']=learn_rate\n",
    "        db['lambda']=lambda1\n",
    "        \n",
    "        if algorithm_choice==1: \n",
    "            db['algorithm']='Gradient_Descent'\n",
    "        elif algorithm_choice==2:\n",
    "            db['algorithm']='Adam'\n",
    "            db['epsilon']=my_epsilon\n",
    "        elif algorithm_choice==3:\n",
    "            db['algorithm']='Momentum'\n",
    "            db['momentum']=momentum_par\n",
    "        elif algorithm_choice==4:\n",
    "            db['algorithm']='Adagrad'\n",
    "        elif algorithm_choice==5:\n",
    "            db['algorithm']='RMSProp'\n",
    "\n",
    "        sio.savemat(wheretosave, db)        \n",
    "\n",
    "    step=step+1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# COMPUTE TRAINED NETWORK OUTPUT\n",
    "\n",
    "o_output=zeros([1024, dur])\n",
    "\n",
    "batchsz=32\n",
    "for bbatch in range(32):\n",
    "    startind=(bbatch)*batchsz\n",
    "    endind=(bbatch+1)*batchsz\n",
    "    fd={batchsize_: train_loss_size, input_filt1_: input_bip1_train[:, startind:endind, :], \\\n",
    "             input_filt2_: input_bip2_train[:, startind:endind, :], input_filt3_: input_bip3_train[:, startind:endind, :],\\\n",
    "             input_filt4_: input_bip4_train[:, startind:endind, :], input_filt5_: input_bip5_train[:, startind:endind, :],\\\n",
    "             input_filt6_: input_bip6_train[:, startind:endind, :], input_filt7_: input_bip7_train[:, startind:endind, :],\\\n",
    "             input_filt8_: input_bip8_train[:, startind:endind, :], input_filt9_: input_bip9_train[:, startind:endind, :],\\\n",
    "             input_filt10_: input_bip10_train[:, startind:endind, :], input_filt11_: input_bip11_train[:, startind:endind, :],\\\n",
    "             input_filt12_: input_bip12_train[:, startind:endind, :], input_filt13_: input_bip13_train[:, startind:endind, :],\\\n",
    "             input_filt14_: input_bip14_train[:, startind:endind, :], input_filt15_: input_bip15_train[:, startind:endind, :],\\\n",
    "             input_filt16_: input_bip16_train[:, startind:endind, :]}\n",
    "    o_output[startind:endind, :]=np.reshape(sess.run([output], fd), [32, dur]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SAVE PARAMETER HISTORIES AND TRAINING HYPERPARAMSIB\n",
    "\n",
    "db={}\n",
    "\n",
    "db['b1_out']=b1copy_out\n",
    "db['am1_out']=am1_out\n",
    "db['b11a1_mult']=b11a1_mult.eval(session=sess, feed_dict=singlefd)\n",
    "db['b1copy_out']=b1copy_out\n",
    "db['b2_out']=b2_out\n",
    "db['b11_out']=b11_out\n",
    "db['input1']=input1\n",
    "\n",
    "db['f1b1_syn_hist']=f1b1_syn_hist.eval(session=sess)\n",
    "db['f2b1_syn_hist']=f2b1_syn_hist.eval(session=sess)\n",
    "db['f3b1_syn_hist']=f3b1_syn_hist.eval(session=sess)\n",
    "db['f4b1_syn_hist']=f4b1_syn_hist.eval(session=sess)\n",
    "db['f5b1_syn_hist']=f5b1_syn_hist.eval(session=sess)\n",
    "db['f6b1_syn_hist']=f6b1_syn_hist.eval(session=sess)\n",
    "db['f7b1_syn_hist']=f7b1_syn_hist.eval(session=sess)\n",
    "db['f8b1_syn_hist']=f8b1_syn_hist.eval(session=sess)\n",
    "db['f9b1_syn_hist']=f9b1_syn_hist.eval(session=sess)\n",
    "db['f10b1_syn_hist']=f10b1_syn_hist.eval(session=sess)\n",
    "db['f11b1_syn_hist']=f11b1_syn_hist.eval(session=sess)\n",
    "db['f12b1_syn_hist']=f12b1_syn_hist.eval(session=sess)\n",
    "db['f13b1_syn_hist']=f13b1_syn_hist.eval(session=sess)\n",
    "db['f14b1_syn_hist']=f14b1_syn_hist.eval(session=sess)\n",
    "db['f15b1_syn_hist']=f15b1_syn_hist.eval(session=sess)\n",
    "db['f16b1_syn_hist']=f16b1_syn_hist.eval(session=sess)\n",
    "\n",
    "db['f1b2_syn_hist']=f1b2_syn_hist.eval(session=sess)\n",
    "db['f2b2_syn_hist']=f2b2_syn_hist.eval(session=sess)\n",
    "db['f3b2_syn_hist']=f3b2_syn_hist.eval(session=sess)\n",
    "db['f4b2_syn_hist']=f4b2_syn_hist.eval(session=sess)\n",
    "db['f5b2_syn_hist']=f5b2_syn_hist.eval(session=sess)\n",
    "db['f6b2_syn_hist']=f6b2_syn_hist.eval(session=sess)\n",
    "db['f7b2_syn_hist']=f7b2_syn_hist.eval(session=sess)\n",
    "db['f8b2_syn_hist']=f8b2_syn_hist.eval(session=sess)\n",
    "db['f9b2_syn_hist']=f9b2_syn_hist.eval(session=sess)\n",
    "db['f10b2_syn_hist']=f10b2_syn_hist.eval(session=sess)\n",
    "db['f11b2_syn_hist']=f11b2_syn_hist.eval(session=sess)\n",
    "db['f12b2_syn_hist']=f12b2_syn_hist.eval(session=sess)\n",
    "db['f13b2_syn_hist']=f13b2_syn_hist.eval(session=sess)\n",
    "db['f14b2_syn_hist']=f14b2_syn_hist.eval(session=sess)\n",
    "db['f15b2_syn_hist']=f15b2_syn_hist.eval(session=sess)\n",
    "db['f16b2_syn_hist']=f16b2_syn_hist.eval(session=sess)\n",
    "\n",
    "db['f1b11_syn_hist']=f1b11_syn_hist.eval(session=sess)\n",
    "db['f2b11_syn_hist']=f2b11_syn_hist.eval(session=sess)\n",
    "db['f3b11_syn_hist']=f3b11_syn_hist.eval(session=sess)\n",
    "db['f4b11_syn_hist']=f4b11_syn_hist.eval(session=sess)\n",
    "db['f5b11_syn_hist']=f5b11_syn_hist.eval(session=sess)\n",
    "db['f6b11_syn_hist']=f6b11_syn_hist.eval(session=sess)\n",
    "db['f7b11_syn_hist']=f7b11_syn_hist.eval(session=sess)\n",
    "db['f8b11_syn_hist']=f8b11_syn_hist.eval(session=sess)\n",
    "db['f9b11_syn_hist']=f9b11_syn_hist.eval(session=sess)\n",
    "db['f10b11_syn_hist']=f10b11_syn_hist.eval(session=sess)\n",
    "db['f11b11_syn_hist']=f11b11_syn_hist.eval(session=sess)\n",
    "db['f12b11_syn_hist']=f12b11_syn_hist.eval(session=sess)\n",
    "db['f13b11_syn_hist']=f13b11_syn_hist.eval(session=sess)\n",
    "db['f14b11_syn_hist']=f14b11_syn_hist.eval(session=sess)\n",
    "db['f15b11_syn_hist']=f15b11_syn_hist.eval(session=sess)\n",
    "db['f16b11_syn_hist']=f16b11_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip1_gc_syn_hist']=bip1_gc_syn_hist.eval(session=sess)\n",
    "db['bip2_gc_syn_hist']=bip2_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip11_gc_syn_hist']=bip11_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip1_copy_gc_syn_hist']=bip1_copy_gc_syn_hist.eval(session=sess)\n",
    "db['bip2_copy_gc_syn_hist']=bip2_copy_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip11_copy_gc_syn_hist']=bip11_copy_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip1_am1_syn_hist']=bip1_am1_syn_hist.eval(session=sess)\n",
    "db['bip2_am1_syn_hist']=bip2_am1_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip11_am1_syn_hist']=bip11_am1_syn_hist.eval(session=sess)\n",
    "\n",
    "db['am1_gc_syn_hist']=am1_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['am1_b1copy_syn_hist']=am1_b1copy_syn_hist.eval(session=sess)\n",
    "db['am1_b2copy_syn_hist']=am1_b2copy_syn_hist.eval(session=sess)\n",
    "\n",
    "db['b1_bias_hist']=b1_bias_hist.eval(session=sess)\n",
    "db['b2_bias_hist']=b2_bias_hist.eval(session=sess)\n",
    "db['b11_bias_hist']=b11_bias_hist.eval(session=sess)\n",
    "\n",
    "db['am1_bias_hist']=am1_bias_hist.eval(session=sess)\n",
    "db['gc_bias_hist']=gc_bias_hist.eval(session=sess)\n",
    "db['gc_stretch_hist']=gc_stretch_hist.eval(session=sess)\n",
    "\n",
    "db['output']=o_output\n",
    "\n",
    "db['loss_hist']=loss_hist\n",
    "db['batch_loss_hist']=batch_loss_hist\n",
    "db['test_hist']=test_hist\n",
    "\n",
    "db['learning_rate']=learn_rate\n",
    "db['lambda']=lambda1\n",
    "db['batch_size']=batchsize\n",
    "db['no_data_ex']=no_data_ex\n",
    "\n",
    "db['datapath']=datapath\n",
    "\n",
    "db['L1_hist']=L1_hist\n",
    "db['output_hist']=output_hist.eval(session=sess)\n",
    "\n",
    "\n",
    "\n",
    "if algorithm_choice==1: \n",
    "    db['algorithm']='Gradient_Descent'\n",
    "elif algorithm_choice==2:\n",
    "    db['algorithm']='Adam'\n",
    "    db['epsilon']=my_epsilon\n",
    "elif algorithm_choice==3:\n",
    "    db['algorithm']='Momentum'\n",
    "    db['momentum']=momentum_par\n",
    "elif algorithm_choice==4:\n",
    "    db['algorithm']='Adagrad'\n",
    "elif algorithm_choice==5:\n",
    "    db['algorithm']='RMSProp'\n",
    "\n",
    "sio.savemat(wheretosave, db)\n",
    "print(wheretosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "bip1=b1_relu.eval(session=sess, feed_dict=singlefd)\n",
    "print(shape(bip1))\n",
    "plt.figure()\n",
    "plt.plot(np.transpose(bip1[:, 1, :]))\n",
    "\n",
    "bip2=b2_relu.eval(session=sess, feed_dict=singlefd)\n",
    "print(shape(bip2))\n",
    "plt.figure()\n",
    "plt.plot(np.transpose(bip2[:, 1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "b1_bias_hist.eval()\n",
    "\n",
    "b2_bias_hist.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
