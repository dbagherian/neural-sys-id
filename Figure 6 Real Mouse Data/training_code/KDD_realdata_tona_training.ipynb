{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#path to save trained model\n",
    "sd=50000\n",
    "\n",
    "\n",
    "\n",
    "wheretosave='/home/ubuntu/Notebooks/kdd_tona9_sd' + str(sd) + '.mat'\n",
    "wheretosave='/home/ubuntu/Notebooks/kdd_tona9_bias_sd' + str(sd) + '.mat'\n",
    "no_data_ex=4640 \n",
    "no_data_validation=182 \n",
    "no_data_test=160\n",
    "train_loss_size = 32 \n",
    "total_data_ex=4982 \n",
    "\n",
    "#number of pixels in training images\n",
    "numpix=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p27/lib/python2.7/site-packages/tensorflow_core/__init__.py:1467: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import hdf5storage\n",
    "from __future__ import division\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "run_opts = tf.RunOptions(report_tensor_allocations_upon_oom = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Handle training data: Stimuli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "#load preconvolved stimuli\n",
    "\n",
    "datapath='/home/ubuntu/Notebooks/kdd_tona_preconv_data.mat'\n",
    "\n",
    "data = hdf5storage.loadmat(datapath)\n",
    "\n",
    "## Handle training data: Stimuli convolved with bipolar cell kernels\n",
    "\n",
    "input_bip1_0 = data['b1_input']\n",
    "input_bip2_0 = data['b2_input']\n",
    "input_bip3_0 = data['b3_input']\n",
    "input_bip4_0 = data['b4_input']\n",
    "input_bip5_0 = data['b5_input']\n",
    "input_bip6_0 = data['b6_input']\n",
    "input_bip7_0 = data['b7_input']\n",
    "input_bip8_0 = data['b8_input']\n",
    "input_bip9_0 = data['b9_input']\n",
    "input_bip10_0 = data['b10_input']\n",
    "input_bip11_0 = data['b11_input']\n",
    "input_bip12_0 = data['b12_input']\n",
    "input_bip13_0 = data['b13_input']\n",
    "input_bip14_0 = data['b14_input']\n",
    "input_bip15_0 = data['b15_input']\n",
    "input_bip16_0 = data['b16_input']\n",
    "\n",
    "\n",
    "\n",
    "data_duration1=input_bip1_0.shape[1]\n",
    "print(data_duration1)\n",
    "\n",
    "data_duration = 990\n",
    "\n",
    "def rearrange_bip_input(input_bip_0, startind, endind):\n",
    "    input_bip_1 = reshape(input_bip_0, [1, total_data_ex, data_duration1, numpix])\n",
    "    input_bip_11 = input_bip_1[:, startind:endind, 7:997, :]\n",
    "    input_bip_2 = np.swapaxes(input_bip_11, 0, 3)\n",
    "    input_bip_3 = reshape(input_bip_2, [numpix, total_data_ex, data_duration])\n",
    "    return input_bip_3\n",
    "\n",
    "startind = 0\n",
    "endind = total_data_ex\n",
    "\n",
    "input_bip1_3 = rearrange_bip_input(input_bip1_0, startind, endind)\n",
    "input_bip2_3 = rearrange_bip_input(input_bip2_0, startind, endind)\n",
    "input_bip3_3 = rearrange_bip_input(input_bip3_0, startind, endind)\n",
    "input_bip4_3 = rearrange_bip_input(input_bip4_0, startind, endind)\n",
    "input_bip5_3 = rearrange_bip_input(input_bip5_0, startind, endind)\n",
    "input_bip6_3 = rearrange_bip_input(input_bip6_0, startind, endind)\n",
    "input_bip7_3 = rearrange_bip_input(input_bip7_0, startind, endind)\n",
    "input_bip8_3 = rearrange_bip_input(input_bip8_0, startind, endind)\n",
    "input_bip9_3 = rearrange_bip_input(input_bip9_0, startind, endind)\n",
    "input_bip10_3 = rearrange_bip_input(input_bip10_0, startind, endind)\n",
    "input_bip11_3 = rearrange_bip_input(input_bip11_0, startind, endind)\n",
    "input_bip12_3 = rearrange_bip_input(input_bip12_0, startind, endind)\n",
    "input_bip13_3 = rearrange_bip_input(input_bip13_0, startind, endind)\n",
    "input_bip14_3 = rearrange_bip_input(input_bip14_0, startind, endind)\n",
    "input_bip15_3 = rearrange_bip_input(input_bip15_0, startind, endind)\n",
    "input_bip16_3 = rearrange_bip_input(input_bip16_0, startind, endind)\n",
    "\n",
    "\n",
    "input_bip1_valid = input_bip1_3[:, 0:no_data_validation, :]\n",
    "input_bip1_train = input_bip1_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip1_test = input_bip1_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip2_valid = input_bip2_3[:, 0:no_data_validation, :]\n",
    "input_bip2_train = input_bip2_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip2_test = input_bip2_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip3_valid = input_bip3_3[:, 0:no_data_validation, :]\n",
    "input_bip3_train = input_bip3_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip3_test = input_bip3_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip4_valid = input_bip4_3[:, 0:no_data_validation, :]\n",
    "input_bip4_train = input_bip4_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip4_test = input_bip4_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip5_valid = input_bip5_3[:, 0:no_data_validation, :]\n",
    "input_bip5_train = input_bip5_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip5_test = input_bip5_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip6_valid = input_bip6_3[:, 0:no_data_validation, :]\n",
    "input_bip6_train = input_bip6_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip6_test = input_bip6_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip7_valid = input_bip7_3[:, 0:no_data_validation, :]\n",
    "input_bip7_train = input_bip7_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip7_test = input_bip7_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip8_valid = input_bip8_3[:, 0:no_data_validation, :]\n",
    "input_bip8_train = input_bip8_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip8_test = input_bip8_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip9_valid = input_bip9_3[:, 0:no_data_validation, :]\n",
    "input_bip9_train = input_bip9_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip9_test = input_bip9_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip10_valid = input_bip10_3[:, 0:no_data_validation, :]\n",
    "input_bip10_train = input_bip10_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip10_test = input_bip10_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "\n",
    "input_bip11_valid = input_bip11_3[:, 0:no_data_validation, :]\n",
    "input_bip11_train = input_bip11_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip11_test = input_bip11_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "\n",
    "input_bip12_valid = input_bip12_3[:, 0:no_data_validation, :]\n",
    "input_bip12_train = input_bip12_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip12_test = input_bip12_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip13_valid = input_bip13_3[:, 0:no_data_validation, :]\n",
    "input_bip13_train = input_bip13_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip13_test = input_bip13_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip14_valid = input_bip14_3[:, 0:no_data_validation, :]\n",
    "input_bip14_train = input_bip14_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip14_test = input_bip14_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip15_valid = input_bip15_3[:, 0:no_data_validation, :]\n",
    "input_bip15_train = input_bip15_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip15_test = input_bip15_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]\n",
    "\n",
    "input_bip16_valid = input_bip16_3[:, 0:no_data_validation, :]\n",
    "input_bip16_train = input_bip16_3[:, no_data_validation:no_data_validation+no_data_ex, :]\n",
    "input_bip16_test = input_bip16_3[:, no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# load and handle ganglion cell responses\n",
    "\n",
    "\n",
    "datapath='/home/ubuntu/Notebooks/cell9_y_train.mat'\n",
    "data = hdf5storage.loadmat(datapath)\n",
    "\n",
    "y_train0 = 0.5*reshape(data['y_train'], [total_data_ex, 1, data_duration1])\n",
    "y_train0 = y_train0[0:total_data_ex, :, 0:990]\n",
    "\n",
    "y_valid = y_train0[ 0:no_data_validation, :, :]\n",
    "y_train = y_train0[no_data_validation:no_data_validation+no_data_ex, :, :]\n",
    "y_test = y_train0[no_data_validation+no_data_ex:no_data_validation+no_data_ex+no_data_test, :, :]\n",
    "\n",
    "gen_gc_w=[0.0, -0.5, 0.0, 1.0, 0.0]\n",
    "gen_gc_w=np.reshape(gen_gc_w, [5, 1, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SET NUMBER OF NEURONS IN EACH LAYER\n",
    "no_filters=16 #14\n",
    "no_filters_per_bc_type=1\n",
    "\n",
    "no_bipolar_rows = 1\n",
    "no_bipolars= numpix*no_bipolar_rows\n",
    "no_bipolar_types=2 \n",
    "no_relu=0\n",
    "no_am_types = 5\n",
    "no_am1=8 \n",
    "no_am2=21\n",
    "no_am3=21\n",
    "no_gc=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## load and handle filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "\n",
    "\n",
    "def bias_var(shape, initial_val):\n",
    "    initial = tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "#     initial = tf.random_uniform(shape, minval=-1.0, maxval=0.0, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bg_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.1, maxval=0.8, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def ba_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.05, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def zero_synapse_var(shape, initial_val):\n",
    "#     initial_val=tf.zeros(shape=shape)\n",
    "    initial=tf.constant(0.0*initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "#     initial = tf.random_uniform(shape, minval=0.05, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.15, maxval=0.18, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def linear_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.05, maxval=0.08, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def fb_synapse_var(shape, initial_val):\n",
    "    initial_val = initial_val.astype(float32)\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "    \n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "#     initial = tf.random_uniform(shape, minval=0.1, maxval=0.8, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def ab_synapse_var(shape, initial_val):\n",
    "    initial=tf.constant(initial_val, shape=shape)\n",
    "#     initial=tf.constant(initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.1, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def ag_synapse_var(shape, true_initial_val, train_initial_val):\n",
    "    initial=tf.constant(true_initial_val, shape=shape)\n",
    "#     initial=tf.constant(train_initial_val, shape=shape)\n",
    "    \n",
    "#     initial=tf.constant(true_initial_val+0.2*(np.random.uniform(low=-1.0, high=1.0, size=shape).astype(float32)), shape=shape)\n",
    "    initial = tf.random_uniform(shape, minval=0.1, maxval=0.2, dtype=tf.float32) #2.9\n",
    "    return tf.Variable(initial) #initial\n",
    "\n",
    "def pbconv2d(x, W):\n",
    "    padsize=175 #200 #W.shape[0]\n",
    "    paddedx=tf.pad(x, [[0, 0], [padsize, 0], [0, 0], [0, 0]], 'CONSTANT')\n",
    "    outconv=tf.nn.conv2d(paddedx, W, strides=[1, 1, 1, 1], padding='SAME') #250 for movingdot and noise\n",
    "    #return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+250, 0, 0], [-1, 250, 1, 1])\n",
    "    return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+x_train.shape[1], 0, 0], [-1, x_train.shape[1], 1, 1])\n",
    "\n",
    "\n",
    "def gcconv2d(x, W):\n",
    "    padsize=5 #200 #W.shape[0]\n",
    "    paddedx=tf.pad(x, [[0, 0], [padsize, 0], [0, 0], [0, 0]], 'CONSTANT')\n",
    "    outconv=tf.nn.conv2d(paddedx, W, strides=[1, 1, 1, 1], padding='SAME') #250 for movingdot and noise\n",
    "    #return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+250, 0, 0], [-1, 250, 1, 1])\n",
    "    return tf.reshape(outconv[:, np.round(padsize/2).astype(int):np.round(padsize/2).astype(int)+data_duration, 0, 0], [-1, data_duration, 1, 1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#create input placeholder variables\n",
    "\n",
    "input_filt1_ = tf.placeholder(\"float32\", name=\"input_filt1\")\n",
    "input_filt2_ = tf.placeholder(\"float32\", name=\"input_filt2\")\n",
    "input_filt3_ = tf.placeholder(\"float32\", name=\"input_filt3\")\n",
    "input_filt4_ = tf.placeholder(\"float32\", name=\"input_filt4\")\n",
    "input_filt5_ = tf.placeholder(\"float32\", name=\"input_filt5\")\n",
    "input_filt6_ = tf.placeholder(\"float32\", name=\"input_filt6\")\n",
    "input_filt7_ = tf.placeholder(\"float32\", name=\"input_filt7\")\n",
    "input_filt8_ = tf.placeholder(\"float32\", name=\"input_filt8\")\n",
    "input_filt9_ = tf.placeholder(\"float32\", name=\"input_filt9\")\n",
    "input_filt10_ = tf.placeholder(\"float32\", name=\"input_filt10\")\n",
    "input_filt11_ = tf.placeholder(\"float32\", name=\"input_filt11\")\n",
    "input_filt12_ = tf.placeholder(\"float32\", name=\"input_filt12\")\n",
    "input_filt13_ = tf.placeholder(\"float32\", name=\"input_filt13\")\n",
    "input_filt14_ = tf.placeholder(\"float32\", name=\"input_filt14\")\n",
    "input_filt15_ = tf.placeholder(\"float32\", name=\"input_filt15\")\n",
    "input_filt16_ = tf.placeholder(\"float32\", name=\"input_filt16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# TO HAND ADJUST INITIALIZATIONS, USE PARAMS BELOW\n",
    "# NB: THIS IS FOR PLAYING AROUND/INSPECTION ONLY. \n",
    "# DURING ACTUAL TRAINING, VARIABLES ARE RANDOMLY INITIALIZED (see helper functions)\n",
    "\n",
    "b1g = [0.0]\n",
    "b2g = [0.0]\n",
    "b11g = [0.0]\n",
    "\n",
    "b1copyg = [0.0]\n",
    "b2copyg = [0.0]\n",
    "b11copyg = [0.0]\n",
    "\n",
    "b1b = 0.0\n",
    "b2b = -0.0\n",
    "b11b = -0.0 \n",
    "\n",
    "b1a1 = 0.0\n",
    "b2a1 = 0.0\n",
    "b11a1 = 1.0\n",
    "\n",
    "a1g = [0.0]\n",
    "\n",
    "a1b1copy = 5.0\n",
    "a1b2copy = 0.0\n",
    "\n",
    "\n",
    "bip1_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip1_gc_initial[bip_i, gc_i]=b1g[gc_i]\n",
    "bip1_gc_initial=bip1_gc_initial.astype(float32)\n",
    "\n",
    "bip2_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip2_gc_initial[bip_i, gc_i]=b2g[gc_i]\n",
    "bip2_gc_initial=bip2_gc_initial.astype(float32)\n",
    "\n",
    "\n",
    "bip11_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip11_gc_initial[bip_i, gc_i]=b11g[gc_i]\n",
    "bip11_gc_initial=bip11_gc_initial.astype(float32)\n",
    "\n",
    "\n",
    "\n",
    "bip1_copy_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(4, 12):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip1_copy_gc_initial[bip_i, gc_i]=b1copyg[gc_i]\n",
    "bip1_copy_gc_initial=bip1_copy_gc_initial.astype(float32)\n",
    "\n",
    "bip2_copy_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(8):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip2_copy_gc_initial[bip_i, gc_i]=b2copyg[gc_i]\n",
    "bip2_copy_gc_initial=bip2_copy_gc_initial.astype(float32)\n",
    "\n",
    "\n",
    "bip11_copy_gc_initial=np.zeros([no_bipolars, no_gc])\n",
    "for bip_i in range(8):\n",
    "    for gc_i in range(no_gc):\n",
    "        bip11_gc_initial[bip_i, gc_i]=b11copyg[gc_i]\n",
    "bip11_copy_gc_initial=bip11_copy_gc_initial.astype(float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "am1_b1copy_initial=np.zeros([no_am1, no_bipolars])\n",
    "for am_i in range(1):\n",
    "    for bip_i in range(4, 12):\n",
    "        am1_b1copy_initial[bip_i-4, bip_i]=a1b1copy\n",
    "am1_b1copy_initial=am1_b1copy_initial.astype(float32)\n",
    "\n",
    "am1_b2copy_initial=np.zeros([no_am1, no_bipolars])\n",
    "for am_i in range(3):\n",
    "    for bip_i in range(8):\n",
    "        am1_b2copy_initial[am_i, bip_i]=a1b2copy\n",
    "am1_b2copy_initial=am1_b2copy_initial.astype(float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "am1_gc_initial=np.zeros([no_am1, no_gc])\n",
    "for am_i in range(3):\n",
    "    for gc_i in range(no_gc):\n",
    "        am1_gc_initial[am_i, gc_i]=a1g[gc_i]\n",
    "am1_gc_initial=am1_gc_initial.astype(float32)\n",
    "\n",
    "am1_gc_train_initial=np.zeros([no_am1, no_gc])\n",
    "for am_i in range(no_am1):\n",
    "    am1_gc_train_initial[am_i, 0]=0.0*np.random.uniform()\n",
    "am1_gc_train_initial=am1_gc_train_initial.astype(float32)\n",
    "\n",
    "\n",
    "bip1_am1_initial=np.zeros([no_bipolars, no_am1])\n",
    "for am_i in range(1):\n",
    "    for bip_i in range(8, 16):\n",
    "        bip1_am1_initial[bip_i, am_i]=b1a1\n",
    "bip1_am1_initial=bip1_am1_initial.astype(float32)\n",
    "\n",
    "bip2_am1_initial=np.zeros([no_bipolars, no_am1])\n",
    "for am_i in range(1):\n",
    "    for bip_i in range(8, 16):\n",
    "        bip2_am1_initial[bip_i, am_i]=b2a1\n",
    "bip2_am1_initial=bip2_am1_initial.astype(float32)\n",
    "\n",
    "bip11_am1_initial=np.zeros([no_bipolars, no_am1])\n",
    "for bip_i in range(4, 12):\n",
    "#     for bip_i in range(4, 12):\n",
    "    bip11_am1_initial[bip_i-1, bip_i-4]=b11a1\n",
    "    bip11_am1_initial[bip_i, bip_i-4]=b11a1\n",
    "    bip11_am1_initial[bip_i+1, bip_i-4]=b11a1\n",
    "bip11_am1_initial=bip11_am1_initial.astype(float32)\n",
    "\n",
    "\n",
    "gc_stretch_initial=1.0*np.ones([no_gc, 1])\n",
    "gc_stretch_initial=gc_stretch_initial.astype(float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "# load synaptic weight masks (derived from IPL address book)\n",
    "\n",
    "maskpath='/home/ubuntu/Notebooks/alpha_realdata_syn_weight_masks_2D_30pix.mat'\n",
    "mask=sio.loadmat(maskpath)\n",
    "\n",
    "bip1_gc_mask = mask['bip1_gc_mask']\n",
    "bip2_gc_mask = mask['bip2_gc_mask']\n",
    "bip11_gc_mask = mask['bip11_gc_mask']\n",
    "\n",
    "bip1_am1_mask = mask['bip1_am1_mask']\n",
    "bip2_am1_mask = mask['bip2_am1_mask']\n",
    "bip11_am1_mask = mask['bip11_am1_mask']\n",
    "\n",
    "am1_gc_mask = mask['am1_gc_mask']+1.0\n",
    "\n",
    "print(am1_gc_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# INITIALIZE SYNAPTIC WEIGHT AND BIAS VARIABLES\n",
    "\n",
    "# bip1_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip1_gc_initial), bip1_gc_mask) #20201215\n",
    "bip1_gc_syn=tf.math.multiply(synapse_var([no_bipolars, no_gc], bip1_gc_initial), bip1_gc_mask)\n",
    "\n",
    "bip2_gc_syn=tf.math.multiply(linear_synapse_var([no_bipolars, no_gc], bip2_gc_initial), bip2_gc_mask)\n",
    "# bip2_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip2_gc_initial), bip2_gc_mask)\n",
    "\n",
    "bip11_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip11_gc_initial), bip11_gc_mask)\n",
    "\n",
    "bip1_copy_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip1_copy_gc_initial), bip1_gc_mask)#20201215\n",
    "\n",
    "bip2_copy_gc_syn=tf.math.multiply(zero_synapse_var([no_bipolars, no_gc], bip2_copy_gc_initial), bip2_gc_mask)\n",
    "\n",
    "bip11_copy_gc_syn=tf.math.multiply(bg_synapse_var([no_bipolars, no_gc], bip11_copy_gc_initial), bip11_gc_mask)\n",
    "\n",
    "bip1_am1_syn = tf.math.multiply(ba_synapse_var([no_bipolars, no_am1], bip1_am1_initial), bip1_am1_mask)\n",
    "bip2_am1_syn = tf.math.multiply(ba_synapse_var([no_bipolars, no_am1], bip2_am1_initial), bip2_am1_mask)\n",
    "bip11_am1_syn = tf.math.multiply(ba_synapse_var([no_bipolars, no_am1], bip11_am1_initial), bip11_am1_mask)\n",
    "\n",
    "\n",
    "\n",
    "am1_gc_syn = tf.math.multiply(ag_synapse_var([no_am1, no_gc], am1_gc_initial, am1_gc_train_initial), am1_gc_mask)\n",
    "\n",
    "am1_b1copy_syn = ab_synapse_var([no_am1, no_bipolars], am1_b1copy_initial)\n",
    "\n",
    "am1_b2copy_syn = zero_synapse_var([no_am1, no_bipolars], am1_b2copy_initial)\n",
    "\n",
    "\n",
    "b1_bias_initial=b1b*np.ones([no_bipolars, 1])\n",
    "b1_bias_initial=b1_bias_initial.astype(float32)\n",
    "\n",
    "b2_bias_initial=b2b*np.ones([no_bipolars, 1])\n",
    "b2_bias_initial=b2_bias_initial.astype(float32)\n",
    "\n",
    "\n",
    "b11_bias_initial=b11b*np.ones([no_bipolars, 1])\n",
    "b11_bias_initial=b11_bias_initial.astype(float32)\n",
    "\n",
    "\n",
    "\n",
    "b1_bias=bias_var([no_bipolars, 1], b1_bias_initial)\n",
    "b2_bias=bias_var([no_bipolars, 1], b2_bias_initial)\n",
    "\n",
    "b11_bias=bias_var([no_bipolars, 1], b11_bias_initial)\n",
    "\n",
    "\n",
    "am1_bias_initial=-50.0*np.ones([no_am1, 1])\n",
    "am1_bias_initial=am1_bias_initial.astype(float32)\n",
    "am1_bias=bias_var([no_am1, 1], am1_bias_initial)\n",
    "\n",
    "gc_bias_initial = np.array([[0.0]])\n",
    "gc_bias_initial=gc_bias_initial.astype(float32)\n",
    "gc_bias=bias_var([no_gc, 1], gc_bias_initial)\n",
    "\n",
    "gc_stretch=synapse_var([no_gc, 1], gc_stretch_initial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#INITIALIZE BIPOLAR CELL TEMPORAL KERNELS. three parameter sets modeled after biological bipolar cells.\n",
    "\n",
    "# ## normal filt\n",
    "# f1b1=32.4739\n",
    "# f2b1=-36.2776\n",
    "# f3b1=9.2522\n",
    "# f4b1=-24.8925\n",
    "# f5b1=-3.3185\n",
    "# f6b1=3.4590\n",
    "# f7b1=1.8170\n",
    "# f8b1=-2.8191\n",
    "# f9b1=0.2779\n",
    "# f10b1=-0.0095\n",
    "# f11b1=0.0742\n",
    "# f12b1=0.5002\n",
    "# f13b1=-0.8313\n",
    "# f14b1=1.0948\n",
    "# f15b1=-0.7449\n",
    "# f16b1=0.6164\n",
    "\n",
    "# f1b2=32.4739\n",
    "# f2b2=-36.2776\n",
    "# f3b2=9.2522\n",
    "# f4b2=-24.8925\n",
    "# f5b2=-3.3185\n",
    "# f6b2=3.4590\n",
    "# f7b2=1.8170\n",
    "# f8b2=-2.8191\n",
    "# f9b2=0.2779\n",
    "# f10b2=-0.0095\n",
    "# f11b2=0.0742\n",
    "# f12b2=0.5002\n",
    "# f13b2=-0.8313\n",
    "# f14b2=1.0948\n",
    "# f15b2=-0.7449\n",
    "# f16b2=0.6164\n",
    "\n",
    "# f1b11=-32.4739\n",
    "# f2b11=36.2776\n",
    "# f3b11=-9.2522\n",
    "# f4b11=24.8925\n",
    "# f5b11=3.3185\n",
    "# f6b11=-3.4590\n",
    "# f7b11=-1.8170\n",
    "# f8b11=2.8191\n",
    "# f9b11=-0.2779\n",
    "# f10b11=0.0095\n",
    "# f11b11=-0.0742\n",
    "# f12b11=-0.5002\n",
    "# f13b11=0.8313\n",
    "# f14b11=-1.0948\n",
    "# f15b11=0.7449\n",
    "# f16b11=-0.6164\n",
    "\n",
    "## slow filt\n",
    "f1b1=8.9629\n",
    "f2b1=-14.8934\n",
    "f3b1=-3.7342\n",
    "f4b1=-2.4524\n",
    "f5b1=-2.2385\n",
    "f6b1=4.8663\n",
    "f7b1=1.0306\n",
    "f8b1=-0.1179\n",
    "f9b1=-0.1026\n",
    "f10b1=0.1568\n",
    "f11b1=0.1731\n",
    "f12b1=0.1854\n",
    "f13b1=0.0526\n",
    "f14b1=-0.0769\n",
    "f15b1=-0.0104\n",
    "f16b1=-0.0069\n",
    "\n",
    "f1b2=8.9629\n",
    "f2b2=-14.8934\n",
    "f3b2=-3.7342\n",
    "f4b2=-2.4524\n",
    "f5b2=-2.2385\n",
    "f6b2=4.8663\n",
    "f7b2=1.0306\n",
    "f8b2=-0.1179\n",
    "f9b2=-0.1026\n",
    "f10b2=0.1568\n",
    "f11b2=0.1731\n",
    "f12b2=0.1854\n",
    "f13b2=0.0526\n",
    "f14b2=-0.0769\n",
    "f15b2=-0.0104\n",
    "f16b2=-0.0069\n",
    "\n",
    "f1b11=-8.9629\n",
    "f2b11=14.8934\n",
    "f3b11=3.7342\n",
    "f4b11=2.4524\n",
    "f5b11=2.2385\n",
    "f6b11=-4.8663\n",
    "f7b11=-1.0306\n",
    "f8b11=0.1179\n",
    "f9b11=0.1026\n",
    "f10b11=-0.1568\n",
    "f11b11=-0.1731\n",
    "f12b11=-0.1854\n",
    "f13b11=-0.0526\n",
    "f14b11=0.0769\n",
    "f15b11=0.0104\n",
    "f16b11=0.0069\n",
    "\n",
    "\n",
    "# ## fast filt\n",
    "# f1b1=3.3739\n",
    "# f2b1=-3.0542\n",
    "# f3b1=4.9315\n",
    "# f4b1=-7.0294\n",
    "# f5b1=1.8001\n",
    "# f6b1=-5.5280\n",
    "# f7b1=-1.2573\n",
    "# f8b1=0.5046\n",
    "# f9b1=0.2822\n",
    "# f10b1=-0.1797\n",
    "# f11b1=-0.0894\n",
    "# f12b1=-0.6905\n",
    "# f13b1=0.0932\n",
    "# f14b1=-0.6807\n",
    "# f15b1=0.4166\n",
    "# f16b1=-0.8054\n",
    "\n",
    "\n",
    "# f1b2=3.3739\n",
    "# f2b2=-3.0542\n",
    "# f3b2=4.9315\n",
    "# f4b2=-7.0294\n",
    "# f5b2=1.8001\n",
    "# f6b2=-5.5280\n",
    "# f7b2=-1.2573\n",
    "# f8b2=0.5046\n",
    "# f9b2=0.2822\n",
    "# f10b2=-0.1797\n",
    "# f11b2=-0.0894\n",
    "# f12b2=-0.6905\n",
    "# f13b2=0.0932\n",
    "# f14b2=-0.6807\n",
    "# f15b2=0.4166\n",
    "# f16b2=-0.8054\n",
    "\n",
    "# f1b11=-3.3739\n",
    "# f2b11=3.0542\n",
    "# f3b11=-4.9315\n",
    "# f4b11=7.0294\n",
    "# f5b11=-1.8001\n",
    "# f6b11=5.5280\n",
    "# f7b11=1.2573\n",
    "# f8b11=-0.5046\n",
    "# f9b11=-0.2822\n",
    "# f10b11=0.1797\n",
    "# f11b11=0.0894\n",
    "# f12b11=0.6905\n",
    "# f13b11=-0.0932\n",
    "# f14b11=0.6807\n",
    "# f15b11=-0.4166\n",
    "# f16b11=0.8054\n",
    "\n",
    "f1b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f1b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f2b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f2b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f3b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f3b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f4b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f4b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f5b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f5b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f6b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f6b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f7b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f7b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f8b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f8b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f9b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f9b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f10b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f10b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f11b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f11b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f12b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f12b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f13b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f13b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f14b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f14b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f15b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f15b1*np.ones([1, no_filters_per_bc_type]))\n",
    "f16b1_syn = fb_synapse_var([1, no_filters_per_bc_type], f16b1*np.ones([1, no_filters_per_bc_type]))\n",
    "\n",
    "f1b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f1b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f2b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f2b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f3b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f3b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f4b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f4b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f5b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f5b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f6b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f6b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f7b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f7b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f8b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f8b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f9b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f9b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f10b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f10b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f11b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f11b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f12b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f12b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f13b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f13b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f14b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f14b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f15b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f15b2*np.ones([1, no_filters_per_bc_type]))\n",
    "f16b2_syn = fb_synapse_var([1, no_filters_per_bc_type], f16b2*np.ones([1, no_filters_per_bc_type]))\n",
    "\n",
    "f1b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f1b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f2b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f2b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f3b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f3b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f4b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f4b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f5b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f5b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f6b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f6b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f7b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f7b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f8b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f8b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f9b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f9b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f10b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f10b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f11b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f11b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f12b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f12b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f13b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f13b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f14b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f14b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f15b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f15b11*np.ones([1, no_filters_per_bc_type]))\n",
    "f16b11_syn = fb_synapse_var([1, no_filters_per_bc_type], f16b11*np.ones([1, no_filters_per_bc_type]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dur=data_duration\n",
    "batchsize=32\n",
    "no_bip=no_bipolars\n",
    "\n",
    "batchsize_ = tf.placeholder(\"int32\", name=\"batch_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# DEFINE ANN GRAPH\n",
    "\n",
    "@tf.function\n",
    "def biplayer(f1_input, f2_input, f3_input, f4_input, f5_input, f6_input, f7_input, f8_input, \n",
    "                f9_input, f10_input, f11_input, f12_input, f13_input, f14_input, f15_input, f16_input, \n",
    "                f1b_syn, f2b_syn, f3b_syn, f4b_syn, f5b_syn, f6b_syn, f7b_syn, f8b_syn, f9b_syn, f10b_syn, \n",
    "                f11b_syn, f12b_syn, f13b_syn, f14b_syn, f15b_syn, f16b_syn, b_bias, bip_gc_syn, no_bip, no_gc, batchsize, dur): #, no_bip, no_filt, batchsize, dur):\n",
    "    \n",
    "    f1b_syn=tf.broadcast_to(tf.reshape(f1b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f2b_syn=tf.broadcast_to(tf.reshape(f2b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f3b_syn=tf.broadcast_to(tf.reshape(f3b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f4b_syn=tf.broadcast_to(tf.reshape(f4b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f5b_syn=tf.broadcast_to(tf.reshape(f5b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f6b_syn=tf.broadcast_to(tf.reshape(f6b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f7b_syn=tf.broadcast_to(tf.reshape(f7b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f8b_syn=tf.broadcast_to(tf.reshape(f8b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f9b_syn=tf.broadcast_to(tf.reshape(f9b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f10b_syn=tf.broadcast_to(tf.reshape(f10b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f11b_syn=tf.broadcast_to(tf.reshape(f11b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f12b_syn=tf.broadcast_to(tf.reshape(f12b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f13b_syn=tf.broadcast_to(tf.reshape(f13b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f14b_syn=tf.broadcast_to(tf.reshape(f14b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f15b_syn=tf.broadcast_to(tf.reshape(f15b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f16b_syn=tf.broadcast_to(tf.reshape(f16b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    \n",
    "    f1_input=tf.tile(f1_input, [no_bipolar_rows, 1, 1])\n",
    "    f2_input=tf.tile(f2_input, [no_bipolar_rows, 1, 1])\n",
    "    f3_input=tf.tile(f3_input, [no_bipolar_rows, 1, 1])\n",
    "    f4_input=tf.tile(f4_input, [no_bipolar_rows, 1, 1])\n",
    "    f5_input=tf.tile(f5_input, [no_bipolar_rows, 1, 1])\n",
    "    f6_input=tf.tile(f6_input, [no_bipolar_rows, 1, 1])\n",
    "    f7_input=tf.tile(f7_input, [no_bipolar_rows, 1, 1])\n",
    "    f8_input=tf.tile(f8_input, [no_bipolar_rows, 1, 1])\n",
    "    f9_input=tf.tile(f9_input, [no_bipolar_rows, 1, 1])\n",
    "    f10_input=tf.tile(f10_input, [no_bipolar_rows, 1, 1])\n",
    "    f11_input=tf.tile(f11_input, [no_bipolar_rows, 1, 1])\n",
    "    f12_input=tf.tile(f12_input, [no_bipolar_rows, 1, 1])\n",
    "    f13_input=tf.tile(f13_input, [no_bipolar_rows, 1, 1])\n",
    "    f14_input=tf.tile(f14_input, [no_bipolar_rows, 1, 1])\n",
    "    f15_input=tf.tile(f15_input, [no_bipolar_rows, 1, 1])\n",
    "    f16_input=tf.tile(f16_input, [no_bipolar_rows, 1, 1])\n",
    "\n",
    "    \n",
    "    b_input = tf.add_n([tf.math.multiply(f1b_syn, f1_input), tf.math.multiply(f2b_syn, f2_input), tf.math.multiply(f3b_syn, f3_input),\\\n",
    "                        tf.math.multiply(f4b_syn, f4_input), tf.math.multiply(f5b_syn, f5_input), tf.math.multiply(f6b_syn, f6_input),\\\n",
    "                        tf.math.multiply(f7b_syn, f7_input), tf.math.multiply(f8b_syn, f8_input), tf.math.multiply(f9b_syn, f9_input),\\\n",
    "                        tf.math.multiply(f10b_syn, f10_input), tf.math.multiply(f11b_syn, f11_input), tf.math.multiply(f12b_syn, f12_input), \\\n",
    "                        tf.math.multiply(f13b_syn, f13_input), tf.math.multiply(f14b_syn, f14_input), tf.math.multiply(f15b_syn, f15_input), tf.math.multiply(f16b_syn, f16_input)])\n",
    "    b_bias_expand=tf.broadcast_to(tf.reshape(b_bias, [no_bipolars, 1, 1]), [no_bipolars, batchsize_, dur], name=\"bro1\")\n",
    "    b_bias_add=tf.add(-1.0*b_input, b_bias_expand)\n",
    "    del b_input\n",
    "    del b_bias_expand\n",
    "    b_relu=tf.nn.relu(b_bias_add)\n",
    "    del b_bias_add\n",
    "    bip_layer_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize_, 1, dur]), [no_bip, batchsize_, no_gc, dur], name=\"bro2\")\n",
    "    \n",
    "    bg_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(bip_gc_syn), [no_bip, 1, no_gc, 1]), [no_bip, batchsize_, no_gc, dur], name=\"bro3\")\n",
    "    bg_mult=tf.math.multiply(bip_layer_expand, bg_syn_expand)\n",
    "    del bip_layer_expand \n",
    "    del bg_syn_expand\n",
    "    bg_sum=tf.reduce_sum(bg_mult, 0)\n",
    "    del bg_mult\n",
    "    return b_relu, bg_sum\n",
    "    \n",
    "@tf.function\n",
    "def linear_biplayer(f1_input, f2_input, f3_input, f4_input, f5_input, f6_input, f7_input, f8_input, \n",
    "                f9_input, f10_input, f11_input, f12_input, f13_input, f14_input, f15_input, f16_input, \n",
    "                f1b_syn, f2b_syn, f3b_syn, f4b_syn, f5b_syn, f6b_syn, f7b_syn, f8b_syn, f9b_syn, f10b_syn, \n",
    "                f11b_syn, f12b_syn, f13b_syn, f14b_syn, f15b_syn, f16b_syn, b_bias, bip_gc_syn, no_bip, no_gc, batchsize, dur): #, no_bip, no_filt, batchsize, dur):\n",
    "    \n",
    "    f1b_syn=tf.broadcast_to(tf.reshape(f1b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur], name='brosyn1')\n",
    "    f2b_syn=tf.broadcast_to(tf.reshape(f2b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f3b_syn=tf.broadcast_to(tf.reshape(f3b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f4b_syn=tf.broadcast_to(tf.reshape(f4b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f5b_syn=tf.broadcast_to(tf.reshape(f5b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f6b_syn=tf.broadcast_to(tf.reshape(f6b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f7b_syn=tf.broadcast_to(tf.reshape(f7b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f8b_syn=tf.broadcast_to(tf.reshape(f8b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f9b_syn=tf.broadcast_to(tf.reshape(f9b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f10b_syn=tf.broadcast_to(tf.reshape(f10b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f11b_syn=tf.broadcast_to(tf.reshape(f11b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f12b_syn=tf.broadcast_to(tf.reshape(f12b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f13b_syn=tf.broadcast_to(tf.reshape(f13b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f14b_syn=tf.broadcast_to(tf.reshape(f14b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f15b_syn=tf.broadcast_to(tf.reshape(f15b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f16b_syn=tf.broadcast_to(tf.reshape(f16b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    \n",
    "    f1_input=tf.tile(f1_input, [no_bipolar_rows, 1, 1])\n",
    "    f2_input=tf.tile(f2_input, [no_bipolar_rows, 1, 1])\n",
    "    f3_input=tf.tile(f3_input, [no_bipolar_rows, 1, 1])\n",
    "    f4_input=tf.tile(f4_input, [no_bipolar_rows, 1, 1])\n",
    "    f5_input=tf.tile(f5_input, [no_bipolar_rows, 1, 1])\n",
    "    f6_input=tf.tile(f6_input, [no_bipolar_rows, 1, 1])\n",
    "    f7_input=tf.tile(f7_input, [no_bipolar_rows, 1, 1])\n",
    "    f8_input=tf.tile(f8_input, [no_bipolar_rows, 1, 1])\n",
    "    f9_input=tf.tile(f9_input, [no_bipolar_rows, 1, 1])\n",
    "    f10_input=tf.tile(f10_input, [no_bipolar_rows, 1, 1])\n",
    "    f11_input=tf.tile(f11_input, [no_bipolar_rows, 1, 1])\n",
    "    f12_input=tf.tile(f12_input, [no_bipolar_rows, 1, 1])\n",
    "    f13_input=tf.tile(f13_input, [no_bipolar_rows, 1, 1])\n",
    "    f14_input=tf.tile(f14_input, [no_bipolar_rows, 1, 1])\n",
    "    f15_input=tf.tile(f15_input, [no_bipolar_rows, 1, 1])\n",
    "    f16_input=tf.tile(f16_input, [no_bipolar_rows, 1, 1])\n",
    "\n",
    "    \n",
    "\n",
    "    b_input = tf.add_n([tf.math.multiply(f1b_syn, f1_input), tf.math.multiply(f2b_syn, f2_input), tf.math.multiply(f3b_syn, f3_input),\\\n",
    "                        tf.math.multiply(f4b_syn, f4_input), tf.math.multiply(f5b_syn, f5_input), tf.math.multiply(f6b_syn, f6_input),\\\n",
    "                        tf.math.multiply(f7b_syn, f7_input), tf.math.multiply(f8b_syn, f8_input), tf.math.multiply(f9b_syn, f9_input),\\\n",
    "                        tf.math.multiply(f10b_syn, f10_input), tf.math.multiply(f11b_syn, f11_input), tf.math.multiply(f12b_syn, f12_input), \\\n",
    "                        tf.math.multiply(f13b_syn, f13_input), tf.math.multiply(f14b_syn, f14_input), tf.math.multiply(f15b_syn, f15_input), tf.math.multiply(f16b_syn, f16_input)])\n",
    "    b_bias_expand=tf.broadcast_to(tf.reshape(b_bias, [no_bipolars, 1, 1]), [no_bipolars, batchsize_, dur], name=\"bro1\")\n",
    "    b_bias_add=tf.add(-1.0*b_input, b_bias_expand)\n",
    "    del b_input\n",
    "    del b_bias_expand\n",
    "    b_relu=b_bias_add\n",
    "    del b_bias_add\n",
    "    bip_layer_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize_, 1, dur]), [no_bip, batchsize_, no_gc, dur], name=\"bro2\")\n",
    "\n",
    "    bg_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(bip_gc_syn), [no_bip, 1, no_gc, 1]), [no_bip, batchsize_, no_gc, dur], name=\"bro3\")\n",
    "    bg_mult=tf.math.multiply(bip_layer_expand, bg_syn_expand)\n",
    "    del bip_layer_expand\n",
    "    del bg_syn_expand\n",
    "    bg_sum=tf.reduce_sum(bg_mult, 0)\n",
    "    del bg_mult\n",
    "    return b_relu, bg_sum\n",
    "    \n",
    "\n",
    "b1_relu, b1g_sum = biplayer(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                            input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                            input_filt14_, input_filt15_, input_filt16_, f1b1_syn, f2b1_syn, f3b1_syn, f4b1_syn, f5b1_syn,\n",
    "                            f6b1_syn, f7b1_syn, f8b1_syn, f9b1_syn, f10b1_syn, f11b1_syn, f12b1_syn, f13b1_syn, f14b1_syn, \n",
    "                            f15b1_syn, f16b1_syn, b1_bias, bip1_gc_syn, no_bip, no_gc, batchsize_, dur)\n",
    "\n",
    "b2_relu, b2g_sum = linear_biplayer(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                                   input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                                   input_filt14_, input_filt15_, input_filt16_, f1b2_syn, f2b2_syn, f3b2_syn, f4b2_syn, f5b2_syn,\n",
    "                                   f6b2_syn, f7b2_syn, f8b2_syn, f9b2_syn, f10b2_syn, f11b2_syn, f12b2_syn, f13b2_syn, f14b2_syn, \n",
    "                                   f15b2_syn, f16b2_syn, b2_bias, bip2_gc_syn, no_bip, no_gc, batchsize_, dur)\n",
    "\n",
    "\n",
    "b11_relu, b11g_sum = biplayer(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                              input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                              input_filt14_, input_filt15_, input_filt16_, f1b11_syn, f2b11_syn, f3b11_syn, f4b11_syn, f5b11_syn,\n",
    "                              f6b11_syn, f7b11_syn, f8b11_syn, f9b11_syn, f10b11_syn, f11b11_syn, f12b11_syn, f13b11_syn, f14b11_syn, \n",
    "                              f15b11_syn, f16b11_syn, b11_bias, bip11_gc_syn, no_bip, no_gc, batchsize_, dur)\n",
    "\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def bip_to_am_input(b_relu, bip_am_syn, no_bip, no_am, batchsize, dur):\n",
    "    bip_layer_am_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize, 1, dur]), [no_bip, batchsize, no_am, dur], name=\"bro10\")\n",
    "    ba_syn_expand = tf.broadcast_to(tf.reshape(tf.abs(bip_am_syn), [no_bip, 1, no_am, 1]), [no_bip, batchsize, no_am, dur], name=\"bro11\")\n",
    "    del b_relu\n",
    "    ba_mult = tf.math.multiply(bip_layer_am_expand, ba_syn_expand)\n",
    "    del bip_layer_am_expand\n",
    "    del ba_syn_expand\n",
    "    ba_sum = tf.reduce_sum(ba_mult, 0)\n",
    "    return ba_mult, ba_sum\n",
    "\n",
    "b11a1_mult, b11a1_sum = bip_to_am_input(b11_relu, bip11_am1_syn, no_bip, no_am1, batchsize_, dur)\n",
    "\n",
    "am1_activation = tf.add_n([b11a1_sum])\n",
    "\n",
    "am1_bias_expand = tf.broadcast_to(am1_bias, [batchsize_, no_am1, dur], name=\"bro20\")\n",
    "\n",
    "am1_bias_add = tf.add(am1_activation, am1_bias_expand)\n",
    "del am1_bias_expand\n",
    "\n",
    "\n",
    "am1_output = tf.nn.relu(am1_bias_add)\n",
    "del am1_bias_add\n",
    "\n",
    "am1_reshape = tf.reshape(am1_output, [batchsize_, no_am1, 1, dur])\n",
    "am1_expand=tf.broadcast_to(am1_reshape, [batchsize_, no_am1, no_gc, dur], name=\"bro22\")\n",
    "am1g_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(am1_gc_syn), [1, no_am1, no_gc, 1]), [batchsize_, no_am1, no_gc, dur], name=\"bro23\")\n",
    "am1g_mult=tf.math.multiply(am1_expand, am1g_syn_expand)\n",
    "del am1_expand\n",
    "del am1g_syn_expand\n",
    "am1g_sum=tf.reduce_sum(am1g_mult, 1)\n",
    "del am1g_mult\n",
    "\n",
    "\n",
    "\n",
    "am1_bcopy_expand=tf.broadcast_to(am1_reshape, [batchsize_, no_am1, no_bip, dur], name=\"bro26\")\n",
    "del am1_reshape\n",
    "\n",
    "@tf.function\n",
    "def biplayer_copy_input(f1_input, f2_input, f3_input, f4_input, f5_input, f6_input, f7_input, f8_input, \n",
    "                        f9_input, f10_input, f11_input, f12_input, f13_input, f14_input, f15_input, f16_input, \n",
    "                        f1b_syn, f2b_syn, f3b_syn, f4b_syn, f5b_syn, f6b_syn, f7b_syn, f8b_syn, f9b_syn, f10b_syn, \n",
    "                        f11b_syn, f12b_syn, f13b_syn, f14b_syn, f15b_syn, f16b_syn,am_bcopy_expand, am_bcopy_syn, b_bias, bip_copy_gc_syn, no_bip, no_am, no_gc, batchsize, dur):\n",
    "    \n",
    "    f1b_syn=tf.broadcast_to(tf.reshape(f1b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f2b_syn=tf.broadcast_to(tf.reshape(f2b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f3b_syn=tf.broadcast_to(tf.reshape(f3b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f4b_syn=tf.broadcast_to(tf.reshape(f4b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f5b_syn=tf.broadcast_to(tf.reshape(f5b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f6b_syn=tf.broadcast_to(tf.reshape(f6b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f7b_syn=tf.broadcast_to(tf.reshape(f7b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f8b_syn=tf.broadcast_to(tf.reshape(f8b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f9b_syn=tf.broadcast_to(tf.reshape(f9b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f10b_syn=tf.broadcast_to(tf.reshape(f10b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f11b_syn=tf.broadcast_to(tf.reshape(f11b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f12b_syn=tf.broadcast_to(tf.reshape(f12b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f13b_syn=tf.broadcast_to(tf.reshape(f13b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f14b_syn=tf.broadcast_to(tf.reshape(f14b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f15b_syn=tf.broadcast_to(tf.reshape(f15b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    f16b_syn=tf.broadcast_to(tf.reshape(f16b_syn, [no_filters_per_bc_type, 1, 1]), [no_bipolars, batchsize_, dur])\n",
    "    \n",
    "    f1_input=tf.tile(f1_input, [no_bipolar_rows, 1, 1])\n",
    "    f2_input=tf.tile(f2_input, [no_bipolar_rows, 1, 1])\n",
    "    f3_input=tf.tile(f3_input, [no_bipolar_rows, 1, 1])\n",
    "    f4_input=tf.tile(f4_input, [no_bipolar_rows, 1, 1])\n",
    "    f5_input=tf.tile(f5_input, [no_bipolar_rows, 1, 1])\n",
    "    f6_input=tf.tile(f6_input, [no_bipolar_rows, 1, 1])\n",
    "    f7_input=tf.tile(f7_input, [no_bipolar_rows, 1, 1])\n",
    "    f8_input=tf.tile(f8_input, [no_bipolar_rows, 1, 1])\n",
    "    f9_input=tf.tile(f9_input, [no_bipolar_rows, 1, 1])\n",
    "    f10_input=tf.tile(f10_input, [no_bipolar_rows, 1, 1])\n",
    "    f11_input=tf.tile(f11_input, [no_bipolar_rows, 1, 1])\n",
    "    f12_input=tf.tile(f12_input, [no_bipolar_rows, 1, 1])\n",
    "    f13_input=tf.tile(f13_input, [no_bipolar_rows, 1, 1])\n",
    "    f14_input=tf.tile(f14_input, [no_bipolar_rows, 1, 1])\n",
    "    f15_input=tf.tile(f15_input, [no_bipolar_rows, 1, 1])\n",
    "    f16_input=tf.tile(f16_input, [no_bipolar_rows, 1, 1])\n",
    "\n",
    "    \n",
    "    b_input = tf.add_n([tf.math.multiply(f1b_syn, f1_input), tf.math.multiply(f2b_syn, f2_input), tf.math.multiply(f3b_syn, f3_input),\\\n",
    "                        tf.math.multiply(f4b_syn, f4_input), tf.math.multiply(f5b_syn, f5_input), tf.math.multiply(f6b_syn, f6_input),\\\n",
    "                        tf.math.multiply(f7b_syn, f7_input), tf.math.multiply(f8b_syn, f8_input), tf.math.multiply(f9b_syn, f9_input),\\\n",
    "                        tf.math.multiply(f10b_syn, f10_input), tf.math.multiply(f11b_syn, f11_input), tf.math.multiply(f12b_syn, f12_input), \\\n",
    "                        tf.math.multiply(f13b_syn, f13_input), tf.math.multiply(f14b_syn, f14_input), tf.math.multiply(f15b_syn, f15_input), tf.math.multiply(f16b_syn, f16_input)])\n",
    "    ambcopy_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(am_bcopy_syn), [1, no_am, no_bip, 1]), [batchsize, no_am, no_bip, dur], name=\"bro33\")\n",
    "    ambcopy_mult=tf.math.multiply(am_bcopy_expand, ambcopy_syn_expand)\n",
    "    del am_bcopy_expand\n",
    "    del ambcopy_syn_expand\n",
    "    ambcopy_sum1=tf.squeeze(tf.reduce_sum(ambcopy_mult, 1))\n",
    "    ambcopy_sum=tf.transpose(ambcopy_sum1, [1, 0, 2])\n",
    "    \n",
    "    del ambcopy_mult\n",
    "    del ambcopy_sum1\n",
    "    \n",
    "    b_bias_expand=tf.broadcast_to(tf.reshape(b_bias, [no_bipolars, 1, 1]), [no_bipolars, batchsize, dur], name=\"bro1\")\n",
    "    b_bias_add=tf.add_n([b_input,-1.0*ambcopy_sum, b_bias_expand])\n",
    "    del b_input\n",
    "    del b_bias_expand\n",
    "    b_relu=tf.nn.relu(b_bias_add)\n",
    "    del b_bias_add\n",
    "    bip_layer_expand=tf.broadcast_to(tf.reshape(b_relu, [no_bip, batchsize_, 1, dur]), [no_bip, batchsize, no_gc, dur], name=\"bro2\")\n",
    "\n",
    "    bg_syn_expand=tf.broadcast_to(tf.reshape(tf.abs(10.0*bip_copy_gc_syn), [no_bip, 1, no_gc, 1]), [no_bip, batchsize, no_gc, dur], name=\"bro3\")\n",
    "    bg_mult=tf.math.multiply(bip_layer_expand, bg_syn_expand)\n",
    "    del bip_layer_expand\n",
    "    del bg_syn_expand\n",
    "    bg_sum=tf.reduce_sum(bg_mult, 0)\n",
    "    del bg_mult\n",
    "    return b_relu, bg_sum\n",
    "\n",
    "b1copy_relu, b1copyg_sum = biplayer_copy_input(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                                  input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                                  input_filt14_, input_filt15_, input_filt16_, f1b1_syn, f2b1_syn, f3b1_syn, f4b1_syn, f5b1_syn,\n",
    "                                  f6b1_syn, f7b1_syn, f8b1_syn, f9b1_syn, f10b1_syn, f11b1_syn, f12b1_syn, f13b1_syn, f14b1_syn, \n",
    "                                  f15b1_syn, f16b1_syn, am1_bcopy_expand, am1_b1copy_syn, b1_bias, bip1_copy_gc_syn, no_bip, \n",
    "                                  no_am1, no_gc, batchsize_, dur)\n",
    "b2copy_relu, b2copyg_sum = biplayer_copy_input(input_filt1_, input_filt2_, input_filt3_, input_filt4_, input_filt5_, input_filt6_, input_filt7_,\n",
    "                                  input_filt8_, input_filt9_, input_filt10_, input_filt11_, input_filt12_, input_filt13_, \n",
    "                                  input_filt14_, input_filt15_, input_filt16_, f1b2_syn, f2b2_syn, f3b2_syn, f4b2_syn, f5b2_syn,\n",
    "                                  f6b2_syn, f7b2_syn, f8b2_syn, f9b2_syn, f10b2_syn, f11b2_syn, f12b2_syn, f13b2_syn, f14b2_syn, \n",
    "                                  f15b2_syn, f16b2_syn,am1_bcopy_expand, am1_b2copy_syn, b2_bias, bip2_copy_gc_syn, \n",
    "                                  no_bip, no_am1, no_gc, batchsize_, dur)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "gc_activation=tf.add_n([b1copyg_sum, b2copyg_sum, b1g_sum, b2g_sum, -1.0*am1g_sum])\n",
    "\n",
    "\n",
    "pre_gc=tf.reshape(tf.squeeze(gcconv2d(tf.reshape(gc_activation, [batchsize_, dur, 1, 1]) , gen_gc_w)), [batchsize_, no_gc, dur])\n",
    "# pre_gc=gc_activation\n",
    "\n",
    "del b1copyg_sum\n",
    "del b2copyg_sum\n",
    "del b1g_sum\n",
    "del b2g_sum\n",
    "del am1g_sum\n",
    "\n",
    "\n",
    "gc_bias_expand=tf.broadcast_to(gc_bias, [batchsize_, no_gc, dur])\n",
    "\n",
    "gc_bias_add=tf.add(pre_gc, gc_bias_expand)\n",
    "\n",
    "output=4.0*gc_stretch*tf.nn.relu(gc_bias_add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(\"float\", name=\"output_spikes\")\n",
    "learn_rate=1e-3\n",
    "\n",
    "trainsampfd={batchsize_: train_loss_size, input_filt1_: input_bip1_train[:, 0:train_loss_size, :], \\\n",
    "             input_filt2_: input_bip2_train[:, 0:train_loss_size, :], input_filt3_: input_bip3_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt4_: input_bip4_train[:, 0:train_loss_size, :], input_filt5_: input_bip5_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt6_: input_bip6_train[:, 0:train_loss_size, :], input_filt7_: input_bip7_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt8_: input_bip8_train[:, 0:train_loss_size, :], input_filt9_: input_bip9_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt10_: input_bip10_train[:, 0:train_loss_size, :], input_filt11_: input_bip11_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt12_: input_bip12_train[:, 0:train_loss_size, :], input_filt13_: input_bip13_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt14_: input_bip14_train[:, 0:train_loss_size, :], input_filt15_: input_bip15_train[:, 0:train_loss_size, :],\\\n",
    "             input_filt16_: input_bip16_train[:, 0:train_loss_size, :], y_:y_train[0:train_loss_size, :, :]}\n",
    "\n",
    "singlefd={batchsize_: 32, input_filt1_: input_bip1_train[:, 0:32, :], \\\n",
    "          input_filt2_: input_bip2_train[:, 0:32, :], input_filt3_: input_bip3_train[:, 0:32, :],\\\n",
    "          input_filt4_: input_bip4_train[:, 0:32, :], input_filt5_: input_bip5_train[:, 0:32, :],\\\n",
    "          input_filt6_: input_bip6_train[:, 0:32, :], input_filt7_: input_bip7_train[:, 0:32, :],\\\n",
    "          input_filt8_: input_bip8_train[:, 0:32, :], input_filt9_: input_bip9_train[:, 0:32, :],\\\n",
    "          input_filt10_: input_bip10_train[:, 0:32, :], input_filt11_: input_bip11_train[:, 0:32, :],\\\n",
    "          input_filt12_: input_bip12_train[:, 0:32, :], input_filt13_: input_bip13_train[:, 0:32, :],\\\n",
    "          input_filt14_: input_bip14_train[:, 0:32, :], input_filt15_: input_bip15_train[:, 0:32, :],\\\n",
    "          input_filt16_: input_bip16_train[:, 0:32, :], y_:y_train[0:32, :, :]}\n",
    "\n",
    "\n",
    "batchsize= 32\n",
    "\n",
    "# L2 loss (normalized)\n",
    "loss = (tf.nn.l2_loss((output - y_), name='loss'))/(batchsize*data_duration) \n",
    "single_loss = tf.reduce_sum((abs(output - y_))/(batchsize*data_duration), 1)\n",
    "\n",
    "# L1 regularization on weights and output\n",
    "reg1 = tf.add_n([tf.reduce_sum(tf.abs(bip1_gc_syn)), tf.reduce_sum(tf.abs(bip2_gc_syn)),  tf.reduce_sum(tf.abs(bip11_gc_syn))])\n",
    "reg2 = tf.add_n([tf.reduce_sum(tf.abs(bip1_copy_gc_syn)), tf.reduce_sum(tf.abs(bip2_copy_gc_syn)), tf.reduce_sum(tf.abs(bip11_copy_gc_syn))])\n",
    "reg3 = tf.add_n([tf.reduce_sum(tf.abs(bip1_am1_syn)), tf.reduce_sum(tf.abs(bip2_am1_syn)), tf.reduce_sum(tf.abs(bip11_am1_syn))])\n",
    "reg5 = tf.add_n([tf.reduce_sum(tf.abs(am1_gc_syn))])\n",
    "reg6 = tf.add_n([tf.reduce_sum(tf.abs(am1_b1copy_syn)), tf.reduce_sum(tf.abs(am1_b2copy_syn))])\n",
    "reg7 = 1e-4*tf.reduce_sum(tf.abs(output))\n",
    "# regularizer=tf.add_n([reg1, reg2, reg3, reg5, reg6, reg7])\n",
    "regularizer=tf.add_n([reg1, reg3, reg5])\n",
    "\n",
    "\n",
    "\n",
    "# lambda1=1e-1 \n",
    "lambda1=1e1 \n",
    "\n",
    "objective=tf.add(loss, lambda1*regularizer)\n",
    "\n",
    "algorithm_choice=2  #1\n",
    "\n",
    "if algorithm_choice==1:\n",
    "    train_step = tf.train.GradientDescentOptimizer(learn_rate).minimize(objective)\n",
    "elif algorithm_choice==2:\n",
    "    my_epsilon=1e-4 #1e-8\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate=learn_rate, epsilon=my_epsilon).minimize(objective)\n",
    "elif algorithm_choice==3:\n",
    "    momentum_par=0.9\n",
    "    train_step = tf.train.MomentumOptimizer(learn_rate, momentum_par).minimize(objective)\n",
    "elif algorithm_choice==4:\n",
    "    train_step = tf.train.AdagradOptimizer(learn_rate).minimize(objective)\n",
    "elif algorithm_choice==5:\n",
    "    train_step = tf.train.RMSPropOptimizer(learn_rate).minimize(objective)\n",
    "\n",
    "sess = tf.InteractiveSession(config=config)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initialize arrays to store weight histories\n",
    "\n",
    "f1b1_syn_hist=tf.reshape(f1b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f2b1_syn_hist=tf.reshape(f2b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f3b1_syn_hist=tf.reshape(f3b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f4b1_syn_hist=tf.reshape(f4b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f5b1_syn_hist=tf.reshape(f5b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f6b1_syn_hist=tf.reshape(f6b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f7b1_syn_hist=tf.reshape(f7b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f8b1_syn_hist=tf.reshape(f8b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f9b1_syn_hist=tf.reshape(f9b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f10b1_syn_hist=tf.reshape(f10b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f11b1_syn_hist=tf.reshape(f11b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f12b1_syn_hist=tf.reshape(f12b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f13b1_syn_hist=tf.reshape(f13b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f14b1_syn_hist=tf.reshape(f14b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f15b1_syn_hist=tf.reshape(f15b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f16b1_syn_hist=tf.reshape(f16b1_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "\n",
    "f1b2_syn_hist=tf.reshape(f1b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f2b2_syn_hist=tf.reshape(f2b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f3b2_syn_hist=tf.reshape(f3b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f4b2_syn_hist=tf.reshape(f4b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f5b2_syn_hist=tf.reshape(f5b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f6b2_syn_hist=tf.reshape(f6b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f7b2_syn_hist=tf.reshape(f7b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f8b2_syn_hist=tf.reshape(f8b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f9b2_syn_hist=tf.reshape(f9b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f10b2_syn_hist=tf.reshape(f10b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f11b2_syn_hist=tf.reshape(f11b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f12b2_syn_hist=tf.reshape(f12b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f13b2_syn_hist=tf.reshape(f13b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f14b2_syn_hist=tf.reshape(f14b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f15b2_syn_hist=tf.reshape(f15b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f16b2_syn_hist=tf.reshape(f16b2_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "\n",
    "f1b11_syn_hist=tf.reshape(f1b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f2b11_syn_hist=tf.reshape(f2b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f3b11_syn_hist=tf.reshape(f3b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f4b11_syn_hist=tf.reshape(f4b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f5b11_syn_hist=tf.reshape(f5b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f6b11_syn_hist=tf.reshape(f6b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f7b11_syn_hist=tf.reshape(f7b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f8b11_syn_hist=tf.reshape(f8b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f9b11_syn_hist=tf.reshape(f9b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f10b11_syn_hist=tf.reshape(f10b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f11b11_syn_hist=tf.reshape(f11b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f12b11_syn_hist=tf.reshape(f12b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f13b11_syn_hist=tf.reshape(f13b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f14b11_syn_hist=tf.reshape(f14b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f15b11_syn_hist=tf.reshape(f15b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "f16b11_syn_hist=tf.reshape(f16b11_syn.eval(session=sess), [1, no_filters_per_bc_type])\n",
    "\n",
    "bip1_gc_syn_hist=tf.reshape(bip1_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip2_gc_syn_hist=tf.reshape(bip2_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip11_gc_syn_hist=tf.reshape(bip11_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "\n",
    "\n",
    "bip1_copy_gc_syn_hist=tf.reshape(bip1_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip2_copy_gc_syn_hist=tf.reshape(bip2_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "bip11_copy_gc_syn_hist=tf.reshape(bip11_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])\n",
    "\n",
    "\n",
    "b1_bias_hist=tf.reshape(b1_bias.eval(session=sess), [1, no_bipolars])\n",
    "b2_bias_hist=tf.reshape(b2_bias.eval(session=sess), [1, no_bipolars])\n",
    "b11_bias_hist=tf.reshape(b11_bias.eval(session=sess), [1, no_bipolars])\n",
    "\n",
    "\n",
    "am1_bias_hist=tf.reshape(am1_bias.eval(session=sess), [1, no_am1])\n",
    "gc_bias_hist=tf.reshape(gc_bias.eval(session=sess), [1, no_gc])\n",
    "\n",
    "gc_stretch_hist=tf.reshape(gc_stretch.eval(session=sess), [1, no_gc])\n",
    "\n",
    "bip1_am1_syn_hist=tf.reshape(bip1_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])\n",
    "bip2_am1_syn_hist=tf.reshape(bip2_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])\n",
    "bip11_am1_syn_hist=tf.reshape(bip11_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])\n",
    "\n",
    "am1_b1copy_syn_hist=tf.reshape(am1_b1copy_syn.eval(session=sess), [1, no_am1, no_bipolars])\n",
    "am1_b2copy_syn_hist=tf.reshape(am1_b2copy_syn.eval(session=sess), [1, no_am1, no_bipolars])\n",
    "\n",
    "am1_gc_syn_hist=tf.reshape(am1_gc_syn.eval(session=sess), [1, no_am1, no_gc])\n",
    "\n",
    "output_hist=tf.reshape(output.eval(session=sess, feed_dict=singlefd), [1, 32, data_duration])\n",
    "\n",
    "#loss\n",
    "loss_hist = ones([1])\n",
    "valid_hist = ones([1])\n",
    "test_hist = ones([1])\n",
    "\n",
    "\n",
    "check=1.0\n",
    "step=0\n",
    "end_flag=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.58134577824519\n"
     ]
    }
   ],
   "source": [
    "# COMPUTE LOSS AT ANN INITIALIZATION\n",
    "\n",
    "loss_val = (batchsize/78.0)*sess.run(loss, feed_dict= trainsampfd)\n",
    "print(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# INITIALIZE LOSS HISTORIES\n",
    "\n",
    "fddd={batchsize_: no_data_test, input_filt1_: input_bip1_test, \\\n",
    "          input_filt2_: input_bip2_test, input_filt3_: input_bip3_test,\\\n",
    "          input_filt4_: input_bip4_test, input_filt5_: input_bip5_test,\\\n",
    "          input_filt6_: input_bip6_test, input_filt7_: input_bip7_test,\\\n",
    "          input_filt8_: input_bip8_test, input_filt9_: input_bip9_test,\\\n",
    "          input_filt10_: input_bip10_test, input_filt11_: input_bip11_test,\\\n",
    "          input_filt12_: input_bip12_test, input_filt13_: input_bip13_test,\\\n",
    "          input_filt14_: input_bip14_test, input_filt15_: input_bip15_test,\\\n",
    "          input_filt16_: input_bip16_test, y_:y_test}\n",
    "\n",
    "test_loss = (batchsize/input_bip1_test.shape[1])*sess.run(loss, feed_dict=fddd)\n",
    "\n",
    "loss_hist=loss_val*loss_hist\n",
    "test_hist=test_loss*test_hist\n",
    "\n",
    "batch_loss_hist=np.zeros([1])\n",
    "batch_loss_hist=batch_loss_hist.astype(float32)\n",
    "L1_hist=np.zeros([1])\n",
    "L1_hist=L1_hist.astype(float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1_bias_hist.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0  loss: = 83.189949 \n",
      "\n",
      "step: 1  loss: = 81.856659 \n",
      "\n",
      "step: 2  loss: = 80.839241 \n",
      "\n",
      "step: 3  loss: = 79.523170 \n",
      "\n",
      "step: 4  loss: = 78.384041 \n",
      "\n",
      "step: 5  loss: = 77.562019 \n",
      "\n",
      "step: 6  loss: = 75.452255 \n",
      "\n",
      "step: 7  loss: = 74.362518 \n",
      "\n",
      "step: 8  loss: = 73.427910 \n",
      "\n",
      "step: 9  loss: = 72.427711 \n",
      "\n",
      "step: 10  loss: = 71.679939 \n",
      "\n",
      "step: 11  loss: = 71.574844 \n",
      "\n",
      "step: 12  loss: = 70.385468 \n",
      "\n",
      "step: 13  loss: = 70.313049 \n",
      "\n",
      "step: 14  loss: = 70.435287 \n",
      "\n",
      "step: 15  loss: = 69.575951 \n",
      "\n",
      "step: 16  loss: = 69.416718 \n",
      "\n",
      "step: 17  loss: = 69.787224 \n",
      "\n",
      "step: 18  loss: = 70.024353 \n",
      "\n",
      "step: 19  loss: = 69.646843 \n",
      "\n",
      "step: 20  loss: = 69.559753 \n",
      "\n",
      "step: 21  loss: = 68.875053 \n",
      "\n",
      "step: 22  loss: = 68.805176 \n",
      "\n",
      "step: 23  loss: = 68.465401 \n",
      "\n",
      "step: 24  loss: = 68.940338 \n",
      "\n",
      "step: 25  loss: = 68.149193 \n",
      "\n",
      "step: 26  loss: = 68.548340 \n",
      "\n",
      "step: 27  loss: = 67.839531 \n",
      "\n",
      "step: 28  loss: = 68.428719 \n",
      "\n",
      "step: 29  loss: = 67.663857 \n",
      "\n",
      "step: 30  loss: = 68.311020 \n",
      "\n",
      "step: 31  loss: = 68.098106 \n",
      "\n",
      "step: 32  loss: = 67.908478 \n",
      "\n",
      "step: 33  loss: = 67.371529 \n",
      "\n",
      "step: 34  loss: = 67.512260 \n",
      "\n",
      "step: 35  loss: = 67.213020 \n",
      "\n",
      "step: 36  loss: = 67.425377 \n",
      "\n",
      "step: 37  loss: = 67.238586 \n",
      "\n",
      "step: 38  loss: = 67.205284 \n",
      "\n",
      "step: 39  loss: = 67.545090 \n",
      "\n",
      "step: 40  loss: = 67.290848 \n",
      "\n",
      "step: 41  loss: = 67.072540 \n",
      "\n",
      "step: 42  loss: = 67.126434 \n",
      "\n",
      "step: 43  loss: = 66.759239 \n",
      "\n",
      "step: 44  loss: = 66.995071 \n",
      "\n",
      "step: 45  loss: = 66.548592 \n",
      "\n",
      "step: 46  loss: = 67.441727 \n",
      "\n",
      "step: 47  loss: = 66.788101 \n",
      "\n",
      "step: 48  loss: = 66.522163 \n",
      "\n",
      "step: 49  loss: = 66.619995 \n",
      "\n",
      "step: 50  loss: = 66.341492 \n",
      "\n",
      "step: 51  loss: = 66.483093 \n",
      "\n",
      "step: 52  loss: = 66.272728 \n",
      "\n",
      "step: 53  loss: = 66.569588 \n",
      "\n",
      "step: 54  loss: = 66.049896 \n",
      "\n",
      "step: 55  loss: = 68.115753 \n",
      "\n",
      "step: 56  loss: = 66.003189 \n",
      "\n",
      "step: 57  loss: = 66.540916 \n",
      "\n",
      "step: 58  loss: = 66.692810 \n",
      "\n",
      "step: 59  loss: = 66.623909 \n",
      "\n",
      "step: 60  loss: = 66.356705 \n",
      "\n",
      "step: 61  loss: = 65.933762 \n",
      "\n",
      "step: 62  loss: = 66.096565 \n",
      "\n",
      "step: 63  loss: = 66.178497 \n",
      "\n",
      "step: 64  loss: = 65.904022 \n",
      "\n",
      "step: 65  loss: = 66.154045 \n",
      "\n",
      "step: 66  loss: = 66.432579 \n",
      "\n",
      "step: 67  loss: = 66.613899 \n",
      "\n",
      "step: 68  loss: = 66.790985 \n",
      "\n",
      "step: 69  loss: = 66.356010 \n",
      "\n",
      "step: 70  loss: = 66.119560 \n",
      "\n",
      "step: 71  loss: = 66.066544 \n",
      "\n",
      "step: 72  loss: = 66.212784 \n",
      "\n",
      "step: 73  loss: = 66.114616 \n",
      "\n",
      "step: 74  loss: = 66.980080 \n",
      "\n",
      "step: 75  loss: = 65.902832 \n",
      "\n",
      "step: 76  loss: = 65.842262 \n",
      "\n",
      "step: 77  loss: = 65.945541 \n",
      "\n",
      "step: 78  loss: = 66.318245 \n",
      "\n",
      "step: 79  loss: = 66.150597 \n",
      "\n",
      "step: 80  loss: = 66.772079 \n",
      "\n",
      "step: 81  loss: = 66.362526 \n",
      "\n",
      "step: 82  loss: = 65.678978 \n",
      "\n",
      "step: 83  loss: = 65.315727 \n",
      "\n",
      "step: 84  loss: = 65.971443 \n",
      "\n",
      "step: 85  loss: = 66.835808 \n",
      "\n",
      "step: 86  loss: = 66.003624 \n",
      "\n",
      "step: 87  loss: = 65.974632 \n",
      "\n",
      "step: 88  loss: = 65.719238 \n",
      "\n",
      "step: 89  loss: = 65.829208 \n",
      "\n",
      "step: 90  loss: = 66.373436 \n",
      "\n",
      "step: 91  loss: = 66.187225 \n",
      "\n",
      "step: 92  loss: = 66.134521 \n",
      "\n",
      "step: 93  loss: = 65.820686 \n",
      "\n",
      "step: 94  loss: = 66.546806 \n",
      "\n",
      "step: 95  loss: = 66.041733 \n",
      "\n",
      "step: 96  loss: = 66.035492 \n",
      "\n",
      "step: 97  loss: = 65.886864 \n",
      "\n",
      "step: 98  loss: = 65.777321 \n",
      "\n",
      "step: 99  loss: = 66.073082 \n",
      "\n",
      "step: 100  loss: = 66.203819 \n",
      "\n",
      "step: 101  loss: = 65.849373 \n",
      "\n",
      "step: 102  loss: = 66.200836 \n",
      "\n",
      "step: 103  loss: = 65.901833 \n",
      "\n",
      "step: 104  loss: = 66.079948 \n",
      "\n",
      "step: 105  loss: = 65.671593 \n",
      "\n",
      "step: 106  loss: = 66.147072 \n",
      "\n",
      "step: 107  loss: = 65.671013 \n",
      "\n",
      "step: 108  loss: = 65.672577 \n",
      "\n",
      "step: 109  loss: = 65.880386 \n",
      "\n",
      "step: 110  loss: = 66.373940 \n",
      "\n",
      "step: 111  loss: = 65.490936 \n",
      "\n",
      "step: 112  loss: = 65.974373 \n",
      "\n",
      "step: 113  loss: = 65.473763 \n",
      "\n",
      "step: 114  loss: = 65.702774 \n",
      "\n",
      "step: 115  loss: = 66.034363 \n",
      "\n",
      "step: 116  loss: = 65.892998 \n",
      "\n",
      "step: 117  loss: = 65.538513 \n",
      "\n",
      "step: 118  loss: = 65.404289 \n",
      "\n",
      "step: 119  loss: = 65.506989 \n",
      "\n",
      "step: 120  loss: = 65.932877 \n",
      "\n",
      "step: 121  loss: = 65.495804 \n",
      "\n",
      "step: 122  loss: = 65.950615 \n",
      "\n",
      "step: 123  loss: = 65.924530 \n",
      "\n",
      "step: 124  loss: = 65.745102 \n",
      "\n",
      "step: 125  loss: = 65.648193 \n",
      "\n",
      "step: 126  loss: = 65.825897 \n",
      "\n",
      "step: 127  loss: = 65.895203 \n",
      "\n",
      "step: 128  loss: = 66.283333 \n",
      "\n",
      "step: 129  loss: = 65.520348 \n",
      "\n",
      "step: 130  loss: = 66.423019 \n",
      "\n",
      "step: 131  loss: = 66.206306 \n",
      "\n",
      "step: 132  loss: = 66.133255 \n",
      "\n",
      "step: 133  loss: = 65.628052 \n",
      "\n",
      "step: 134  loss: = 65.456726 \n",
      "\n",
      "step: 135  loss: = 65.361076 \n",
      "\n",
      "step: 136  loss: = 66.075310 \n",
      "\n",
      "step: 137  loss: = 65.399506 \n",
      "\n",
      "step: 138  loss: = 65.361923 \n",
      "\n",
      "step: 139  loss: = 65.502441 \n",
      "\n",
      "step: 140  loss: = 65.478386 \n",
      "\n",
      "step: 141  loss: = 66.963570 \n",
      "\n",
      "step: 142  loss: = 66.047424 \n",
      "\n",
      "step: 143  loss: = 65.751930 \n",
      "\n",
      "step: 144  loss: = 66.011726 \n",
      "\n",
      "step: 145  loss: = 67.088966 \n",
      "\n",
      "step: 146  loss: = 66.331139 \n",
      "\n",
      "step: 147  loss: = 65.908455 \n",
      "\n",
      "step: 148  loss: = 66.586983 \n",
      "\n",
      "step: 149  loss: = 66.192429 \n",
      "\n",
      "step: 150  loss: = 66.265991 \n",
      "\n",
      "step: 151  loss: = 65.905144 \n",
      "\n",
      "step: 152  loss: = 65.804283 \n",
      "\n",
      "step: 153  loss: = 65.933655 \n",
      "\n",
      "step: 154  loss: = 65.789665 \n",
      "\n",
      "step: 155  loss: = 66.373650 \n",
      "\n",
      "step: 156  loss: = 66.562912 \n",
      "\n",
      "step: 157  loss: = 66.256828 \n",
      "\n",
      "step: 158  loss: = 65.569839 \n",
      "\n",
      "step: 159  loss: = 65.231033 \n",
      "\n",
      "step: 160  loss: = 65.796722 \n",
      "\n",
      "step: 161  loss: = 65.806831 \n",
      "\n",
      "step: 162  loss: = 67.014908 \n",
      "\n",
      "step: 163  loss: = 66.120888 \n",
      "\n",
      "step: 164  loss: = 66.954498 \n",
      "\n",
      "step: 165  loss: = 66.046814 \n",
      "\n",
      "step: 166  loss: = 65.851257 \n",
      "\n",
      "step: 167  loss: = 66.287262 \n",
      "\n",
      "step: 168  loss: = 65.830750 \n",
      "\n",
      "step: 169  loss: = 66.467583 \n",
      "\n",
      "step: 170  loss: = 66.355507 \n",
      "\n",
      "step: 171  loss: = 65.638397 \n",
      "\n",
      "step: 172  loss: = 66.580605 \n",
      "\n",
      "step: 173  loss: = 66.077507 \n",
      "\n",
      "step: 174  loss: = 65.455803 \n",
      "\n",
      "step: 175  loss: = 65.875412 \n",
      "\n",
      "step: 176  loss: = 65.615181 \n",
      "\n",
      "step: 177  loss: = 67.066322 \n",
      "\n",
      "step: 178  loss: = 65.578262 \n",
      "\n",
      "step: 179  loss: = 66.019333 \n",
      "\n",
      "step: 180  loss: = 65.963310 \n",
      "\n",
      "step: 181  loss: = 65.700821 \n",
      "\n",
      "step: 182  loss: = 65.940819 \n",
      "\n",
      "step: 183  loss: = 65.508095 \n",
      "\n",
      "step: 184  loss: = 66.278076 \n",
      "\n",
      "step: 185  loss: = 66.147881 \n",
      "\n",
      "step: 186  loss: = 65.647919 \n",
      "\n",
      "step: 187  loss: = 66.121857 \n",
      "\n",
      "step: 188  loss: = 65.424278 \n",
      "\n",
      "step: 189  loss: = 66.177956 \n",
      "\n",
      "step: 190  loss: = 65.888145 \n",
      "\n",
      "step: 191  loss: = 65.753815 \n",
      "\n",
      "step: 192  loss: = 65.855049 \n",
      "\n",
      "step: 193  loss: = 65.799561 \n",
      "\n",
      "step: 194  loss: = 66.296776 \n",
      "\n",
      "step: 195  loss: = 65.638878 \n",
      "\n",
      "step: 196  loss: = 65.954666 \n",
      "\n",
      "step: 197  loss: = 66.013954 \n",
      "\n",
      "step: 198  loss: = 65.154175 \n",
      "\n",
      "step: 199  loss: = 65.785408 \n",
      "\n",
      "step: 200  loss: = 65.858086 \n",
      "\n",
      "step: 201  loss: = 66.302544 \n",
      "\n",
      "step: 202  loss: = 65.736313 \n",
      "\n",
      "step: 203  loss: = 65.833672 \n",
      "\n",
      "step: 204  loss: = 65.741074 \n",
      "\n",
      "step: 205  loss: = 65.741043 \n",
      "\n",
      "step: 206  loss: = 66.332657 \n",
      "\n",
      "step: 207  loss: = 65.822510 \n",
      "\n",
      "step: 208  loss: = 65.821823 \n",
      "\n",
      "step: 209  loss: = 66.533730 \n",
      "\n",
      "step: 210  loss: = 65.340157 \n",
      "\n",
      "step: 211  loss: = 65.392342 \n",
      "\n",
      "step: 212  loss: = 66.772079 \n",
      "\n",
      "step: 213  loss: = 65.692261 \n",
      "\n",
      "step: 214  loss: = 65.918282 \n",
      "\n",
      "step: 215  loss: = 67.035400 \n",
      "\n",
      "step: 216  loss: = 65.927620 \n",
      "\n",
      "step: 217  loss: = 65.818420 \n",
      "\n",
      "step: 218  loss: = 66.092743 \n",
      "\n",
      "step: 219  loss: = 65.720337 \n",
      "\n",
      "step: 220  loss: = 65.448868 \n",
      "\n",
      "step: 221  loss: = 65.094727 \n",
      "\n",
      "step: 222  loss: = 66.046661 \n",
      "\n",
      "step: 223  loss: = 66.282509 \n",
      "\n",
      "step: 224  loss: = 65.581482 \n",
      "\n",
      "step: 225  loss: = 65.426247 \n",
      "\n",
      "step: 226  loss: = 65.616356 \n",
      "\n",
      "step: 227  loss: = 65.809647 \n",
      "\n",
      "step: 228  loss: = 65.757286 \n",
      "\n",
      "step: 229  loss: = 66.170250 \n",
      "\n",
      "step: 230  loss: = 66.520454 \n",
      "\n",
      "step: 231  loss: = 65.865379 \n",
      "\n",
      "step: 232  loss: = 66.094101 \n",
      "\n",
      "step: 233  loss: = 65.489326 \n",
      "\n",
      "step: 234  loss: = 65.412064 \n",
      "\n",
      "step: 235  loss: = 66.453094 \n",
      "\n",
      "step: 236  loss: = 65.801773 \n",
      "\n",
      "step: 237  loss: = 65.992226 \n",
      "\n",
      "step: 238  loss: = 65.469711 \n",
      "\n",
      "step: 239  loss: = 65.981613 \n",
      "\n",
      "step: 240  loss: = 65.306808 \n",
      "\n",
      "step: 241  loss: = 66.007271 \n",
      "\n",
      "step: 242  loss: = 65.964348 \n",
      "\n",
      "step: 243  loss: = 65.768478 \n",
      "\n",
      "step: 244  loss: = 65.824028 \n",
      "\n",
      "step: 245  loss: = 65.787979 \n",
      "\n",
      "step: 246  loss: = 65.871056 \n",
      "\n",
      "step: 247  loss: = 65.733238 \n",
      "\n",
      "step: 248  loss: = 65.980606 \n",
      "\n",
      "step: 249  loss: = 65.923080 \n",
      "\n",
      "step: 250  loss: = 65.964813 \n",
      "\n",
      "step: 251  loss: = 66.522034 \n",
      "\n",
      "step: 252  loss: = 66.027939 \n",
      "\n",
      "step: 253  loss: = 65.975555 \n",
      "\n",
      "step: 254  loss: = 65.734215 \n",
      "\n",
      "step: 255  loss: = 66.077118 \n",
      "\n",
      "step: 256  loss: = 65.782753 \n",
      "\n",
      "step: 257  loss: = 65.242470 \n",
      "\n",
      "step: 258  loss: = 65.666725 \n",
      "\n",
      "step: 259  loss: = 66.276375 \n",
      "\n",
      "step: 260  loss: = 65.408089 \n",
      "\n",
      "step: 261  loss: = 65.748642 \n",
      "\n",
      "step: 262  loss: = 67.184616 \n",
      "\n",
      "step: 263  loss: = 65.583855 \n",
      "\n",
      "step: 264  loss: = 66.089149 \n",
      "\n",
      "step: 265  loss: = 65.918633 \n",
      "\n",
      "step: 266  loss: = 65.952866 \n",
      "\n",
      "step: 267  loss: = 66.283226 \n",
      "\n",
      "step: 268  loss: = 65.479111 \n",
      "\n",
      "step: 269  loss: = 65.912582 \n",
      "\n",
      "step: 270  loss: = 65.471527 \n",
      "\n",
      "step: 271  loss: = 65.965958 \n",
      "\n",
      "step: 272  loss: = 66.295204 \n",
      "\n",
      "step: 273  loss: = 66.131874 \n",
      "\n",
      "step: 274  loss: = 65.737129 \n",
      "\n",
      "step: 275  loss: = 66.475334 \n",
      "\n",
      "step: 276  loss: = 66.475754 \n",
      "\n",
      "step: 277  loss: = 66.632118 \n",
      "\n",
      "step: 278  loss: = 66.276405 \n",
      "\n",
      "step: 279  loss: = 66.089546 \n",
      "\n",
      "step: 280  loss: = 66.524170 \n",
      "\n",
      "step: 281  loss: = 65.540253 \n",
      "\n",
      "step: 282  loss: = 65.548126 \n",
      "\n",
      "step: 283  loss: = 65.842003 \n",
      "\n",
      "step: 284  loss: = 66.829933 \n",
      "\n",
      "step: 285  loss: = 66.517326 \n",
      "\n",
      "step: 286  loss: = 66.513145 \n",
      "\n",
      "step: 287  loss: = 66.471184 \n",
      "\n",
      "step: 288  loss: = 66.948769 \n",
      "\n",
      "step: 289  loss: = 65.784393 \n",
      "\n",
      "step: 290  loss: = 66.992279 \n",
      "\n",
      "step: 291  loss: = 66.510315 \n",
      "\n",
      "step: 292  loss: = 65.755257 \n",
      "\n",
      "step: 293  loss: = 65.753853 \n",
      "\n",
      "step: 294  loss: = 65.912712 \n",
      "\n",
      "step: 295  loss: = 65.478813 \n",
      "\n",
      "step: 296  loss: = 66.007233 \n",
      "\n",
      "step: 297  loss: = 65.879257 \n",
      "\n",
      "step: 298  loss: = 65.446083 \n",
      "\n",
      "step: 299  loss: = 66.434486 \n",
      "\n",
      "step: 300  loss: = 66.131386 \n",
      "\n",
      "step: 301  loss: = 66.118561 \n",
      "\n",
      "step: 302  loss: = 66.315506 \n",
      "\n",
      "step: 303  loss: = 66.074509 \n",
      "\n",
      "step: 304  loss: = 66.797745 \n",
      "\n",
      "step: 305  loss: = 66.327103 \n",
      "\n",
      "step: 306  loss: = 65.660187 \n",
      "\n",
      "step: 307  loss: = 66.065681 \n",
      "\n",
      "step: 308  loss: = 66.035278 \n",
      "\n",
      "step: 309  loss: = 66.145088 \n",
      "\n",
      "step: 310  loss: = 66.115448 \n",
      "\n",
      "step: 311  loss: = 65.881554 \n",
      "\n",
      "step: 312  loss: = 65.849052 \n",
      "\n",
      "step: 313  loss: = 66.137680 \n",
      "\n",
      "step: 314  loss: = 65.501678 \n",
      "\n",
      "step: 315  loss: = 65.491592 \n",
      "\n",
      "step: 316  loss: = 65.799782 \n",
      "\n",
      "step: 317  loss: = 65.841331 \n",
      "\n",
      "step: 318  loss: = 65.219765 \n",
      "\n",
      "step: 319  loss: = 66.160851 \n",
      "\n",
      "step: 320  loss: = 65.991051 \n",
      "\n",
      "step: 321  loss: = 65.580894 \n",
      "\n",
      "step: 322  loss: = 66.088516 \n",
      "\n",
      "step: 323  loss: = 65.816605 \n",
      "\n",
      "step: 324  loss: = 65.941071 \n",
      "\n",
      "step: 325  loss: = 66.165314 \n",
      "\n",
      "step: 326  loss: = 65.973404 \n",
      "\n",
      "step: 327  loss: = 65.767250 \n",
      "\n",
      "step: 328  loss: = 65.713188 \n",
      "\n",
      "step: 329  loss: = 66.386810 \n",
      "\n",
      "step: 330  loss: = 65.310081 \n",
      "\n",
      "step: 331  loss: = 65.755280 \n",
      "\n",
      "step: 332  loss: = 66.329056 \n",
      "\n",
      "step: 333  loss: = 65.458672 \n",
      "\n",
      "step: 334  loss: = 65.952034 \n",
      "\n",
      "step: 335  loss: = 65.982674 \n",
      "\n",
      "step: 336  loss: = 66.183922 \n",
      "\n",
      "step: 337  loss: = 65.766594 \n",
      "\n",
      "step: 338  loss: = 65.924431 \n",
      "\n",
      "step: 339  loss: = 65.540024 \n",
      "\n",
      "step: 340  loss: = 65.855827 \n",
      "\n",
      "step: 341  loss: = 66.516609 \n",
      "\n",
      "step: 342  loss: = 66.688438 \n",
      "\n",
      "step: 343  loss: = 65.772682 \n",
      "\n",
      "step: 344  loss: = 66.175835 \n",
      "\n",
      "step: 345  loss: = 65.965698 \n",
      "\n",
      "step: 346  loss: = 65.696831 \n",
      "\n",
      "step: 347  loss: = 67.072876 \n",
      "\n",
      "step: 348  loss: = 65.503082 \n",
      "\n",
      "step: 349  loss: = 66.517075 \n",
      "\n",
      "step: 350  loss: = 66.464317 \n",
      "\n",
      "step: 351  loss: = 65.661980 \n",
      "\n",
      "step: 352  loss: = 66.250465 \n",
      "\n",
      "step: 353  loss: = 65.662285 \n",
      "\n",
      "step: 354  loss: = 66.729027 \n",
      "\n",
      "step: 355  loss: = 65.443138 \n",
      "\n",
      "step: 356  loss: = 65.872948 \n",
      "\n",
      "step: 357  loss: = 65.817535 \n",
      "\n",
      "step: 358  loss: = 66.228577 \n",
      "\n",
      "step: 359  loss: = 66.298752 \n",
      "\n",
      "step: 360  loss: = 66.357719 \n",
      "\n",
      "step: 361  loss: = 66.010818 \n",
      "\n",
      "step: 362  loss: = 66.181747 \n",
      "\n",
      "step: 363  loss: = 65.817154 \n",
      "\n",
      "step: 364  loss: = 66.794594 \n",
      "\n",
      "step: 365  loss: = 67.008636 \n",
      "\n",
      "step: 366  loss: = 66.178871 \n",
      "\n",
      "step: 367  loss: = 65.718224 \n",
      "\n",
      "step: 368  loss: = 66.681023 \n",
      "\n",
      "step: 369  loss: = 65.904678 \n",
      "\n",
      "step: 370  loss: = 66.521667 \n",
      "\n",
      "step: 371  loss: = 66.806328 \n",
      "\n",
      "step: 372  loss: = 65.671974 \n",
      "\n",
      "step: 373  loss: = 65.702484 \n",
      "\n",
      "step: 374  loss: = 66.005142 \n",
      "\n",
      "step: 375  loss: = 66.382202 \n",
      "\n",
      "step: 376  loss: = 65.671005 \n",
      "\n",
      "step: 377  loss: = 65.742821 \n",
      "\n",
      "step: 378  loss: = 66.433403 \n",
      "\n",
      "step: 379  loss: = 65.267517 \n",
      "\n",
      "step: 380  loss: = 66.754974 \n",
      "\n",
      "step: 381  loss: = 65.279114 \n",
      "\n",
      "step: 382  loss: = 66.536102 \n",
      "\n",
      "step: 383  loss: = 66.033646 \n",
      "\n",
      "step: 384  loss: = 65.329781 \n",
      "\n",
      "step: 385  loss: = 66.977791 \n",
      "\n",
      "step: 386  loss: = 65.889587 \n",
      "\n",
      "step: 387  loss: = 65.773476 \n",
      "\n",
      "step: 388  loss: = 66.111122 \n",
      "\n",
      "step: 389  loss: = 65.878220 \n",
      "\n",
      "step: 390  loss: = 65.789322 \n",
      "\n",
      "step: 391  loss: = 66.081184 \n",
      "\n",
      "step: 392  loss: = 65.710625 \n",
      "\n",
      "step: 393  loss: = 65.560249 \n",
      "\n",
      "step: 394  loss: = 66.483131 \n",
      "\n",
      "step: 395  loss: = 65.542908 \n",
      "\n",
      "step: 396  loss: = 66.144585 \n",
      "\n",
      "step: 397  loss: = 65.998085 \n",
      "\n",
      "step: 398  loss: = 66.140823 \n",
      "\n",
      "step: 399  loss: = 65.932159 \n",
      "\n",
      "step: 400  loss: = 66.452850 \n",
      "\n",
      "step: 401  loss: = 65.922295 \n",
      "\n",
      "step: 402  loss: = 66.292297 \n",
      "\n",
      "step: 403  loss: = 65.798782 \n",
      "\n",
      "step: 404  loss: = 65.710907 \n",
      "\n",
      "step: 405  loss: = 65.843010 \n",
      "\n",
      "step: 406  loss: = 67.020721 \n",
      "\n",
      "step: 407  loss: = 65.232704 \n",
      "\n",
      "step: 408  loss: = 65.952812 \n",
      "\n",
      "step: 409  loss: = 65.692390 \n",
      "\n",
      "step: 410  loss: = 66.531189 \n",
      "\n",
      "step: 411  loss: = 66.519402 \n",
      "\n",
      "step: 412  loss: = 65.789246 \n",
      "\n",
      "step: 413  loss: = 68.012642 \n",
      "\n",
      "step: 414  loss: = 65.563721 \n",
      "\n",
      "step: 415  loss: = 66.403252 \n",
      "\n",
      "step: 416  loss: = 65.984825 \n",
      "\n",
      "step: 417  loss: = 67.666824 \n",
      "\n",
      "step: 418  loss: = 65.181595 \n",
      "\n",
      "step: 419  loss: = 65.580635 \n",
      "\n",
      "step: 420  loss: = 66.119621 \n",
      "\n",
      "step: 421  loss: = 65.648674 \n",
      "\n",
      "step: 422  loss: = 65.916550 \n",
      "\n",
      "step: 423  loss: = 65.944427 \n",
      "\n",
      "step: 424  loss: = 65.506378 \n",
      "\n",
      "step: 425  loss: = 65.431305 \n",
      "\n",
      "step: 426  loss: = 66.632362 \n",
      "\n",
      "step: 427  loss: = 65.268684 \n",
      "\n",
      "step: 428  loss: = 66.284157 \n",
      "\n",
      "step: 429  loss: = 66.109055 \n",
      "\n",
      "step: 430  loss: = 67.196922 \n",
      "\n",
      "step: 431  loss: = 65.517815 \n",
      "\n",
      "step: 432  loss: = 65.688393 \n",
      "\n",
      "step: 433  loss: = 65.590454 \n",
      "\n",
      "step: 434  loss: = 66.003632 \n",
      "\n",
      "step: 435  loss: = 66.641640 \n",
      "\n",
      "step: 436  loss: = 65.652779 \n",
      "\n",
      "step: 437  loss: = 66.007248 \n",
      "\n",
      "step: 438  loss: = 66.559868 \n",
      "\n",
      "step: 439  loss: = 65.521729 \n",
      "\n",
      "step: 440  loss: = 66.112572 \n",
      "\n",
      "step: 441  loss: = 66.307030 \n",
      "\n",
      "step: 442  loss: = 65.477448 \n",
      "\n",
      "step: 443  loss: = 66.446396 \n",
      "\n",
      "step: 444  loss: = 65.583565 \n",
      "\n",
      "step: 445  loss: = 65.697083 \n",
      "\n",
      "step: 446  loss: = 66.008423 \n",
      "\n",
      "step: 447  loss: = 67.045807 \n",
      "\n",
      "step: 448  loss: = 66.288162 \n",
      "\n",
      "step: 449  loss: = 66.005028 \n",
      "\n",
      "step: 450  loss: = 65.160912 \n",
      "\n",
      "step: 451  loss: = 65.983887 \n",
      "\n",
      "step: 452  loss: = 65.892700 \n",
      "\n",
      "step: 453  loss: = 66.406342 \n",
      "\n",
      "step: 454  loss: = 65.905617 \n",
      "\n",
      "step: 455  loss: = 65.466690 \n",
      "\n",
      "step: 456  loss: = 65.904816 \n",
      "\n",
      "step: 457  loss: = 66.784279 \n",
      "\n",
      "step: 458  loss: = 65.950203 \n",
      "\n",
      "step: 459  loss: = 65.784920 \n",
      "\n",
      "step: 460  loss: = 66.341164 \n",
      "\n",
      "step: 461  loss: = 66.139336 \n",
      "\n",
      "step: 462  loss: = 65.898132 \n",
      "\n",
      "step: 463  loss: = 65.595833 \n",
      "\n",
      "step: 464  loss: = 65.250481 \n",
      "\n",
      "step: 465  loss: = 65.784210 \n",
      "\n",
      "step: 466  loss: = 66.412720 \n",
      "\n",
      "step: 467  loss: = 66.339348 \n",
      "\n",
      "step: 468  loss: = 66.235733 \n",
      "\n",
      "step: 469  loss: = 66.099068 \n",
      "\n",
      "step: 470  loss: = 66.027924 \n",
      "\n",
      "step: 471  loss: = 66.070900 \n",
      "\n",
      "step: 472  loss: = 65.602959 \n",
      "\n",
      "step: 473  loss: = 65.942688 \n",
      "\n",
      "step: 474  loss: = 65.990517 \n",
      "\n",
      "step: 475  loss: = 65.898285 \n",
      "\n",
      "step: 476  loss: = 65.527908 \n",
      "\n",
      "step: 477  loss: = 65.597382 \n",
      "\n",
      "step: 478  loss: = 66.158829 \n",
      "\n",
      "step: 479  loss: = 65.761444 \n",
      "\n",
      "step: 480  loss: = 66.339172 \n",
      "\n",
      "step: 481  loss: = 66.116478 \n",
      "\n",
      "step: 482  loss: = 65.212654 \n",
      "\n",
      "step: 483  loss: = 65.861031 \n",
      "\n",
      "step: 484  loss: = 66.236160 \n",
      "\n",
      "step: 485  loss: = 65.441437 \n",
      "\n",
      "step: 486  loss: = 65.060509 \n",
      "\n",
      "step: 487  loss: = 65.556488 \n",
      "\n",
      "step: 488  loss: = 66.748222 \n",
      "\n",
      "step: 489  loss: = 66.529465 \n",
      "\n",
      "step: 490  loss: = 66.189369 \n",
      "\n",
      "step: 491  loss: = 65.950638 \n",
      "\n",
      "step: 492  loss: = 65.658035 \n",
      "\n",
      "step: 493  loss: = 65.791962 \n",
      "\n",
      "step: 494  loss: = 66.444679 \n",
      "\n",
      "step: 495  loss: = 65.831261 \n",
      "\n",
      "step: 496  loss: = 65.791946 \n",
      "\n",
      "step: 497  loss: = 65.790108 \n",
      "\n",
      "step: 498  loss: = 65.224747 \n",
      "\n",
      "step: 499  loss: = 65.857620 \n",
      "\n",
      "step: 500  loss: = 65.765839 \n",
      "\n",
      "step: 501  loss: = 65.802353 \n",
      "\n",
      "step: 502  loss: = 65.230164 \n",
      "\n",
      "step: 503  loss: = 65.287025 \n",
      "\n",
      "step: 504  loss: = 66.476028 \n",
      "\n",
      "step: 505  loss: = 67.219185 \n",
      "\n",
      "step: 506  loss: = 65.835724 \n",
      "\n",
      "step: 507  loss: = 66.310783 \n",
      "\n",
      "step: 508  loss: = 66.853485 \n",
      "\n",
      "step: 509  loss: = 66.286995 \n",
      "\n",
      "step: 510  loss: = 65.748077 \n",
      "\n",
      "step: 511  loss: = 66.230759 \n",
      "\n",
      "step: 512  loss: = 67.745514 \n",
      "\n",
      "step: 513  loss: = 65.884552 \n",
      "\n",
      "step: 514  loss: = 66.181282 \n",
      "\n",
      "step: 515  loss: = 65.881157 \n",
      "\n",
      "step: 516  loss: = 66.447884 \n",
      "\n",
      "step: 517  loss: = 65.697113 \n",
      "\n",
      "step: 518  loss: = 65.779694 \n",
      "\n",
      "step: 519  loss: = 66.109673 \n",
      "\n",
      "step: 520  loss: = 65.548340 \n",
      "\n",
      "step: 521  loss: = 65.596848 \n",
      "\n",
      "step: 522  loss: = 65.540871 \n",
      "\n",
      "step: 523  loss: = 66.155388 \n",
      "\n",
      "step: 524  loss: = 65.991364 \n",
      "\n",
      "step: 525  loss: = 65.777473 \n",
      "\n",
      "step: 526  loss: = 65.763229 \n",
      "\n",
      "step: 527  loss: = 66.049942 \n",
      "\n",
      "step: 528  loss: = 66.023422 \n",
      "\n",
      "step: 529  loss: = 66.027954 \n",
      "\n",
      "step: 530  loss: = 65.812592 \n",
      "\n",
      "step: 531  loss: = 65.772560 \n",
      "\n",
      "step: 532  loss: = 66.509407 \n",
      "\n",
      "step: 533  loss: = 66.166229 \n",
      "\n",
      "step: 534  loss: = 66.302986 \n",
      "\n",
      "step: 535  loss: = 66.108490 \n",
      "\n",
      "step: 536  loss: = 66.307373 \n",
      "\n",
      "step: 537  loss: = 65.474625 \n",
      "\n",
      "step: 538  loss: = 65.405380 \n",
      "\n",
      "step: 539  loss: = 66.887024 \n",
      "\n",
      "step: 540  loss: = 66.293449 \n",
      "\n",
      "step: 541  loss: = 66.453033 \n",
      "\n",
      "step: 542  loss: = 66.100624 \n",
      "\n",
      "step: 543  loss: = 65.569405 \n",
      "\n",
      "step: 544  loss: = 65.943520 \n",
      "\n",
      "step: 545  loss: = 65.976051 \n",
      "\n",
      "step: 546  loss: = 65.483414 \n",
      "\n",
      "step: 547  loss: = 65.987755 \n",
      "\n",
      "step: 548  loss: = 66.087074 \n",
      "\n",
      "step: 549  loss: = 66.574844 \n",
      "\n",
      "step: 550  loss: = 65.702484 \n",
      "\n",
      "step: 551  loss: = 66.128853 \n",
      "\n",
      "step: 552  loss: = 66.652931 \n",
      "\n",
      "step: 553  loss: = 66.475334 \n",
      "\n",
      "step: 554  loss: = 65.219955 \n",
      "\n",
      "step: 555  loss: = 65.682358 \n",
      "\n",
      "step: 556  loss: = 66.282135 \n",
      "\n",
      "step: 557  loss: = 65.385063 \n",
      "\n",
      "step: 558  loss: = 64.988922 \n",
      "\n",
      "step: 559  loss: = 66.550140 \n",
      "\n",
      "step: 560  loss: = 66.167847 \n",
      "\n",
      "step: 561  loss: = 65.441467 \n",
      "\n",
      "step: 562  loss: = 66.898903 \n",
      "\n",
      "step: 563  loss: = 65.945618 \n",
      "\n",
      "step: 564  loss: = 65.493240 \n",
      "\n",
      "step: 565  loss: = 66.277115 \n",
      "\n",
      "step: 566  loss: = 65.848373 \n",
      "\n",
      "step: 567  loss: = 66.325554 \n",
      "\n",
      "step: 568  loss: = 65.716049 \n",
      "\n",
      "step: 569  loss: = 66.051430 \n",
      "\n",
      "step: 570  loss: = 66.016525 \n",
      "\n",
      "step: 571  loss: = 65.684128 \n",
      "\n",
      "step: 572  loss: = 65.451439 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN THE NETWORK\n",
    "\n",
    "for step in range(100): \n",
    "    \n",
    "    inds = np.reshape(np.random.permutation(range(input_bip1_train.shape[1])), [-1, batchsize])\n",
    "\n",
    "    for n in range(len(inds)):  \n",
    "        fdd = {batchsize_: batchsize, input_filt1_: input_bip1_train[:, inds[n, :], :], \\\n",
    "               input_filt2_: input_bip2_train[:, inds[n, :], :], input_filt3_: input_bip3_train[:, inds[n, :], :],\\\n",
    "               input_filt4_: input_bip4_train[:, inds[n, :], :], input_filt5_: input_bip5_train[:, inds[n, :], :],\\\n",
    "               input_filt6_: input_bip6_train[:, inds[n, :], :], input_filt7_: input_bip7_train[:, inds[n, :], :],\\\n",
    "               input_filt8_: input_bip8_train[:, inds[n, :], :], input_filt9_: input_bip9_train[:, inds[n, :], :],\\\n",
    "               input_filt10_: input_bip10_train[:, inds[n, :], :], input_filt11_: input_bip11_train[:, inds[n, :], :],\\\n",
    "               input_filt12_: input_bip12_train[:, inds[n, :], :], input_filt13_: input_bip13_train[:, inds[n, :], :],\\\n",
    "               input_filt14_: input_bip14_train[:, inds[n, :], :], input_filt15_: input_bip15_train[:, inds[n, :], :],\\\n",
    "               input_filt16_: input_bip16_train[:, inds[n, :], :], y_:y_train[inds[n, :], :, :]}\n",
    "        sess.run(train_step, feed_dict=fdd, options = run_opts)\n",
    "        \n",
    "    batch_loss=sess.run(loss, feed_dict=fdd)\n",
    "    batch_loss_hist=np.concatenate([batch_loss_hist, np.array([batch_loss])], axis=0)\n",
    "    L1=sess.run(regularizer, feed_dict=fdd)\n",
    "    L1_hist=np.concatenate([L1_hist, np.array([L1])], axis=0)\n",
    "    loss_val = (batchsize/train_loss_size)*sess.run(loss, feed_dict= trainsampfd)\n",
    "    loss_hist=np.concatenate([loss_hist, np.array([loss_val])], axis=0)\n",
    "    check=loss_val\n",
    "\n",
    "    print(\"step: %d  loss: = %9f \\n\" % (step, loss_val))\n",
    "    \n",
    "    if (step % 10 == 0):\n",
    "        test_loss = (batchsize/input_bip1_test.shape[1])*sess.run(loss, feed_dict= fddd)\n",
    "        test_hist=np.concatenate([test_hist, np.array([test_loss])], axis=0)\n",
    " \n",
    "\n",
    "    if (step % 10 == 0):\n",
    "        \n",
    "        f1b1_syn_hist=tf.concat([f1b1_syn_hist, tf.reshape(f1b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f1b1_syn_concat')\n",
    "        f2b1_syn_hist=tf.concat([f2b1_syn_hist, tf.reshape(f2b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f2b1_syn_concat')\n",
    "        f3b1_syn_hist=tf.concat([f3b1_syn_hist, tf.reshape(f3b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f3b1_syn_concat')\n",
    "        f4b1_syn_hist=tf.concat([f4b1_syn_hist, tf.reshape(f4b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f4b1_syn_concat')\n",
    "        f5b1_syn_hist=tf.concat([f5b1_syn_hist, tf.reshape(f5b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f5b1_syn_concat')\n",
    "        f6b1_syn_hist=tf.concat([f6b1_syn_hist, tf.reshape(f6b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f6b1_syn_concat')\n",
    "        f7b1_syn_hist=tf.concat([f7b1_syn_hist, tf.reshape(f7b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f7b1_syn_concat')\n",
    "        f8b1_syn_hist=tf.concat([f8b1_syn_hist, tf.reshape(f8b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f8b1_syn_concat')\n",
    "        f9b1_syn_hist=tf.concat([f9b1_syn_hist, tf.reshape(f9b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f9b1_syn_concat')\n",
    "        f10b1_syn_hist=tf.concat([f10b1_syn_hist, tf.reshape(f10b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f10b1_syn_concat')\n",
    "        f11b1_syn_hist=tf.concat([f11b1_syn_hist, tf.reshape(f11b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f11b1_syn_concat')\n",
    "        f12b1_syn_hist=tf.concat([f12b1_syn_hist, tf.reshape(f12b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f12b1_syn_concat')\n",
    "        f13b1_syn_hist=tf.concat([f13b1_syn_hist, tf.reshape(f13b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f13b1_syn_concat')\n",
    "        f14b1_syn_hist=tf.concat([f14b1_syn_hist, tf.reshape(f14b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f14b1_syn_concat')\n",
    "        f15b1_syn_hist=tf.concat([f15b1_syn_hist, tf.reshape(f15b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f15b1_syn_concat')\n",
    "        f16b1_syn_hist=tf.concat([f16b1_syn_hist, tf.reshape(f16b1_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f16b1_syn_concat')\n",
    "        \n",
    "        f1b2_syn_hist=tf.concat([f1b2_syn_hist, tf.reshape(f1b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f1b2_syn_concat')\n",
    "        f2b2_syn_hist=tf.concat([f2b2_syn_hist, tf.reshape(f2b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f2b2_syn_concat')\n",
    "        f3b2_syn_hist=tf.concat([f3b2_syn_hist, tf.reshape(f3b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f3b2_syn_concat')\n",
    "        f4b2_syn_hist=tf.concat([f4b2_syn_hist, tf.reshape(f4b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f4b2_syn_concat')\n",
    "        f5b2_syn_hist=tf.concat([f5b2_syn_hist, tf.reshape(f5b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f5b2_syn_concat')\n",
    "        f6b2_syn_hist=tf.concat([f6b2_syn_hist, tf.reshape(f6b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f6b2_syn_concat')\n",
    "        f7b2_syn_hist=tf.concat([f7b2_syn_hist, tf.reshape(f7b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f7b2_syn_concat')\n",
    "        f8b2_syn_hist=tf.concat([f8b2_syn_hist, tf.reshape(f8b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f8b2_syn_concat')\n",
    "        f9b2_syn_hist=tf.concat([f9b2_syn_hist, tf.reshape(f9b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f9b2_syn_concat')\n",
    "        f10b2_syn_hist=tf.concat([f10b2_syn_hist, tf.reshape(f10b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f10b2_syn_concat')\n",
    "        f11b2_syn_hist=tf.concat([f11b2_syn_hist, tf.reshape(f11b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f11b2_syn_concat')\n",
    "        f12b2_syn_hist=tf.concat([f12b2_syn_hist, tf.reshape(f12b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f12b2_syn_concat')\n",
    "        f13b2_syn_hist=tf.concat([f13b2_syn_hist, tf.reshape(f13b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f13b2_syn_concat')\n",
    "        f14b2_syn_hist=tf.concat([f14b2_syn_hist, tf.reshape(f14b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f14b2_syn_concat')\n",
    "        f15b2_syn_hist=tf.concat([f15b2_syn_hist, tf.reshape(f15b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f15b2_syn_concat')\n",
    "        f16b2_syn_hist=tf.concat([f16b2_syn_hist, tf.reshape(f16b2_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f16b2_syn_concat')\n",
    "        \n",
    "        f1b11_syn_hist=tf.concat([f1b11_syn_hist, tf.reshape(f1b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f1b11_syn_concat')\n",
    "        f2b11_syn_hist=tf.concat([f2b11_syn_hist, tf.reshape(f2b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f2b11_syn_concat')\n",
    "        f3b11_syn_hist=tf.concat([f3b11_syn_hist, tf.reshape(f3b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f3b11_syn_concat')\n",
    "        f4b11_syn_hist=tf.concat([f4b11_syn_hist, tf.reshape(f4b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f4b11_syn_concat')\n",
    "        f5b11_syn_hist=tf.concat([f5b11_syn_hist, tf.reshape(f5b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f5b11_syn_concat')\n",
    "        f6b11_syn_hist=tf.concat([f6b11_syn_hist, tf.reshape(f6b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f6b11_syn_concat')\n",
    "        f7b11_syn_hist=tf.concat([f7b11_syn_hist, tf.reshape(f7b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f7b11_syn_concat')\n",
    "        f8b11_syn_hist=tf.concat([f8b11_syn_hist, tf.reshape(f8b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f8b11_syn_concat')\n",
    "        f9b11_syn_hist=tf.concat([f9b11_syn_hist, tf.reshape(f9b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f9b11_syn_concat')\n",
    "        f10b11_syn_hist=tf.concat([f10b11_syn_hist, tf.reshape(f10b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f10b11_syn_concat')\n",
    "        f11b11_syn_hist=tf.concat([f11b11_syn_hist, tf.reshape(f11b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f11b11_syn_concat')\n",
    "        f12b11_syn_hist=tf.concat([f12b11_syn_hist, tf.reshape(f12b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f12b11_syn_concat')\n",
    "        f13b11_syn_hist=tf.concat([f13b11_syn_hist, tf.reshape(f13b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f13b11_syn_concat')\n",
    "        f14b11_syn_hist=tf.concat([f14b11_syn_hist, tf.reshape(f14b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f14b11_syn_concat')\n",
    "        f15b11_syn_hist=tf.concat([f15b11_syn_hist, tf.reshape(f15b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f15b11_syn_concat')\n",
    "        f16b11_syn_hist=tf.concat([f16b11_syn_hist, tf.reshape(f16b11_syn.eval(session=sess), [1, no_filters_per_bc_type])], 0, name = 'f16b11_syn_concat')\n",
    "        \n",
    "        bip1_gc_syn_hist=tf.concat([bip1_gc_syn_hist, tf.reshape(bip1_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip1_gc_syn_concat')\n",
    "        bip2_gc_syn_hist=tf.concat([bip2_gc_syn_hist, tf.reshape(bip2_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip2_gc_syn_concat')\n",
    "        bip11_gc_syn_hist=tf.concat([bip11_gc_syn_hist, tf.reshape(bip11_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip11_gc_syn_concat')\n",
    "\n",
    "        bip1_copy_gc_syn_hist=tf.concat([bip1_copy_gc_syn_hist, tf.reshape(bip1_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip1_copy_gc_syn_concat')\n",
    "        bip2_copy_gc_syn_hist=tf.concat([bip2_copy_gc_syn_hist, tf.reshape(bip2_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip2_copy_gc_syn_concat')\n",
    "        bip11_copy_gc_syn_hist=tf.concat([bip11_copy_gc_syn_hist, tf.reshape(bip11_copy_gc_syn.eval(session=sess), [1, no_bipolars, no_gc])], 0, name = 'bip11_copy_gc_syn_concat')\n",
    "\n",
    "        bip1_am1_syn_hist=tf.concat([bip1_am1_syn_hist, tf.reshape(bip1_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])], 0, name = 'bip1_am1_syn_concat')\n",
    "        bip2_am1_syn_hist=tf.concat([bip2_am1_syn_hist, tf.reshape(bip2_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])], 0, name = 'bip2_am1_syn_concat')\n",
    "        bip11_am1_syn_hist=tf.concat([bip11_am1_syn_hist, tf.reshape(bip11_am1_syn.eval(session=sess), [1, no_bipolars, no_am1])], 0, name = 'bip11_am1_syn_concat')\n",
    "        \n",
    "        am1_gc_syn_hist=tf.concat([am1_gc_syn_hist, tf.reshape(am1_gc_syn.eval(session=sess), [1, no_am1, no_gc])], 0, name = 'am1_gc_syn_concat')\n",
    "\n",
    "        am1_b1copy_syn_hist=tf.concat([am1_b1copy_syn_hist, tf.reshape(am1_b1copy_syn.eval(session=sess), [1, no_am1, no_bipolars])], 0, name = 'am1_b1copy_syn_concat')\n",
    "        am1_b2copy_syn_hist=tf.concat([am1_b2copy_syn_hist, tf.reshape(am1_b2copy_syn.eval(session=sess), [1, no_am1, no_bipolars])], 0, name = 'am1_b2copy_syn_concat')\n",
    "\n",
    "        b1_bias_hist=tf.concat([b1_bias_hist, tf.reshape(b1_bias.eval(session=sess), [1, no_bipolars])], 0, name = 'bip1_bias_concat')\n",
    "        b2_bias_hist=tf.concat([b2_bias_hist, tf.reshape(b2_bias.eval(session=sess), [1, no_bipolars])], 0, name = 'bip2_bias_concat')\n",
    "        b11_bias_hist=tf.concat([b11_bias_hist, tf.reshape(b11_bias.eval(session=sess), [1, no_bipolars])], 0, name = 'bip11_bias_concat')\n",
    "\n",
    "        am1_bias_hist=tf.concat([am1_bias_hist, tf.reshape(am1_bias.eval(session=sess), [1, no_am1])], 0, name = 'am1_bias_concat')\n",
    "        gc_bias_hist=tf.concat([gc_bias_hist, tf.reshape(gc_bias.eval(session=sess), [1, no_gc])], 0, name = 'gc_bias_concat')\n",
    "        gc_stretch_hist=tf.concat([gc_stretch_hist, tf.reshape(gc_stretch.eval(session=sess), [1, no_gc])], 0, name = 'gc_bias_concat')\n",
    "\n",
    "        output_hist=tf.concat([output_hist, tf.reshape(output.eval(session=sess, feed_dict=singlefd), [1, 32, data_duration])], 0, name = 'output_concat')\n",
    "    \n",
    "        db={}\n",
    "        \n",
    "        db['f1b1_syn_hist']=f1b1_syn_hist.eval(session=sess)\n",
    "        db['f2b1_syn_hist']=f2b1_syn_hist.eval(session=sess)\n",
    "        db['f3b1_syn_hist']=f3b1_syn_hist.eval(session=sess)\n",
    "        db['f4b1_syn_hist']=f4b1_syn_hist.eval(session=sess)\n",
    "        db['f5b1_syn_hist']=f5b1_syn_hist.eval(session=sess)\n",
    "        db['f6b1_syn_hist']=f6b1_syn_hist.eval(session=sess)\n",
    "        db['f7b1_syn_hist']=f7b1_syn_hist.eval(session=sess)\n",
    "        db['f8b1_syn_hist']=f8b1_syn_hist.eval(session=sess)\n",
    "        db['f9b1_syn_hist']=f9b1_syn_hist.eval(session=sess)\n",
    "        db['f10b1_syn_hist']=f10b1_syn_hist.eval(session=sess)\n",
    "        db['f11b1_syn_hist']=f11b1_syn_hist.eval(session=sess)\n",
    "        db['f12b1_syn_hist']=f12b1_syn_hist.eval(session=sess)\n",
    "        db['f13b1_syn_hist']=f13b1_syn_hist.eval(session=sess)\n",
    "        db['f14b1_syn_hist']=f14b1_syn_hist.eval(session=sess)\n",
    "        db['f15b1_syn_hist']=f15b1_syn_hist.eval(session=sess)\n",
    "        db['f16b1_syn_hist']=f16b1_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['f1b2_syn_hist']=f1b2_syn_hist.eval(session=sess)\n",
    "        db['f2b2_syn_hist']=f2b2_syn_hist.eval(session=sess)\n",
    "        db['f3b2_syn_hist']=f3b2_syn_hist.eval(session=sess)\n",
    "        db['f4b2_syn_hist']=f4b2_syn_hist.eval(session=sess)\n",
    "        db['f5b2_syn_hist']=f5b2_syn_hist.eval(session=sess)\n",
    "        db['f6b2_syn_hist']=f6b2_syn_hist.eval(session=sess)\n",
    "        db['f7b2_syn_hist']=f7b2_syn_hist.eval(session=sess)\n",
    "        db['f8b2_syn_hist']=f8b2_syn_hist.eval(session=sess)\n",
    "        db['f9b2_syn_hist']=f9b2_syn_hist.eval(session=sess)\n",
    "        db['f10b2_syn_hist']=f10b2_syn_hist.eval(session=sess)\n",
    "        db['f11b2_syn_hist']=f11b2_syn_hist.eval(session=sess)\n",
    "        db['f12b2_syn_hist']=f12b2_syn_hist.eval(session=sess)\n",
    "        db['f13b2_syn_hist']=f13b2_syn_hist.eval(session=sess)\n",
    "        db['f14b2_syn_hist']=f14b2_syn_hist.eval(session=sess)\n",
    "        db['f15b2_syn_hist']=f15b2_syn_hist.eval(session=sess)\n",
    "        db['f16b2_syn_hist']=f16b2_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['f1b11_syn_hist']=f1b11_syn_hist.eval(session=sess)\n",
    "        db['f2b11_syn_hist']=f2b11_syn_hist.eval(session=sess)\n",
    "        db['f3b11_syn_hist']=f3b11_syn_hist.eval(session=sess)\n",
    "        db['f4b11_syn_hist']=f4b11_syn_hist.eval(session=sess)\n",
    "        db['f5b11_syn_hist']=f5b11_syn_hist.eval(session=sess)\n",
    "        db['f6b11_syn_hist']=f6b11_syn_hist.eval(session=sess)\n",
    "        db['f7b11_syn_hist']=f7b11_syn_hist.eval(session=sess)\n",
    "        db['f8b11_syn_hist']=f8b11_syn_hist.eval(session=sess)\n",
    "        db['f9b11_syn_hist']=f9b11_syn_hist.eval(session=sess)\n",
    "        db['f10b11_syn_hist']=f10b11_syn_hist.eval(session=sess)\n",
    "        db['f11b11_syn_hist']=f11b11_syn_hist.eval(session=sess)\n",
    "        db['f12b11_syn_hist']=f12b11_syn_hist.eval(session=sess)\n",
    "        db['f13b11_syn_hist']=f13b11_syn_hist.eval(session=sess)\n",
    "        db['f14b11_syn_hist']=f14b11_syn_hist.eval(session=sess)\n",
    "        db['f15b11_syn_hist']=f15b11_syn_hist.eval(session=sess)\n",
    "        db['f16b11_syn_hist']=f16b11_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['loss_hist']=loss_hist\n",
    "        db['test_hist']=test_hist   \n",
    "        \n",
    "        db['output_hist']=output_hist.eval(session=sess)\n",
    "        db['bip1_gc_syn_hist']=bip1_gc_syn_hist.eval(session=sess)\n",
    "        db['bip2_gc_syn_hist']=bip2_gc_syn_hist.eval(session=sess)\n",
    "        db['bip11_gc_syn_hist']=bip11_gc_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['bip1_copy_gc_syn_hist']=bip1_copy_gc_syn_hist.eval(session=sess)\n",
    "        db['bip2_copy_gc_syn_hist']=bip2_copy_gc_syn_hist.eval(session=sess)\n",
    "        db['bip11_copy_gc_syn_hist']=bip11_copy_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "        db['bip1_am1_syn_hist']=bip1_am1_syn_hist.eval(session=sess)\n",
    "        db['bip2_am1_syn_hist']=bip2_am1_syn_hist.eval(session=sess)\n",
    "        db['bip11_am1_syn_hist']=bip11_am1_syn_hist.eval(session=sess)\n",
    "       \n",
    "        db['am1_gc_syn_hist']=am1_gc_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['am1_b1copy_syn_hist']=am1_b1copy_syn_hist.eval(session=sess)\n",
    "        db['am1_b2copy_syn_hist']=am1_b2copy_syn_hist.eval(session=sess)\n",
    "        \n",
    "        db['b1_bias_hist']=b1_bias_hist.eval(session=sess)\n",
    "        db['b2_bias_hist']=b2_bias_hist.eval(session=sess)\n",
    "\n",
    "        db['b11_bias_hist']=b11_bias_hist.eval(session=sess)\n",
    "\n",
    "        db['am1_bias_hist']=am1_bias_hist.eval(session=sess)\n",
    "        db['gc_bias_hist']=gc_bias_hist.eval(session=sess)\n",
    "        db['gc_stretch_hist']=gc_stretch_hist.eval(session=sess)\n",
    "\n",
    "        db['learning_rate']=learn_rate\n",
    "        db['lambda']=lambda1\n",
    "        \n",
    "        if algorithm_choice==1: \n",
    "            db['algorithm']='Gradient_Descent'\n",
    "        elif algorithm_choice==2:\n",
    "            db['algorithm']='Adam'\n",
    "            db['epsilon']=my_epsilon\n",
    "        elif algorithm_choice==3:\n",
    "            db['algorithm']='Momentum'\n",
    "            db['momentum']=momentum_par\n",
    "        elif algorithm_choice==4:\n",
    "            db['algorithm']='Adagrad'\n",
    "        elif algorithm_choice==5:\n",
    "            db['algorithm']='RMSProp'\n",
    "\n",
    "        sio.savemat(wheretosave, db)        \n",
    "\n",
    "    step=step+1\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# COMPUTE TRAINED NETWORK OUTPUT\n",
    "\n",
    "o_output=zeros([1024, dur])\n",
    "\n",
    "batchsz=32\n",
    "for bbatch in range(32):\n",
    "    startind=(bbatch)*batchsz\n",
    "    endind=(bbatch+1)*batchsz\n",
    "    fd={batchsize_: train_loss_size, input_filt1_: input_bip1_train[:, startind:endind, :], \\\n",
    "             input_filt2_: input_bip2_train[:, startind:endind, :], input_filt3_: input_bip3_train[:, startind:endind, :],\\\n",
    "             input_filt4_: input_bip4_train[:, startind:endind, :], input_filt5_: input_bip5_train[:, startind:endind, :],\\\n",
    "             input_filt6_: input_bip6_train[:, startind:endind, :], input_filt7_: input_bip7_train[:, startind:endind, :],\\\n",
    "             input_filt8_: input_bip8_train[:, startind:endind, :], input_filt9_: input_bip9_train[:, startind:endind, :],\\\n",
    "             input_filt10_: input_bip10_train[:, startind:endind, :], input_filt11_: input_bip11_train[:, startind:endind, :],\\\n",
    "             input_filt12_: input_bip12_train[:, startind:endind, :], input_filt13_: input_bip13_train[:, startind:endind, :],\\\n",
    "             input_filt14_: input_bip14_train[:, startind:endind, :], input_filt15_: input_bip15_train[:, startind:endind, :],\\\n",
    "             input_filt16_: input_bip16_train[:, startind:endind, :]}\n",
    "    o_output[startind:endind, :]=np.reshape(sess.run([output], fd), [32, dur]) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# SAVE PARAMETER HISTORIES AND TRAINING HYPERPARAMSIB\n",
    "\n",
    "db={}\n",
    "\n",
    "# db['b1_out']=b1copy_out\n",
    "# db['am1_out']=am1_out\n",
    "# db['b11a1_mult']=b11a1_mult.eval(session=sess, feed_dict=singlefd)\n",
    "# db['b1copy_out']=b1copy_out\n",
    "# db['b2_out']=b2_out\n",
    "# db['b11_out']=b11_out\n",
    "# db['input1']=input1\n",
    "\n",
    "db['f1b1_syn_hist']=f1b1_syn_hist.eval(session=sess)\n",
    "db['f2b1_syn_hist']=f2b1_syn_hist.eval(session=sess)\n",
    "db['f3b1_syn_hist']=f3b1_syn_hist.eval(session=sess)\n",
    "db['f4b1_syn_hist']=f4b1_syn_hist.eval(session=sess)\n",
    "db['f5b1_syn_hist']=f5b1_syn_hist.eval(session=sess)\n",
    "db['f6b1_syn_hist']=f6b1_syn_hist.eval(session=sess)\n",
    "db['f7b1_syn_hist']=f7b1_syn_hist.eval(session=sess)\n",
    "db['f8b1_syn_hist']=f8b1_syn_hist.eval(session=sess)\n",
    "db['f9b1_syn_hist']=f9b1_syn_hist.eval(session=sess)\n",
    "db['f10b1_syn_hist']=f10b1_syn_hist.eval(session=sess)\n",
    "db['f11b1_syn_hist']=f11b1_syn_hist.eval(session=sess)\n",
    "db['f12b1_syn_hist']=f12b1_syn_hist.eval(session=sess)\n",
    "db['f13b1_syn_hist']=f13b1_syn_hist.eval(session=sess)\n",
    "db['f14b1_syn_hist']=f14b1_syn_hist.eval(session=sess)\n",
    "db['f15b1_syn_hist']=f15b1_syn_hist.eval(session=sess)\n",
    "db['f16b1_syn_hist']=f16b1_syn_hist.eval(session=sess)\n",
    "\n",
    "db['f1b2_syn_hist']=f1b2_syn_hist.eval(session=sess)\n",
    "db['f2b2_syn_hist']=f2b2_syn_hist.eval(session=sess)\n",
    "db['f3b2_syn_hist']=f3b2_syn_hist.eval(session=sess)\n",
    "db['f4b2_syn_hist']=f4b2_syn_hist.eval(session=sess)\n",
    "db['f5b2_syn_hist']=f5b2_syn_hist.eval(session=sess)\n",
    "db['f6b2_syn_hist']=f6b2_syn_hist.eval(session=sess)\n",
    "db['f7b2_syn_hist']=f7b2_syn_hist.eval(session=sess)\n",
    "db['f8b2_syn_hist']=f8b2_syn_hist.eval(session=sess)\n",
    "db['f9b2_syn_hist']=f9b2_syn_hist.eval(session=sess)\n",
    "db['f10b2_syn_hist']=f10b2_syn_hist.eval(session=sess)\n",
    "db['f11b2_syn_hist']=f11b2_syn_hist.eval(session=sess)\n",
    "db['f12b2_syn_hist']=f12b2_syn_hist.eval(session=sess)\n",
    "db['f13b2_syn_hist']=f13b2_syn_hist.eval(session=sess)\n",
    "db['f14b2_syn_hist']=f14b2_syn_hist.eval(session=sess)\n",
    "db['f15b2_syn_hist']=f15b2_syn_hist.eval(session=sess)\n",
    "db['f16b2_syn_hist']=f16b2_syn_hist.eval(session=sess)\n",
    "\n",
    "db['f1b11_syn_hist']=f1b11_syn_hist.eval(session=sess)\n",
    "db['f2b11_syn_hist']=f2b11_syn_hist.eval(session=sess)\n",
    "db['f3b11_syn_hist']=f3b11_syn_hist.eval(session=sess)\n",
    "db['f4b11_syn_hist']=f4b11_syn_hist.eval(session=sess)\n",
    "db['f5b11_syn_hist']=f5b11_syn_hist.eval(session=sess)\n",
    "db['f6b11_syn_hist']=f6b11_syn_hist.eval(session=sess)\n",
    "db['f7b11_syn_hist']=f7b11_syn_hist.eval(session=sess)\n",
    "db['f8b11_syn_hist']=f8b11_syn_hist.eval(session=sess)\n",
    "db['f9b11_syn_hist']=f9b11_syn_hist.eval(session=sess)\n",
    "db['f10b11_syn_hist']=f10b11_syn_hist.eval(session=sess)\n",
    "db['f11b11_syn_hist']=f11b11_syn_hist.eval(session=sess)\n",
    "db['f12b11_syn_hist']=f12b11_syn_hist.eval(session=sess)\n",
    "db['f13b11_syn_hist']=f13b11_syn_hist.eval(session=sess)\n",
    "db['f14b11_syn_hist']=f14b11_syn_hist.eval(session=sess)\n",
    "db['f15b11_syn_hist']=f15b11_syn_hist.eval(session=sess)\n",
    "db['f16b11_syn_hist']=f16b11_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip1_gc_syn_hist']=bip1_gc_syn_hist.eval(session=sess)\n",
    "db['bip2_gc_syn_hist']=bip2_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip11_gc_syn_hist']=bip11_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip1_copy_gc_syn_hist']=bip1_copy_gc_syn_hist.eval(session=sess)\n",
    "db['bip2_copy_gc_syn_hist']=bip2_copy_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip11_copy_gc_syn_hist']=bip11_copy_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip1_am1_syn_hist']=bip1_am1_syn_hist.eval(session=sess)\n",
    "db['bip2_am1_syn_hist']=bip2_am1_syn_hist.eval(session=sess)\n",
    "\n",
    "db['bip11_am1_syn_hist']=bip11_am1_syn_hist.eval(session=sess)\n",
    "\n",
    "db['am1_gc_syn_hist']=am1_gc_syn_hist.eval(session=sess)\n",
    "\n",
    "db['am1_b1copy_syn_hist']=am1_b1copy_syn_hist.eval(session=sess)\n",
    "db['am1_b2copy_syn_hist']=am1_b2copy_syn_hist.eval(session=sess)\n",
    "\n",
    "db['b1_bias_hist']=b1_bias_hist.eval(session=sess)\n",
    "db['b2_bias_hist']=b2_bias_hist.eval(session=sess)\n",
    "db['b11_bias_hist']=b11_bias_hist.eval(session=sess)\n",
    "\n",
    "db['am1_bias_hist']=am1_bias_hist.eval(session=sess)\n",
    "db['gc_bias_hist']=gc_bias_hist.eval(session=sess)\n",
    "db['gc_stretch_hist']=gc_stretch_hist.eval(session=sess)\n",
    "\n",
    "db['output']=o_output\n",
    "\n",
    "db['loss_hist']=loss_hist\n",
    "db['batch_loss_hist']=batch_loss_hist\n",
    "db['test_hist']=test_hist\n",
    "\n",
    "db['learning_rate']=learn_rate\n",
    "db['lambda']=lambda1\n",
    "db['batch_size']=batchsize\n",
    "db['no_data_ex']=no_data_ex\n",
    "\n",
    "db['datapath']=datapath\n",
    "\n",
    "db['L1_hist']=L1_hist\n",
    "db['output_hist']=output_hist.eval(session=sess)\n",
    "\n",
    "\n",
    "\n",
    "if algorithm_choice==1: \n",
    "    db['algorithm']='Gradient_Descent'\n",
    "elif algorithm_choice==2:\n",
    "    db['algorithm']='Adam'\n",
    "    db['epsilon']=my_epsilon\n",
    "elif algorithm_choice==3:\n",
    "    db['algorithm']='Momentum'\n",
    "    db['momentum']=momentum_par\n",
    "elif algorithm_choice==4:\n",
    "    db['algorithm']='Adagrad'\n",
    "elif algorithm_choice==5:\n",
    "    db['algorithm']='RMSProp'\n",
    "\n",
    "sio.savemat(wheretosave, db)\n",
    "print(wheretosave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
